"""
ğŸ”¢ á»¨ng dá»¥ng Test Model CLI (Command Line Interface)

Script nÃ y cho phÃ©p test model nháº­n dáº¡ng chá»¯ sá»‘ qua command line.

Sá»­ dá»¥ng:
    # Test vá»›i máº«u MNIST ngáº«u nhiÃªn
    python test_model_cli.py
    
    # Test vá»›i file áº£nh
    python test_model_cli.py --image path/to/image.png
    
    # Test nhiá»u máº«u MNIST
    python test_model_cli.py --samples 10
    
    # Hiá»ƒn thá»‹ accuracy trÃªn toÃ n bá»™ test set
    python test_model_cli.py --evaluate
"""

import argparse
import numpy as np
import os
import joblib
import matplotlib.pyplot as plt
from time import time

# ÄÆ°á»ng dáº«n model
MODEL_PATH = 'outputs/svm_digit_classifier.joblib'
FALLBACK_MODEL_PATH = 'svm_digit_classifier.joblib'


def preprocess_digit_image(image_array, dilate_iterations=3, thin_stroke_mode=True, 
                           contrast_factor=1.5, debug=False):
    """
    Tiá»n xá»­ lÃ½ áº£nh chá»¯ sá»‘ viáº¿t tay (tá»« numpy array) Ä‘á»ƒ phÃ¹ há»£p vá»›i MNIST.
    
    Äáº¶C BIá»†T Tá»I Æ¯U CHO NÃ‰T BÃšT Má»NG TRÃŠN GIáº¤Y TRáº®NG!
    
    HÃ m nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c import vÃ  sá»­ dá»¥ng tá»« cÃ¡c module khÃ¡c:
        from test_model_cli import preprocess_digit_image, load_model
        
        model = load_model()
        processed = preprocess_digit_image(my_image_array)
        prediction = model.predict(processed.reshape(1, -1))[0]
    
    Parameters:
    -----------
    image_array : np.ndarray
        áº¢nh Ä‘áº§u vÃ o dáº¡ng numpy array (grayscale, báº¥t ká»³ kÃ­ch thÆ°á»›c)
    dilate_iterations : int
        Sá»‘ láº§n lÃ m dÃ y nÃ©t chá»¯ (máº·c Ä‘á»‹nh 3, tÄƒng lÃªn 4-6 náº¿u nÃ©t ráº¥t má»ng)
    thin_stroke_mode : bool
        Báº­t cháº¿ Ä‘á»™ xá»­ lÃ½ nÃ©t má»ng Ä‘áº·c biá»‡t (máº·c Ä‘á»‹nh True)
    contrast_factor : float
        Há»‡ sá»‘ tÄƒng cÆ°á»ng Ä‘á»™ tÆ°Æ¡ng pháº£n (máº·c Ä‘á»‹nh 1.5, tÄƒng náº¿u nÃ©t nháº¡t)
    debug : bool
        Hiá»ƒn thá»‹ thÃ´ng tin debug
        
    Returns:
    --------
    np.ndarray : áº¢nh 28x28 Ä‘Ã£ xá»­ lÃ½, chuáº©n hÃ³a vá» [0, 1], dáº¡ng (28, 28)
    """
    from PIL import Image, ImageFilter, ImageOps, ImageEnhance
    
    # Äáº£m báº£o lÃ  float64
    img_array = image_array.astype(np.float64)
    
    # Náº¿u cÃ³ 3 kÃªnh mÃ u, chuyá»ƒn sang grayscale
    if len(img_array.shape) == 3:
        img_array = np.mean(img_array, axis=2)
    
    original_shape = img_array.shape
    
    if debug:
        print(f"ğŸ“· KÃ­ch thÆ°á»›c áº£nh gá»‘c: {img_array.shape}")
        print(f"ğŸ“Š Min/Max pixel: {img_array.min():.0f}/{img_array.max():.0f}")
        print(f"ğŸ”§ Cháº¿ Ä‘á»™ nÃ©t má»ng: {'Báº¬T' if thin_stroke_mode else 'Táº®T'}")
    
    # BÆ¯á»šC 1: TÄ‚NG CÆ¯á»œNG Äá»˜ TÆ¯Æ NG PHáº¢N
    img_pil = Image.fromarray(img_array.astype(np.uint8))
    cutoff = 1 if thin_stroke_mode else 2
    img_pil = ImageOps.autocontrast(img_pil, cutoff=cutoff)
    
    if contrast_factor > 1.0:
        enhancer = ImageEnhance.Contrast(img_pil)
        img_pil = enhancer.enhance(contrast_factor)
    
    img_array = np.array(img_pil, dtype=np.float64)
    
    # BÆ¯á»šC 2: Äáº¢O NGÆ¯á»¢C MÃ€U Náº¾U Ná»€N SÃNG
    h, w = img_array.shape
    sample_points = [
        img_array[0, 0], img_array[0, -1], 
        img_array[-1, 0], img_array[-1, -1],
        img_array[0, w//2], img_array[-1, w//2],
        img_array[h//2, 0], img_array[h//2, -1]
    ]
    background_value = np.median(sample_points)
    
    if background_value > 127:
        img_array = 255 - img_array
        if debug:
            print("ğŸ”„ ÄÃ£ Ä‘áº£o ngÆ°á»£c mÃ u (ná»n sÃ¡ng -> ná»n Ä‘en)")
    
    # BÆ¯á»šC 3: Xá»¬ LÃ NHIá»„U
    if thin_stroke_mode:
        noise_threshold = 15
        img_array[img_array < noise_threshold] = 0
    
    # BÆ¯á»šC 4: LÃ€M Má»ŠN VÃ€ Káº¾T Ná»I NÃ‰T Äá»¨T
    if thin_stroke_mode:
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        img_pil = img_pil.filter(ImageFilter.GaussianBlur(radius=0.8))
        img_array = np.array(img_pil, dtype=np.float64)
    
    # BÆ¯á»šC 5: LÃ€M DÃ€Y NÃ‰T CHá»®
    if dilate_iterations > 0:
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        
        scale_factor = max(original_shape) / 200.0
        adjusted_iterations = max(dilate_iterations, int(dilate_iterations * scale_factor))
        adjusted_iterations = min(adjusted_iterations, 8)
        
        for _ in range(adjusted_iterations):
            img_pil = img_pil.filter(ImageFilter.MaxFilter(size=3))
        
        img_array = np.array(img_pil, dtype=np.float64)
        
        if debug:
            print(f"âœï¸ ÄÃ£ lÃ m dÃ y nÃ©t {adjusted_iterations} láº§n")
    
    # BÆ¯á»šC 6: MORPHOLOGICAL CLOSING
    if thin_stroke_mode:
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        img_pil = img_pil.filter(ImageFilter.MinFilter(size=3))
        img_pil = img_pil.filter(ImageFilter.MaxFilter(size=3))
        img_array = np.array(img_pil, dtype=np.float64)
    
    # BÆ¯á»šC 7: NGÆ¯á» NG Äá»˜NG
    if img_array.max() > 0:
        non_zero_pixels = img_array[img_array > 5]
        if len(non_zero_pixels) > 0:
            percentile = 20 if thin_stroke_mode else 30
            threshold = max(20, np.percentile(non_zero_pixels, percentile))
        else:
            threshold = 20
    else:
        threshold = 20
    
    # BÆ¯á»šC 8: TÃŒM BOUNDING BOX VÃ€ CÄ‚N GIá»®A
    coords = np.where(img_array > threshold)
    
    if len(coords[0]) > 0 and len(coords[1]) > 0:
        y_min, y_max = coords[0].min(), coords[0].max()
        x_min, x_max = coords[1].min(), coords[1].max()
        
        padding = 8 if thin_stroke_mode else 5
        y_min = max(0, y_min - padding)
        y_max = min(img_array.shape[0] - 1, y_max + padding)
        x_min = max(0, x_min - padding)
        x_max = min(img_array.shape[1] - 1, x_max + padding)
        
        digit_region = img_array[y_min:y_max+1, x_min:x_max+1]
        
        digit_img = Image.fromarray(digit_region.astype(np.uint8))
        
        h, w = digit_region.shape
        aspect = w / h
        if aspect > 1:
            new_width = 20
            new_height = max(1, int(20 / aspect))
        else:
            new_height = 20
            new_width = max(1, int(20 * aspect))
        
        digit_img = digit_img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        final_array = np.zeros((28, 28), dtype=np.float64)
        y_offset = (28 - new_height) // 2
        x_offset = (28 - new_width) // 2
        
        resized_digit = np.array(digit_img, dtype=np.float64)
        final_array[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = resized_digit
        
        img_array = final_array
    else:
        img = Image.fromarray(img_array.astype(np.uint8))
        img = img.resize((28, 28), Image.Resampling.LANCZOS)
        img_array = np.array(img, dtype=np.float64)
    
    # BÆ¯á»šC 9: LÃ€M DÃ€Y THÃŠM SAU KHI RESIZE
    if thin_stroke_mode:
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        img_pil = img_pil.filter(ImageFilter.MaxFilter(size=3))
        img_array = np.array(img_pil, dtype=np.float64)
    
    # BÆ¯á»šC 10: CHUáº¨N HÃ“A Vá»€ [0, 1]
    if img_array.max() > 0:
        img_array = img_array / 255.0
    
    img_array = np.clip(img_array, 0, 1)
    
    if debug:
        print(f"âœ… áº¢nh cuá»‘i cÃ¹ng: {img_array.shape}, range [{img_array.min():.3f}, {img_array.max():.3f}]")
    
    return img_array


def load_model():
    """Táº£i model Ä‘Ã£ train."""
    if os.path.exists(MODEL_PATH):
        print(f"ğŸ“¥ Äang táº£i model tá»« {MODEL_PATH}...")
        return joblib.load(MODEL_PATH)
    elif os.path.exists(FALLBACK_MODEL_PATH):
        print(f"ğŸ“¥ Äang táº£i model tá»« {FALLBACK_MODEL_PATH}...")
        return joblib.load(FALLBACK_MODEL_PATH)
    else:
        print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y model Ä‘Ã£ train. Äang huáº¥n luyá»‡n model má»›i...")
        return train_new_model()


def train_new_model():
    """Huáº¥n luyá»‡n model má»›i náº¿u chÆ°a cÃ³."""
    from sklearn.datasets import fetch_openml
    from sklearn.model_selection import train_test_split
    from sklearn.svm import SVC
    
    print("ğŸ“¥ Äang táº£i dá»¯ liá»‡u MNIST...")
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, parser='auto')
    y = y.astype(int)
    # Chuáº©n hÃ³a Ä‘Æ¡n giáº£n vá» [0, 1] - KHÃ”NG dÃ¹ng StandardScaler
    X = X.astype(np.float64) / 255.0
    
    # Sá»­ dá»¥ng 30000 máº«u Ä‘á»ƒ train (cÃ¢n báº±ng giá»¯a tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c)
    X_train, _, y_train, _ = train_test_split(X, y, train_size=30000, random_state=42, stratify=y)
    
    print("ğŸ‹ï¸ Äang huáº¥n luyá»‡n model SVM...")
    print("   (QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t vÃ i phÃºt...)")
    
    # KHÃ”NG dÃ¹ng Pipeline vá»›i StandardScaler - trÃ¡nh váº¥n Ä‘á» khÃ´ng khá»›p khi dá»± Ä‘oÃ¡n
    model = SVC(
        kernel='rbf', 
        C=10.0,  # Tá»‘i Æ°u cho MNIST
        gamma=0.01,  # Tá»‘i Æ°u cho MNIST
        probability=True, 
        cache_size=2000,
        random_state=42
    )
    model.fit(X_train, y_train)
    
    # LÆ°u model
    os.makedirs('outputs', exist_ok=True)
    joblib.dump(model, MODEL_PATH)
    print(f"âœ… ÄÃ£ lÆ°u model táº¡i {MODEL_PATH}")
    
    return model


def load_and_preprocess_image(image_path, dilate_iterations=3, debug=False, 
                               thin_stroke_mode=True, contrast_factor=1.5):
    """
    Táº£i vÃ  tiá»n xá»­ lÃ½ áº£nh tá»« file Ä‘á»ƒ phÃ¹ há»£p vá»›i MNIST.
    
    Äáº¶C BIá»†T Tá»I Æ¯U CHO NÃ‰T BÃšT Má»NG TRÃŠN GIáº¤Y TRáº®NG!
    
    QUAN TRá»ŒNG: MNIST cÃ³ cÃ¡c Ä‘áº·c Ä‘iá»ƒm sau:
    - KÃ­ch thÆ°á»›c 28x28 pixels
    - Ná»n Ä‘en (0), chá»¯ tráº¯ng (255)
    - Chá»¯ sá»‘ Ä‘Æ°á»£c cÄƒn giá»¯a vá»›i bounding box
    - GiÃ¡ trá»‹ pixel Ä‘Ã£ chuáº©n hÃ³a vá» [0, 1]
    - NÃ‰T CHá»® TÆ¯Æ NG Äá»I DÃ€Y (2-4 pixels trong 28x28)
    
    Parameters:
    -----------
    image_path : str
        ÄÆ°á»ng dáº«n Ä‘áº¿n file áº£nh
    dilate_iterations : int
        Sá»‘ láº§n lÃ m dÃ y nÃ©t chá»¯ (máº·c Ä‘á»‹nh 3, tÄƒng lÃªn 4-5 náº¿u nÃ©t ráº¥t má»ng)
    debug : bool
        Hiá»ƒn thá»‹ áº£nh trung gian Ä‘á»ƒ debug
    thin_stroke_mode : bool
        Báº­t cháº¿ Ä‘á»™ xá»­ lÃ½ nÃ©t má»ng Ä‘áº·c biá»‡t (máº·c Ä‘á»‹nh True)
    contrast_factor : float
        Há»‡ sá»‘ tÄƒng cÆ°á»ng Ä‘á»™ tÆ°Æ¡ng pháº£n (máº·c Ä‘á»‹nh 1.5, tÄƒng náº¿u nÃ©t nháº¡t)
        
    Returns:
    --------
    np.ndarray : áº¢nh 28x28 Ä‘Ã£ xá»­ lÃ½, chuáº©n hÃ³a vá» [0, 1]
    """
    from PIL import Image, ImageFilter, ImageOps, ImageEnhance
    
    # Äá»c áº£nh vÃ  chuyá»ƒn sang grayscale
    img = Image.open(image_path).convert('L')
    img_array = np.array(img, dtype=np.float64)
    original_shape = img_array.shape
    
    if debug:
        print(f"ğŸ“· KÃ­ch thÆ°á»›c áº£nh gá»‘c: {img_array.shape}")
        print(f"ğŸ“Š Min/Max pixel: {img_array.min():.0f}/{img_array.max():.0f}")
        print(f"ğŸ“Š Mean pixel: {img_array.mean():.1f}")
        print(f"ğŸ”§ Cháº¿ Ä‘á»™ nÃ©t má»ng: {'Báº¬T' if thin_stroke_mode else 'Táº®T'}")
    
    # =====================================================================
    # BÆ¯á»šC 1: TÄ‚NG CÆ¯á»œNG Äá»˜ TÆ¯Æ NG PHáº¢N (Äáº¶C BIá»†T QUAN TRá»ŒNG CHO NÃ‰T Má»NG)
    # =====================================================================
    
    img_pil = Image.fromarray(img_array.astype(np.uint8))
    
    # AutoContrast máº¡nh hÆ¡n cho nÃ©t má»ng
    cutoff = 1 if thin_stroke_mode else 2
    img_pil = ImageOps.autocontrast(img_pil, cutoff=cutoff)
    
    # TÄƒng contrast thÃªm náº¿u cáº§n (cho nÃ©t nháº¡t)
    if contrast_factor > 1.0:
        enhancer = ImageEnhance.Contrast(img_pil)
        img_pil = enhancer.enhance(contrast_factor)
    
    img_array = np.array(img_pil, dtype=np.float64)
    
    if debug:
        print(f"ğŸ“Š Sau tÄƒng contrast (factor={contrast_factor}) - Min/Max: {img_array.min():.0f}/{img_array.max():.0f}")
    
    # =====================================================================
    # BÆ¯á»šC 2: Äáº¢O NGÆ¯á»¢C MÃ€U Náº¾U Ná»€N SÃNG (MNIST CÃ“ Ná»€N ÄEN)
    # =====================================================================
    
    # Kiá»ƒm tra ná»n: láº¥y giÃ¡ trá»‹ á»Ÿ cÃ¡c gÃ³c vÃ  cáº¡nh
    h, w = img_array.shape
    sample_points = [
        img_array[0, 0], img_array[0, -1], 
        img_array[-1, 0], img_array[-1, -1],
        img_array[0, w//2], img_array[-1, w//2],
        img_array[h//2, 0], img_array[h//2, -1],
        # ThÃªm cÃ¡c Ä‘iá»ƒm á»Ÿ gáº§n gÃ³c Ä‘á»ƒ chÃ­nh xÃ¡c hÆ¡n
        img_array[min(10, h-1), min(10, w-1)],
        img_array[min(10, h-1), max(0, w-11)],
        img_array[max(0, h-11), min(10, w-1)],
        img_array[max(0, h-11), max(0, w-11)]
    ]
    background_value = np.median(sample_points)
    
    if debug:
        print(f"ğŸ“Š GiÃ¡ trá»‹ ná»n (median máº«u): {background_value:.0f}")
    
    # Äáº£o mÃ u náº¿u ná»n sÃ¡ng (viáº¿t trÃªn giáº¥y tráº¯ng)
    is_light_background = background_value > 127
    if is_light_background:
        img_array = 255 - img_array
        if debug:
            print("ğŸ”„ ÄÃ£ Ä‘áº£o ngÆ°á»£c mÃ u (ná»n sÃ¡ng -> ná»n Ä‘en)")
    
    # =====================================================================
    # BÆ¯á»šC 3: Xá»¬ LÃ NHIá»„U VÃ€ CHUáº¨N Bá»Š CHO NÃ‰T Má»NG
    # =====================================================================
    
    if thin_stroke_mode:
        # Vá»›i nÃ©t má»ng, ta cáº§n loáº¡i bá» nhiá»…u tá»« giáº¥y nhÆ°ng giá»¯ láº¡i nÃ©t
        # DÃ¹ng ngÆ°á»¡ng tháº¥p hÆ¡n Ä‘á»ƒ giá»¯ nÃ©t má»ng
        noise_threshold = 15
        img_array[img_array < noise_threshold] = 0
        
        if debug:
            print(f"ğŸ§¹ ÄÃ£ loáº¡i bá» nhiá»…u < {noise_threshold}")
    
    # =====================================================================
    # BÆ¯á»šC 4: LÃ€M Má»ŠN VÃ€ Káº¾T Ná»I NÃ‰T Äá»¨T (MORPHOLOGICAL CLOSING)
    # Ráº¥t quan trá»ng cho nÃ©t bÃºt má»ng bá»‹ Ä‘á»©t Ä‘oáº¡n!
    # =====================================================================
    
    if thin_stroke_mode:
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        
        # LÃ m má» nháº¹ Ä‘á»ƒ káº¿t ná»‘i cÃ¡c nÃ©t Ä‘á»©t gáº§n nhau
        img_pil = img_pil.filter(ImageFilter.GaussianBlur(radius=0.8))
        
        img_array = np.array(img_pil, dtype=np.float64)
        
        if debug:
            print("ğŸ”— ÄÃ£ lÃ m má» nháº¹ Ä‘á»ƒ káº¿t ná»‘i nÃ©t Ä‘á»©t")
    
    # =====================================================================
    # BÆ¯á»šC 5: LÃ€M DÃ€Y NÃ‰T CHá»® (MORPHOLOGICAL DILATION)
    # ÄÃ¢y lÃ  bÆ°á»›c QUAN TRá»ŒNG NHáº¤T cho nÃ©t bÃºt má»ng!
    # =====================================================================
    
    if dilate_iterations > 0:
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        
        # TÃ­nh sá»‘ láº§n dilate dá»±a trÃªn kÃ­ch thÆ°á»›c áº£nh
        # áº¢nh lá»›n hÆ¡n cáº§n dilate nhiá»u hÆ¡n
        scale_factor = max(original_shape) / 200.0  # 200 lÃ  kÃ­ch thÆ°á»›c tham chiáº¿u
        adjusted_iterations = max(dilate_iterations, int(dilate_iterations * scale_factor))
        adjusted_iterations = min(adjusted_iterations, 8)  # Giá»›i háº¡n tá»‘i Ä‘a
        
        if debug:
            print(f"âœï¸ Sá»‘ láº§n dilate Ä‘iá»u chá»‰nh: {adjusted_iterations} (gá»‘c: {dilate_iterations})")
        
        # DÃ¹ng MaxFilter Ä‘á»ƒ lÃ m dÃ y nÃ©t (tÆ°Æ¡ng tá»± dilation)
        for i in range(adjusted_iterations):
            img_pil = img_pil.filter(ImageFilter.MaxFilter(size=3))
        
        img_array = np.array(img_pil, dtype=np.float64)
        
        if debug:
            print(f"âœï¸ ÄÃ£ lÃ m dÃ y nÃ©t {adjusted_iterations} láº§n")
    
    # =====================================================================
    # BÆ¯á»šC 6: MORPHOLOGICAL CLOSING Äá»‚ ÄÃ“NG CÃC Lá»– NHá»
    # GiÃºp trÃ¡nh nháº­n nháº§m thÃ nh sá»‘ 8 (8 cÃ³ nhiá»u lá»—/vÃ²ng trÃ²n)
    # =====================================================================
    
    if thin_stroke_mode:
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        
        # MinFilter sau MaxFilter = Closing operation
        # GiÃºp lÃ m má»‹n cáº¡nh vÃ  Ä‘Ã³ng cÃ¡c lá»— nhá»
        img_pil = img_pil.filter(ImageFilter.MinFilter(size=3))
        img_pil = img_pil.filter(ImageFilter.MaxFilter(size=3))
        
        img_array = np.array(img_pil, dtype=np.float64)
        
        if debug:
            print("ğŸ”² ÄÃ£ Ã¡p dá»¥ng morphological closing")
    
    # =====================================================================
    # BÆ¯á»šC 7: NHáº¬N DIá»†N NGÆ¯á» NG VÃ€ Lá»ŒC NHIá»„U CUá»I CÃ™NG
    # =====================================================================
    
    # TÃ­nh ngÆ°á»¡ng Ä‘á»™ng dá»±a trÃªn histogram
    if img_array.max() > 0:
        non_zero_pixels = img_array[img_array > 5]
        if len(non_zero_pixels) > 0:
            # DÃ¹ng ngÆ°á»¡ng tháº¥p hÆ¡n cho nÃ©t má»ng
            percentile = 20 if thin_stroke_mode else 30
            threshold = max(20, np.percentile(non_zero_pixels, percentile))
        else:
            threshold = 20
    else:
        threshold = 20
    
    if debug:
        print(f"ğŸ“Š NgÆ°á»¡ng Ä‘á»™ng: {threshold:.0f}")
    
    # =====================================================================
    # BÆ¯á»šC 8: TÃŒM BOUNDING BOX VÃ€ CÄ‚N GIá»®A
    # =====================================================================
    
    coords = np.where(img_array > threshold)
    
    if len(coords[0]) > 0 and len(coords[1]) > 0:
        y_min, y_max = coords[0].min(), coords[0].max()
        x_min, x_max = coords[1].min(), coords[1].max()
        
        # ThÃªm padding nhá»
        padding = 8 if thin_stroke_mode else 5
        y_min = max(0, y_min - padding)
        y_max = min(img_array.shape[0] - 1, y_max + padding)
        x_min = max(0, x_min - padding)
        x_max = min(img_array.shape[1] - 1, x_max + padding)
        
        # Cáº¯t vÃ¹ng chá»©a chá»¯ sá»‘
        digit_region = img_array[y_min:y_max+1, x_min:x_max+1]
        
        if debug:
            print(f"ğŸ“¦ Bounding box: ({x_min}, {y_min}) -> ({x_max}, {y_max})")
            print(f"ğŸ“¦ KÃ­ch thÆ°á»›c vÃ¹ng chá»¯ sá»‘: {digit_region.shape}")
        
        # Resize vá» 20x20 (MNIST Ä‘á»ƒ margin 4 pixel má»—i bÃªn)
        digit_img = Image.fromarray(digit_region.astype(np.uint8))
        
        # Giá»¯ tá»· lá»‡ khung hÃ¬nh
        h, w = digit_region.shape
        aspect = w / h
        if aspect > 1:
            new_width = 20
            new_height = max(1, int(20 / aspect))
        else:
            new_height = 20
            new_width = max(1, int(20 * aspect))
        
        # DÃ¹ng LANCZOS cho cháº¥t lÆ°á»£ng tá»‘t
        digit_img = digit_img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # Táº¡o áº£nh 28x28 vá»›i ná»n Ä‘en vÃ  Ä‘áº·t chá»¯ sá»‘ vÃ o giá»¯a
        final_array = np.zeros((28, 28), dtype=np.float64)
        
        y_offset = (28 - new_height) // 2
        x_offset = (28 - new_width) // 2
        
        resized_digit = np.array(digit_img, dtype=np.float64)
        final_array[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = resized_digit
        
        img_array = final_array
    else:
        if debug:
            print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y chá»¯ sá»‘, resize toÃ n bá»™ áº£nh")
        img = Image.fromarray(img_array.astype(np.uint8))
        img = img.resize((28, 28), Image.Resampling.LANCZOS)
        img_array = np.array(img, dtype=np.float64)
    
    # =====================================================================
    # BÆ¯á»šC 9: LÃ€M DÃ€Y THÃŠM SAU KHI RESIZE (CHO NÃ‰T Má»NG)
    # =====================================================================
    
    if thin_stroke_mode:
        # Sau khi resize, nÃ©t cÃ³ thá»ƒ má»ng Ä‘i. Dilate thÃªm 1 láº§n
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        img_pil = img_pil.filter(ImageFilter.MaxFilter(size=3))
        img_array = np.array(img_pil, dtype=np.float64)
        
        if debug:
            print("âœï¸ ÄÃ£ lÃ m dÃ y thÃªm sau resize")
    
    # =====================================================================
    # BÆ¯á»šC 10: CHUáº¨N HÃ“A Vá»€ [0, 1]
    # =====================================================================
    
    # Normalize vá» [0, 1]
    if img_array.max() > 0:
        img_array = img_array / 255.0
    
    # Clip Ä‘á»ƒ Ä‘áº£m báº£o trong khoáº£ng [0, 1]
    img_array = np.clip(img_array, 0, 1)
    
    if debug:
        print(f"âœ… áº¢nh cuá»‘i cÃ¹ng: {img_array.shape}, range [{img_array.min():.3f}, {img_array.max():.3f}]")
        # Hiá»ƒn thá»‹ máº­t Ä‘á»™ pixel
        non_zero = np.count_nonzero(img_array > 0.1)
        print(f"ğŸ“Š Máº­t Ä‘á»™ nÃ©t: {non_zero}/{28*28} pixels ({non_zero/(28*28)*100:.1f}%)")
    
    return img_array


def predict_single(model, image, true_label=None, show_plot=True, original_image=None):
    """Dá»± Ä‘oÃ¡n má»™t áº£nh vÃ  hiá»ƒn thá»‹ káº¿t quáº£."""
    # Flatten
    img_flat = image.reshape(1, -1)
    
    # Dá»± Ä‘oÃ¡n
    prediction = model.predict(img_flat)[0]
    probabilities = model.predict_proba(img_flat)[0]
    confidence = probabilities[prediction]
    
    # In káº¿t quáº£
    print(f"\n{'='*50}")
    print(f"ğŸ¯ Dá»± Ä‘oÃ¡n: {prediction}")
    print(f"ğŸ“Š Äá»™ tin cáº­y: {confidence:.2%}")
    
    if true_label is not None:
        correct = prediction == true_label
        print(f"âœ… NhÃ£n thá»±c táº¿: {true_label}")
        print(f"{'âœ… ÄÃšNG!' if correct else 'âŒ SAI!'}")
    
    # Top 3 dá»± Ä‘oÃ¡n
    print(f"\nğŸ“ˆ Top 3 dá»± Ä‘oÃ¡n:")
    top3_idx = np.argsort(probabilities)[::-1][:3]
    for i, idx in enumerate(top3_idx):
        emoji = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰"
        print(f"   {emoji} Chá»¯ sá»‘ {idx}: {probabilities[idx]:.2%}")
    
    # Hiá»ƒn thá»‹ plot
    if show_plot:
        # Náº¿u cÃ³ áº£nh gá»‘c, hiá»ƒn thá»‹ 3 panel
        if original_image is not None:
            fig, axes = plt.subplots(1, 3, figsize=(14, 4))
            
            # áº¢nh gá»‘c
            axes[0].imshow(original_image, cmap='gray')
            axes[0].set_title('áº¢nh gá»‘c')
            axes[0].axis('off')
            
            # áº¢nh Ä‘Ã£ xá»­ lÃ½
            axes[1].imshow(image.reshape(28, 28), cmap='gray')
            title = f'Sau xá»­ lÃ½ â†’ Dá»± Ä‘oÃ¡n: {prediction}'
            if true_label is not None:
                title += f' (Thá»±c táº¿: {true_label})'
            axes[1].set_title(title)
            axes[1].axis('off')
            
            # Biá»ƒu Ä‘á»“ xÃ¡c suáº¥t
            colors = ['#e74c3c' if i == prediction else '#3498db' for i in range(10)]
            axes[2].bar(range(10), probabilities, color=colors)
            axes[2].set_xlabel('Chá»¯ sá»‘')
            axes[2].set_ylabel('XÃ¡c suáº¥t')
            axes[2].set_title('PhÃ¢n bá»‘ xÃ¡c suáº¥t')
            axes[2].set_xticks(range(10))
            axes[2].set_ylim([0, 1])
        else:
            fig, axes = plt.subplots(1, 2, figsize=(10, 4))
            
            # áº¢nh
            axes[0].imshow(image.reshape(28, 28), cmap='gray')
            title = f'Dá»± Ä‘oÃ¡n: {prediction}'
            if true_label is not None:
                title += f' (Thá»±c táº¿: {true_label})'
            axes[0].set_title(title)
            axes[0].axis('off')
            
            # Biá»ƒu Ä‘á»“ xÃ¡c suáº¥t
            colors = ['#e74c3c' if i == prediction else '#3498db' for i in range(10)]
            axes[1].bar(range(10), probabilities, color=colors)
            axes[1].set_xlabel('Chá»¯ sá»‘')
            axes[1].set_ylabel('XÃ¡c suáº¥t')
            axes[1].set_title('PhÃ¢n bá»‘ xÃ¡c suáº¥t')
            axes[1].set_xticks(range(10))
            axes[1].set_ylim([0, 1])
        
        plt.tight_layout()
        plt.show()
    
    return prediction, confidence


def test_random_samples(model, n_samples=5):
    """Test vá»›i cÃ¡c máº«u ngáº«u nhiÃªn tá»« MNIST."""
    from sklearn.datasets import fetch_openml
    
    print(f"\nğŸ“¥ Äang táº£i dá»¯ liá»‡u MNIST...")
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, parser='auto')
    y = y.astype(int)
    X = X.astype(np.float32) / 255.0
    
    # Láº¥y n máº«u ngáº«u nhiÃªn
    indices = np.random.choice(len(X), n_samples, replace=False)
    
    correct = 0
    print(f"\n{'='*60}")
    print(f"ğŸ² Test vá»›i {n_samples} máº«u ngáº«u nhiÃªn tá»« MNIST")
    print(f"{'='*60}")
    
    # Hiá»ƒn thá»‹ táº¥t cáº£ máº«u cÃ¹ng lÃºc
    cols = min(5, n_samples)
    rows = (n_samples + cols - 1) // cols
    fig, axes = plt.subplots(rows, cols, figsize=(3*cols, 3*rows))
    if n_samples == 1:
        axes = np.array([[axes]])
    elif rows == 1:
        axes = axes.reshape(1, -1)
    
    for i, idx in enumerate(indices):
        image = X[idx]
        true_label = y[idx]
        
        # Dá»± Ä‘oÃ¡n
        img_flat = image.reshape(1, -1)
        prediction = model.predict(img_flat)[0]
        probabilities = model.predict_proba(img_flat)[0]
        confidence = probabilities[prediction]
        
        is_correct = prediction == true_label
        if is_correct:
            correct += 1
        
        # In káº¿t quáº£
        status = "âœ…" if is_correct else "âŒ"
        print(f"\nMáº«u {i+1}: Thá»±c táº¿={true_label}, Dá»± Ä‘oÃ¡n={prediction} ({confidence:.1%}) {status}")
        
        # Hiá»ƒn thá»‹ áº£nh
        row, col = i // cols, i % cols
        axes[row, col].imshow(image.reshape(28, 28), cmap='gray')
        color = 'green' if is_correct else 'red'
        axes[row, col].set_title(f'Thá»±c: {true_label}\nDá»± Ä‘oÃ¡n: {prediction}', color=color)
        axes[row, col].axis('off')
    
    # áº¨n cÃ¡c subplot khÃ´ng dÃ¹ng
    for i in range(n_samples, rows * cols):
        row, col = i // cols, i % cols
        axes[row, col].axis('off')
    
    plt.tight_layout()
    plt.show()
    
    accuracy = correct / n_samples
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Káº¿t quáº£: {correct}/{n_samples} Ä‘Ãºng ({accuracy:.1%})")
    print(f"{'='*60}")
    
    return accuracy


def evaluate_model(model):
    """ÄÃ¡nh giÃ¡ model trÃªn toÃ n bá»™ test set."""
    from sklearn.datasets import fetch_openml
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
    import seaborn as sns
    
    print("\nğŸ“¥ Äang táº£i dá»¯ liá»‡u MNIST...")
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, parser='auto')
    y = y.astype(int)
    X = X.astype(np.float32) / 255.0
    
    # Chia dá»¯ liá»‡u
    _, X_test, _, y_test = train_test_split(X, y, test_size=10000, random_state=42, stratify=y)
    
    print(f"\nğŸ” ÄÃ¡nh giÃ¡ model trÃªn {len(X_test)} máº«u test...")
    
    # Dá»± Ä‘oÃ¡n
    start_time = time()
    y_pred = model.predict(X_test)
    predict_time = time() - start_time
    
    # TÃ­nh accuracy
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Káº¾T QUáº¢ ÄÃNH GIÃ")
    print(f"{'='*60}")
    print(f"\nğŸ¯ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"â±ï¸ Thá»i gian dá»± Ä‘oÃ¡n: {predict_time:.2f}s ({predict_time/len(X_test)*1000:.3f}ms/máº«u)")
    
    # Classification report
    print(f"\nğŸ“‹ Classification Report:")
    print(classification_report(y_test, y_pred, digits=4))
    
    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    
    plt.figure(figsize=(10, 8))
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    sns.heatmap(cm_normalized, annot=True, fmt='.1%', cmap='Blues',
                xticklabels=range(10), yticklabels=range(10))
    plt.title('Ma tráº­n Nháº§m láº«n (Normalized)')
    plt.xlabel('Dá»± Ä‘oÃ¡n')
    plt.ylabel('Thá»±c táº¿')
    plt.tight_layout()
    plt.show()
    
    return accuracy


def main():
    parser = argparse.ArgumentParser(
        description='Test Model Nháº­n dáº¡ng Chá»¯ sá»‘',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
VÃ­ dá»¥ sá»­ dá»¥ng:
  # Test vá»›i áº£nh viáº¿t tay nÃ©t bÃºt má»ng trÃªn giáº¥y tráº¯ng (Máº¶C Äá»ŠNH)
  python test_model_cli.py --image my_digit.png
  
  # Náº¿u káº¿t quáº£ váº«n sai, tÄƒng dilate vÃ  contrast
  python test_model_cli.py --image my_digit.png --dilate 5 --contrast 2.0
  
  # Táº¯t cháº¿ Ä‘á»™ nÃ©t má»ng (cho áº£nh nÃ©t Ä‘áº­m sáºµn)
  python test_model_cli.py --image my_digit.png --no-thin-mode
  
  # Debug xem quÃ¡ trÃ¬nh xá»­ lÃ½ áº£nh
  python test_model_cli.py --image my_digit.png --debug
  
  # Test vá»›i MNIST
  python test_model_cli.py --samples 10

LÆ¯U Ã Vá»€ NÃ‰T BÃšT Má»NG:
  - Máº·c Ä‘á»‹nh Ä‘Ã£ báº­t cháº¿ Ä‘á»™ tá»‘i Æ°u cho nÃ©t má»ng trÃªn giáº¥y tráº¯ng
  - Náº¿u váº«n nháº­n sai (hay bá»‹ nháº§m thÃ nh 8), thá»­:
    + TÄƒng --dilate lÃªn 4-6
    + TÄƒng --contrast lÃªn 1.8-2.5
    + Chá»¥p áº£nh rÃµ hÆ¡n, Ä‘á»§ sÃ¡ng
        """
    )
    parser.add_argument('--image', type=str, help='ÄÆ°á»ng dáº«n Ä‘áº¿n file áº£nh Ä‘á»ƒ test')
    parser.add_argument('--samples', type=int, default=5, help='Sá»‘ máº«u MNIST ngáº«u nhiÃªn Ä‘á»ƒ test (default: 5)')
    parser.add_argument('--evaluate', action='store_true', help='ÄÃ¡nh giÃ¡ model trÃªn toÃ n bá»™ test set')
    parser.add_argument('--no-plot', action='store_true', help='KhÃ´ng hiá»ƒn thá»‹ Ä‘á»“ thá»‹')
    parser.add_argument('--dilate', type=int, default=3, 
                        help='Sá»‘ láº§n lÃ m dÃ y nÃ©t chá»¯ (default: 3). TÄƒng lÃªn 4-6 náº¿u nÃ©t bÃºt Ráº¤T má»ng')
    parser.add_argument('--contrast', type=float, default=1.5,
                        help='Há»‡ sá»‘ tÄƒng contrast (default: 1.5). TÄƒng lÃªn 1.8-2.5 cho nÃ©t nháº¡t')
    parser.add_argument('--no-thin-mode', action='store_true',
                        help='Táº¯t cháº¿ Ä‘á»™ xá»­ lÃ½ nÃ©t má»ng (dÃ¹ng cho áº£nh nÃ©t Ä‘áº­m sáºµn)')
    parser.add_argument('--debug', action='store_true', 
                        help='Hiá»ƒn thá»‹ thÃ´ng tin debug vá» quÃ¡ trÃ¬nh xá»­ lÃ½ áº£nh')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸ”¢ TEST MODEL NHáº¬N Dáº NG CHá»® Sá» VIáº¾T TAY")
    print("="*60)
    
    # Táº£i model
    model = load_model()
    print("âœ… Model Ä‘Ã£ sáºµn sÃ ng!")
    
    if args.image:
        # Test vá»›i file áº£nh
        if not os.path.exists(args.image):
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {args.image}")
            return
        
        print(f"\nğŸ“‚ Äang táº£i áº£nh: {args.image}")
        
        # Hiá»ƒn thá»‹ cáº¥u hÃ¬nh
        thin_mode = not args.no_thin_mode
        print(f"ğŸ”§ Cáº¥u hÃ¬nh:")
        print(f"   - Cháº¿ Ä‘á»™ nÃ©t má»ng: {'Báº¬T' if thin_mode else 'Táº®T'}")
        print(f"   - Dilate iterations: {args.dilate}")
        print(f"   - Contrast factor: {args.contrast}")
        
        # Äá»c áº£nh gá»‘c Ä‘á»ƒ hiá»ƒn thá»‹ so sÃ¡nh
        from PIL import Image
        original_img = Image.open(args.image).convert('L')
        original_array = np.array(original_img)
        
        # Tiá»n xá»­ lÃ½ vá»›i cÃ¡c tham sá»‘ má»›i
        image = load_and_preprocess_image(
            args.image, 
            dilate_iterations=args.dilate, 
            debug=args.debug,
            thin_stroke_mode=thin_mode,
            contrast_factor=args.contrast
        )
        
        # Dá»± Ä‘oÃ¡n
        predict_single(model, image, show_plot=not args.no_plot, original_image=original_array)
        
        # Gá»£i Ã½ cá»¥ thá»ƒ hÆ¡n
        print(f"\nğŸ’¡ Gá»£i Ã½ náº¿u káº¿t quáº£ sai:")
        print(f"   1. TÄƒng Ä‘á»™ dÃ y nÃ©t: --dilate 5 hoáº·c --dilate 6")
        print(f"   2. TÄƒng Ä‘á»™ tÆ°Æ¡ng pháº£n: --contrast 2.0 hoáº·c --contrast 2.5")
        print(f"   3. Káº¿t há»£p cáº£ hai: --dilate 5 --contrast 2.0")
        print(f"   4. DÃ¹ng --debug Ä‘á»ƒ xem quÃ¡ trÃ¬nh xá»­ lÃ½ áº£nh")
        
    elif args.evaluate:
        # ÄÃ¡nh giÃ¡ trÃªn test set
        evaluate_model(model)
        
    else:
        # Test vá»›i máº«u MNIST ngáº«u nhiÃªn
        test_random_samples(model, args.samples)


if __name__ == "__main__":
    main()
