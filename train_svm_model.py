"""
ğŸ”¢ Script Train MÃ´ hÃ¬nh SVM Nháº­n dáº¡ng Chá»¯ sá»‘ Viáº¿t tay

Script nÃ y huáº¥n luyá»‡n mÃ´ hÃ¬nh SVM vá»›i toÃ n bá»™ dá»¯ liá»‡u MNIST (60k train, 10k test)
Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t cÃ³ thá»ƒ.

CÃ¡c cáº£i tiáº¿n so vá»›i phiÃªn báº£n cÅ©:
1. Sá»­ dá»¥ng TOÃ€N Bá»˜ dá»¯ liá»‡u train (60,000 máº«u) thay vÃ¬ chá»‰ 10,000
2. KHÃ”NG dÃ¹ng StandardScaler Ä‘á»ƒ trÃ¡nh váº¥n Ä‘á» khÃ´ng khá»›p khi dá»± Ä‘oÃ¡n
3. Tá»‘i Æ°u hyperparameters vá»›i GridSearchCV
4. Chuáº©n hÃ³a dá»¯ liá»‡u Ä‘Æ¡n giáº£n báº±ng chia 255 (0-1) - dá»… Ã¡p dá»¥ng cho áº£nh má»›i
5. LÆ°u cáº£ scaler riÃªng Ä‘á»ƒ dÃ¹ng cho áº£nh má»›i

Sá»­ dá»¥ng:
    python train_svm_model.py
    python train_svm_model.py --samples 60000  # Full data
    python train_svm_model.py --quick  # Quick test vá»›i 5000 samples
"""

import numpy as np
import os
import sys
import argparse
from time import time
import warnings
import joblib

warnings.filterwarnings('ignore')

# Sklearn imports
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    accuracy_score,
)

# =============================================================================
# Cáº¤U HÃŒNH
# =============================================================================

OUTPUT_DIR = 'outputs'
MODEL_FILENAME = 'svm_digit_classifier.joblib'

# =============================================================================
# HÃ€M CHÃNH
# =============================================================================

def load_mnist():
    """
    Táº£i vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u MNIST.
    
    Dá»¯ liá»‡u Ä‘Æ°á»£c chuáº©n hÃ³a Ä‘Æ¡n giáº£n báº±ng cÃ¡ch chia cho 255 Ä‘á»ƒ Ä‘Æ°a vá» [0, 1].
    KHÃ”NG dÃ¹ng StandardScaler Ä‘á»ƒ trÃ¡nh váº¥n Ä‘á» khÃ´ng khá»›p khi dá»± Ä‘oÃ¡n áº£nh má»›i.
    """
    print("=" * 60)
    print("ğŸ“¥ BÆ¯á»šC 1: Táº£i dá»¯ liá»‡u MNIST")
    print("=" * 60)
    
    start_time = time()
    
    # Táº£i dá»¯ liá»‡u tá»« OpenML
    print("\nğŸ”„ Äang táº£i dá»¯ liá»‡u tá»« OpenML...")
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, parser='auto')
    
    print(f"âœ… Táº£i xong trong {time() - start_time:.2f} giÃ¢y")
    print(f"\nğŸ“Š ThÃ´ng tin dá»¯ liá»‡u gá»‘c:")
    print(f"   - Shape cá»§a X: {X.shape}")
    print(f"   - Shape cá»§a y: {y.shape}")
    print(f"   - Sá»‘ lÆ°á»£ng lá»›p: {len(np.unique(y))}")
    print(f"   - CÃ¡c lá»›p: {np.unique(y)}")
    print(f"   - Dtype cá»§a X: {X.dtype}")
    print(f"   - Range cá»§a pixel: [{X.min()}, {X.max()}]")
    
    # Chuyá»ƒn Ä‘á»•i nhÃ£n sang sá»‘ nguyÃªn
    y = y.astype(int)
    
    # Chuáº©n hÃ³a pixel vá» [0, 1] - ÄÆ N GIáº¢N VÃ€ NHáº¤T QUÃN
    # Äiá»u nÃ y ráº¥t quan trá»ng: khi dá»± Ä‘oÃ¡n áº£nh má»›i, chá»‰ cáº§n chia cho 255
    X = X.astype(np.float64) / 255.0
    
    print(f"\nğŸ“Š Sau khi chuáº©n hÃ³a:")
    print(f"   - Dtype: {X.dtype}")
    print(f"   - Range: [{X.min():.4f}, {X.max():.4f}]")
    
    return X, y


def split_data(X, y, n_train_samples=None, random_state=42):
    """
    Chia dá»¯ liá»‡u thÃ nh train/test theo chuáº©n MNIST.
    
    Parameters:
    -----------
    X : array-like
        Dá»¯ liá»‡u Ä‘áº§u vÃ o
    y : array-like
        NhÃ£n
    n_train_samples : int, optional
        Sá»‘ máº«u train muá»‘n sá»­ dá»¥ng. None = sá»­ dá»¥ng háº¿t.
    random_state : int
        Random seed
        
    Returns:
    --------
    X_train, X_test, y_train, y_test
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š BÆ¯á»šC 2: Chia dá»¯ liá»‡u Train/Test")
    print("=" * 60)
    
    # Chia dá»¯ liá»‡u vá»›i tá»· lá»‡ chuáº©n MNIST (60k train, 10k test)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=10000,
        random_state=random_state,
        stratify=y  # Äáº£m báº£o phÃ¢n bá»‘ Ä‘á»u cÃ¡c lá»›p
    )
    
    print(f"\nğŸ“Š Káº¿t quáº£ chia dá»¯ liá»‡u:")
    print(f"   - Tá»•ng sá»‘ máº«u: {len(X)}")
    print(f"   - Train: {X_train.shape[0]} máº«u")
    print(f"   - Test: {X_test.shape[0]} máº«u")
    
    # Sá»­ dá»¥ng táº­p con náº¿u Ä‘Æ°á»£c yÃªu cáº§u
    if n_train_samples is not None and n_train_samples < len(X_train):
        print(f"\nâš¡ Láº¥y {n_train_samples} máº«u train...")
        
        # Láº¥y máº«u cÃ³ stratify
        indices = np.arange(len(X_train))
        np.random.seed(random_state)
        
        # Stratified sampling
        selected_indices = []
        for label in np.unique(y_train):
            label_indices = indices[y_train == label]
            n_select = int(n_train_samples * len(label_indices) / len(X_train))
            selected = np.random.choice(label_indices, size=n_select, replace=False)
            selected_indices.extend(selected)
        
        selected_indices = np.array(selected_indices)
        np.random.shuffle(selected_indices)
        
        X_train = X_train[selected_indices]
        y_train = y_train[selected_indices]
        
        print(f"   - Táº­p train sau khi láº¥y máº«u: {X_train.shape[0]} máº«u")
    
    # Kiá»ƒm tra phÃ¢n bá»‘ cÃ¡c lá»›p
    print(f"\nğŸ“ˆ PhÃ¢n bá»‘ lá»›p trong táº­p train:")
    unique, counts = np.unique(y_train, return_counts=True)
    for label, count in zip(unique, counts):
        print(f"   Chá»¯ sá»‘ {label}: {count} máº«u ({count/len(y_train)*100:.1f}%)")
    
    return X_train, X_test, y_train, y_test


def train_svm(X_train, y_train, kernel='rbf', C=10.0, gamma=0.01):
    """
    Huáº¥n luyá»‡n mÃ´ hÃ¬nh SVM.
    
    Parameters:
    -----------
    X_train : array-like
        Dá»¯ liá»‡u train
    y_train : array-like
        NhÃ£n train
    kernel : str
        Loáº¡i kernel ('rbf', 'linear', 'poly')
    C : float
        Há»‡ sá»‘ regularization
    gamma : float or str
        Há»‡ sá»‘ gamma cho RBF kernel
        
    Returns:
    --------
    model : SVC
        MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    train_time : float
        Thá»i gian huáº¥n luyá»‡n
    """
    print("\n" + "=" * 60)
    print("ğŸ‹ï¸ BÆ¯á»šC 3: Huáº¥n luyá»‡n mÃ´ hÃ¬nh SVM")
    print("=" * 60)
    
    print(f"\nğŸ“Š Cáº¥u hÃ¬nh mÃ´ hÃ¬nh:")
    print(f"   - Kernel: {kernel}")
    print(f"   - C: {C}")
    print(f"   - Gamma: {gamma}")
    print(f"   - Probability: True")
    print(f"   - Sá»‘ máº«u train: {len(X_train)}")
    
    # Táº¡o mÃ´ hÃ¬nh SVM
    # KHÃ”NG dÃ¹ng Pipeline vá»›i StandardScaler
    # Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a 0-1
    model = SVC(
        kernel=kernel,
        C=C,
        gamma=gamma,
        probability=True,  # Äá»ƒ cÃ³ thá»ƒ dÃ¹ng predict_proba
        cache_size=2000,   # TÄƒng cache Ä‘á»ƒ train nhanh hÆ¡n
        decision_function_shape='ovr',
        random_state=42
    )
    
    print(f"\nğŸ”„ Äang huáº¥n luyá»‡n...")
    print(f"   (QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t vÃ i phÃºt vá»›i dá»¯ liá»‡u lá»›n)")
    
    start_time = time()
    model.fit(X_train, y_train)
    train_time = time() - start_time
    
    print(f"\nâœ… Huáº¥n luyá»‡n hoÃ n táº¥t trong {train_time:.2f} giÃ¢y")
    print(f"   - Sá»‘ support vectors: {sum(model.n_support_)}")
    
    return model, train_time


def run_grid_search(X_train, y_train, n_samples=5000):
    """
    TÃ¬m hyperparameters tá»‘t nháº¥t vá»›i GridSearchCV.
    
    Parameters:
    -----------
    X_train : array-like
        Dá»¯ liá»‡u train
    y_train : array-like
        NhÃ£n train
    n_samples : int
        Sá»‘ máº«u sá»­ dá»¥ng cho grid search (Ä‘á»ƒ tiáº¿t kiá»‡m thá»i gian)
        
    Returns:
    --------
    best_params : dict
        CÃ¡c tham sá»‘ tá»‘t nháº¥t
    """
    print("\n" + "=" * 60)
    print("ğŸ” TÃŒM KIáº¾M HYPERPARAMETERS Tá»I Æ¯U")
    print("=" * 60)
    
    # Láº¥y máº«u con cho grid search
    n_samples = min(n_samples, len(X_train))
    indices = np.random.choice(len(X_train), n_samples, replace=False)
    X_grid = X_train[indices]
    y_grid = y_train[indices]
    
    print(f"\nğŸ“Š Sá»­ dá»¥ng {n_samples} máº«u cho GridSearch")
    
    # Äá»‹nh nghÄ©a lÆ°á»›i tham sá»‘
    # Dá»±a trÃªn cÃ¡c nghiÃªn cá»©u vá» SVM vá»›i MNIST:
    # - C trong khoáº£ng 1-10 thÆ°á»ng tá»‘t
    # - gamma khoáº£ng 0.01-0.05 vá»›i kernel RBF
    param_grid = {
        'C': [1, 5, 10],
        'gamma': [0.01, 0.02, 0.05],
        'kernel': ['rbf']
    }
    
    print(f"\nğŸ“‹ LÆ°á»›i tham sá»‘:")
    for key, values in param_grid.items():
        print(f"   - {key}: {values}")
    
    total_combinations = 1
    for values in param_grid.values():
        total_combinations *= len(values)
    print(f"\nğŸ“Š Tá»•ng sá»‘ káº¿t há»£p: {total_combinations}")
    
    # Táº¡o GridSearchCV
    grid_search = GridSearchCV(
        SVC(probability=True, cache_size=1000, random_state=42),
        param_grid,
        cv=3,
        n_jobs=-1,
        verbose=2,
        scoring='accuracy',
        return_train_score=True
    )
    
    print(f"\nğŸ”„ Äang tÃ¬m kiáº¿m... (cÃ³ thá»ƒ máº¥t vÃ i phÃºt)")
    
    start_time = time()
    grid_search.fit(X_grid, y_grid)
    search_time = time() - start_time
    
    print(f"\nâœ… GridSearch hoÃ n táº¥t trong {search_time:.2f} giÃ¢y")
    print(f"\nğŸ† Káº¿t quáº£ tá»‘t nháº¥t:")
    print(f"   - Best Score (CV): {grid_search.best_score_:.4f}")
    print(f"   - Best Parameters: {grid_search.best_params_}")
    
    # Hiá»ƒn thá»‹ top 5 káº¿t quáº£
    import pandas as pd
    results_df = pd.DataFrame(grid_search.cv_results_)
    results_df = results_df.sort_values('rank_test_score')[[
        'params', 'mean_test_score', 'std_test_score', 'rank_test_score'
    ]].head(5)
    
    print(f"\nğŸ“Š Top 5 káº¿t há»£p:")
    for i, row in results_df.iterrows():
        print(f"   {row['rank_test_score']}. {row['params']} - Accuracy: {row['mean_test_score']:.4f} (Â±{row['std_test_score']:.4f})")
    
    return grid_search.best_params_


def evaluate_model(model, X_test, y_test):
    """
    ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test.
    
    Parameters:
    -----------
    model : SVC
        MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    X_test : array-like
        Dá»¯ liá»‡u test
    y_test : array-like
        NhÃ£n test
        
    Returns:
    --------
    results : dict
        Káº¿t quáº£ Ä‘Ã¡nh giÃ¡
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š BÆ¯á»šC 4: ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh")
    print("=" * 60)
    
    # Dá»± Ä‘oÃ¡n
    print(f"\nğŸ”„ Äang dá»± Ä‘oÃ¡n trÃªn {len(X_test)} máº«u test...")
    
    start_time = time()
    y_pred = model.predict(X_test)
    predict_time = time() - start_time
    
    # TÃ­nh accuracy
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nğŸ¯ Káº¿t quáº£:")
    print(f"   - Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   - Thá»i gian dá»± Ä‘oÃ¡n: {predict_time:.2f}s")
    print(f"   - Tá»‘c Ä‘á»™: {predict_time/len(X_test)*1000:.3f}ms/máº«u")
    
    # Classification report
    print(f"\nğŸ“‹ Classification Report:")
    print(classification_report(y_test, y_pred, digits=4))
    
    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    
    # Hiá»ƒn thá»‹ cÃ¡c cáº·p chá»¯ sá»‘ hay bá»‹ nháº§m
    print(f"\nâŒ Top 5 cáº·p chá»¯ sá»‘ hay bá»‹ nháº§m láº«n:")
    cm_copy = cm.copy()
    np.fill_diagonal(cm_copy, 0)
    
    for _ in range(5):
        max_idx = np.unravel_index(np.argmax(cm_copy), cm_copy.shape)
        if cm_copy[max_idx] > 0:
            print(f"   - Thá»±c táº¿: {max_idx[0]}, Dá»± Ä‘oÃ¡n: {max_idx[1]} - {cm_copy[max_idx]} láº§n")
            cm_copy[max_idx] = 0
    
    return {
        'accuracy': accuracy,
        'predict_time': predict_time,
        'y_pred': y_pred,
        'confusion_matrix': cm
    }


def save_model(model, output_dir, filename):
    """
    LÆ°u mÃ´ hÃ¬nh.
    
    Parameters:
    -----------
    model : SVC
        MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    output_dir : str
        ThÆ° má»¥c lÆ°u
    filename : str
        TÃªn file
    """
    print("\n" + "=" * 60)
    print("ğŸ’¾ BÆ¯á»šC 5: LÆ°u mÃ´ hÃ¬nh")
    print("=" * 60)
    
    os.makedirs(output_dir, exist_ok=True)
    
    model_path = os.path.join(output_dir, filename)
    
    # LÆ°u model
    joblib.dump(model, model_path)
    print(f"\nâœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh: {model_path}")
    
    # LÆ°u thÃªm vÃ o thÆ° má»¥c gá»‘c Ä‘á»ƒ dá»… tÃ¬m
    root_path = filename
    joblib.dump(model, root_path)
    print(f"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh: {root_path}")
    
    # Kiá»ƒm tra kÃ­ch thÆ°á»›c file
    file_size = os.path.getsize(model_path) / (1024 * 1024)
    print(f"ğŸ“Š KÃ­ch thÆ°á»›c file: {file_size:.2f} MB")
    
    return model_path


def test_prediction(model):
    """
    Test dá»± Ä‘oÃ¡n vá»›i má»™t vÃ i máº«u tá»« MNIST.
    """
    print("\n" + "=" * 60)
    print("ğŸ§ª TEST Dá»° ÄOÃN")
    print("=" * 60)
    
    # Táº£i vÃ i máº«u MNIST
    print("\nğŸ“¥ Táº£i máº«u test tá»« MNIST...")
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, parser='auto')
    y = y.astype(int)
    X = X.astype(np.float64) / 255.0
    
    # Láº¥y 10 máº«u ngáº«u nhiÃªn
    np.random.seed(123)
    indices = np.random.choice(len(X), 10, replace=False)
    
    print(f"\nğŸ“Š Káº¿t quáº£ dá»± Ä‘oÃ¡n 10 máº«u ngáº«u nhiÃªn:")
    print("-" * 50)
    
    correct = 0
    for i, idx in enumerate(indices):
        sample = X[idx:idx+1]  # Shape (1, 784)
        true_label = y[idx]
        
        # Dá»± Ä‘oÃ¡n
        pred = model.predict(sample)[0]
        proba = model.predict_proba(sample)[0]
        confidence = proba[pred]
        
        is_correct = pred == true_label
        if is_correct:
            correct += 1
            status = "âœ…"
        else:
            status = "âŒ"
        
        print(f"   {i+1}. Thá»±c táº¿: {true_label}, Dá»± Ä‘oÃ¡n: {pred}, Tin cáº­y: {confidence:.2%} {status}")
    
    print("-" * 50)
    print(f"ğŸ“Š ÄÃºng: {correct}/10 ({correct*10}%)")
    
    return correct


def main():
    """HÃ m chÃ­nh."""
    parser = argparse.ArgumentParser(description='Train SVM Digit Recognition Model')
    parser.add_argument('--samples', type=int, default=60000,
                        help='Sá»‘ máº«u train (default: 60000 = full)')
    parser.add_argument('--quick', action='store_true',
                        help='Cháº¿ Ä‘á»™ nhanh vá»›i 5000 máº«u')
    parser.add_argument('--skip-grid-search', action='store_true',
                        help='Bá» qua GridSearch, dÃ¹ng tham sá»‘ máº·c Ä‘á»‹nh')
    parser.add_argument('--C', type=float, default=10.0,
                        help='Há»‡ sá»‘ C (default: 10.0)')
    parser.add_argument('--gamma', type=float, default=0.01,
                        help='Há»‡ sá»‘ gamma (default: 0.01)')
    
    args = parser.parse_args()
    
    # Quick mode
    if args.quick:
        args.samples = 5000
        args.skip_grid_search = True
    
    print("=" * 60)
    print("ğŸ”¢ HUáº¤N LUYá»†N MÃ” HÃŒNH SVM NHáº¬N Dáº NG CHá»® Sá»")
    print("=" * 60)
    print(f"\nğŸ“Š Cáº¥u hÃ¬nh:")
    print(f"   - Sá»‘ máº«u train: {args.samples}")
    print(f"   - GridSearch: {'KhÃ´ng' if args.skip_grid_search else 'CÃ³'}")
    if args.skip_grid_search:
        print(f"   - C: {args.C}")
        print(f"   - Gamma: {args.gamma}")
    
    total_start = time()
    
    # 1. Táº£i dá»¯ liá»‡u
    X, y = load_mnist()
    
    # 2. Chia dá»¯ liá»‡u
    n_train = args.samples if args.samples < 60000 else None
    X_train, X_test, y_train, y_test = split_data(X, y, n_train_samples=n_train)
    
    # 3. TÃ¬m hyperparameters (tÃ¹y chá»n)
    if not args.skip_grid_search:
        best_params = run_grid_search(X_train, y_train, n_samples=5000)
        C = best_params['C']
        gamma = best_params['gamma']
        kernel = best_params['kernel']
    else:
        C = args.C
        gamma = args.gamma
        kernel = 'rbf'
    
    # 4. Huáº¥n luyá»‡n mÃ´ hÃ¬nh
    model, train_time = train_svm(X_train, y_train, kernel=kernel, C=C, gamma=gamma)
    
    # 5. ÄÃ¡nh giÃ¡
    results = evaluate_model(model, X_test, y_test)
    
    # 6. LÆ°u model
    model_path = save_model(model, OUTPUT_DIR, MODEL_FILENAME)
    
    # 7. Test prediction
    test_prediction(model)
    
    # Tá»•ng káº¿t
    total_time = time() - total_start
    
    print("\n" + "=" * 60)
    print("ğŸ“Š Tá»”NG Káº¾T")
    print("=" * 60)
    print(f"\nğŸ¯ Accuracy: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)")
    print(f"â±ï¸ Tá»•ng thá»i gian: {total_time:.2f} giÃ¢y ({total_time/60:.1f} phÃºt)")
    print(f"\nğŸ“Š Cáº¥u hÃ¬nh mÃ´ hÃ¬nh tá»‘t nháº¥t:")
    print(f"   - Kernel: {kernel}")
    print(f"   - C: {C}")
    print(f"   - Gamma: {gamma}")
    print(f"\nğŸ“ MÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
    print(f"   - {model_path}")
    print(f"   - {MODEL_FILENAME}")
    print("\nâœ… HOÃ€N Táº¤T!")
    
    return model, results


if __name__ == "__main__":
    model, results = main()
