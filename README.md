# MachineLearning_NumberDetection

## ğŸ”¢ MÃ´ hÃ¬nh SVM Nháº­n dáº¡ng Chá»¯ sá»‘ Viáº¿t tay (MNIST)

Project nÃ y triá»ƒn khai Ä‘áº§y Ä‘á»§ quy trÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh SVM (Support Vector Machine) Ä‘á»ƒ nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay sá»­ dá»¥ng bá»™ dá»¯ liá»‡u MNIST.

## ğŸ“‹ Má»¥c lá»¥c

- [TÃ­nh nÄƒng](#-tÃ­nh-nÄƒng)
- [CÃ i Ä‘áº·t](#-cÃ i-Ä‘áº·t)
- [Sá»­ dá»¥ng](#-sá»­-dá»¥ng)
- [Cáº¥u trÃºc Project](#-cáº¥u-trÃºc-project)
- [Káº¿t quáº£](#-káº¿t-quáº£)
- [API Reference](#-api-reference)

## âœ¨ TÃ­nh nÄƒng

- **Tiá»n xá»­ lÃ½ dá»¯ liá»‡u**: Tá»± Ä‘á»™ng táº£i vÃ  chuáº©n hÃ³a dá»¯ liá»‡u MNIST
- **Huáº¥n luyá»‡n SVM**: Há»— trá»£ nhiá»u kernel (RBF, Linear, Polynomial, Sigmoid)
- **Tá»‘i Æ°u hÃ³a**: Grid Search Ä‘á»ƒ tÃ¬m siÃªu tham sá»‘ tá»‘t nháº¥t
- **PCA**: TÃ¹y chá»n giáº£m chiá»u vá»›i PCA
- **ÄÃ¡nh giÃ¡**: Classification report, Confusion matrix
- **Xuáº¥t cho Ensemble**: Xuáº¥t xÃ¡c suáº¥t dá»± Ä‘oÃ¡n Ä‘á»ƒ sá»­ dá»¥ng trong há»‡ ensemble
- **GPU Support**: Há»— trá»£ RAPIDS cuML cho GPU acceleration trÃªn Google Colab

## ğŸ›  CÃ i Ä‘áº·t

### YÃªu cáº§u

```bash
# CÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
pip install numpy pandas matplotlib seaborn scikit-learn joblib
```

### CÃ i Ä‘áº·t cuML cho GPU (Google Colab)

```python
# Cháº¡y trÃªn Google Colab vá»›i GPU runtime
!pip install cuml-cu11 --extra-index-url=https://pypi.nvidia.com
```

## ğŸš€ Sá»­ dá»¥ng

### CÃ¡ch 1: Cháº¡y Jupyter Notebook (Khuyáº¿n nghá»‹ cho Google Colab)

1. Upload file `svm_digit_recognition.ipynb` lÃªn Google Colab
2. Chá»n Runtime > Change runtime type > GPU
3. Cháº¡y tá»«ng cell theo thá»© tá»±

### CÃ¡ch 2: Cháº¡y Python Script

```bash
# Cháº¡y vá»›i cáº¥u hÃ¬nh máº·c Ä‘á»‹nh
python svm_digit_recognition.py

# Cháº¡y vá»›i tÃ¹y chá»‰nh
python svm_digit_recognition.py --subset-size 20000 --kernel rbf --C 10

# Sá»­ dá»¥ng toÃ n bá»™ dá»¯ liá»‡u
python svm_digit_recognition.py --use-full-data

# Bá» qua Grid Search
python svm_digit_recognition.py --skip-grid-search --kernel rbf --C 1.0

# Sá»­ dá»¥ng PCA
python svm_digit_recognition.py --use-pca --pca-components 100
```

### Tham sá»‘ dÃ²ng lá»‡nh

| Tham sá»‘ | MÃ´ táº£ | Máº·c Ä‘á»‹nh |
|---------|-------|----------|
| `--subset-size` | Sá»‘ máº«u train Ä‘á»ƒ sá»­ dá»¥ng | 60000 |
| `--use-full-data` | Sá»­ dá»¥ng toÃ n bá»™ dá»¯ liá»‡u train | True |
| `--skip-grid-search` | Bá» qua Grid Search | False |
| `--kernel` | Loáº¡i kernel (rbf, linear, poly, sigmoid) | rbf |
| `--C` | Há»‡ sá»‘ regularization | 10.0 |
| `--use-pca` | Sá»­ dá»¥ng PCA giáº£m chiá»u | False |
| `--pca-components` | Sá»‘ thÃ nh pháº§n PCA | 100 |

### Script train má»›i (khuyáº¿n nghá»‹)

```bash
# Train vá»›i full data vÃ  tham sá»‘ tá»‘i Æ°u
python train_svm_model.py --samples 60000

# Train nhanh Ä‘á»ƒ test (5000 máº«u)
python train_svm_model.py --quick

# Train vá»›i tham sá»‘ tÃ¹y chá»‰nh
python train_svm_model.py --samples 30000 --C 10.0 --gamma 0.01
```

### ğŸ†• Train SVM **tá»± code (khÃ´ng sklearn)** trÃªn Google Colab (khuyáº¿n nghá»‹ theo yÃªu cáº§u)

Repo Ä‘Ã£ cÃ³ implementation SVM **from-scratch báº±ng NumPy** (OVR hinge-loss SGD) + tuá»³ chá»n **RFF** Ä‘á»ƒ xáº¥p xá»‰ RBF-kernel SVM.

```bash
# TrÃªn Google Colab (khÃ´ng dÃ¹ng sklearn):
python train_svm_scratch_colab.py --feature-map rff --rff-dim 2048 --gamma 0.05 --epochs 20
```

Äáº§u ra sáº½ Ä‘Æ°á»£c lÆ°u táº¡i:
- `outputs/svm_digit_classifier_scratch.npz`

CLI/Desktop app sáº½ **tá»± Æ°u tiÃªn load** file `.npz` nÃ y náº¿u tá»“n táº¡i.

## ğŸ§ª Test Model

### CÃ¡ch 1: á»¨ng dá»¥ng Desktop (Tkinter)

á»¨ng dá»¥ng desktop cho phÃ©p báº¡n váº½ chá»¯ sá»‘ Ä‘á»ƒ test model.

```bash
# Cháº¡y á»©ng dá»¥ng desktop
python test_app.py
```

**TÃ­nh nÄƒng:**
- âœï¸ Váº½ chá»¯ sá»‘ trá»±c tiáº¿p trÃªn canvas
- ğŸ“‚ Upload áº£nh chá»¯ sá»‘ tá»« mÃ¡y tÃ­nh (PNG, JPG, BMP, GIF, TIFF, WebP)
- ğŸ² Test vá»›i máº«u ngáº«u nhiÃªn tá»« MNIST
- ğŸ“Š Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ xÃ¡c suáº¥t dá»± Ä‘oÃ¡n
- ğŸ–¼ï¸ Xem áº£nh Ä‘Ã£ xá»­ lÃ½ (28x28)

### CÃ¡ch 2: Command Line (CLI)

```bash
# Test vá»›i máº«u MNIST ngáº«u nhiÃªn (máº·c Ä‘á»‹nh 5 máº«u)
python test_model_cli.py

# Test vá»›i nhiá»u máº«u hÆ¡n
python test_model_cli.py --samples 10

# Test vá»›i file áº£nh (tá»± Ä‘á»™ng báº­t cháº¿ Ä‘á»™ nÃ©t má»ng)
python test_model_cli.py --image path/to/your/digit.png

# ÄÃ¡nh giÃ¡ model trÃªn toÃ n bá»™ test set
python test_model_cli.py --evaluate

# KhÃ´ng hiá»ƒn thá»‹ Ä‘á»“ thá»‹
python test_model_cli.py --no-plot
```

### âš ï¸ Xá»­ lÃ½ NÃ‰T BÃšT Má»NG trÃªn giáº¥y tráº¯ng

Thuáº­t toÃ¡n tiá»n xá»­ lÃ½ Ä‘Ã£ Ä‘Æ°á»£c **cáº£i tiáº¿n máº¡nh máº½** Ä‘á»ƒ xá»­ lÃ½ áº£nh nÃ©t má»ng:

**ğŸ”§ Thuáº­t toÃ¡n xá»­ lÃ½ (v2.0):**
1. **Otsu Thresholding** - Tá»± Ä‘á»™ng tÃ¬m ngÆ°á»¡ng tá»‘i Æ°u Ä‘á»ƒ tÃ¡ch nÃ©t tá»« ná»n
2. **Binarization thÃ´ng minh** - DÃ¹ng percentile histogram Ä‘á»ƒ loáº¡i bá» nhiá»…u hiá»‡u quáº£
3. **Morphological Closing Ä‘Ãºng** - Maxâ†’Min (trÆ°á»›c Ä‘Ã¢y bá»‹ ngÆ°á»£c!)
4. **Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh Ä‘á»™ dÃ y** - Äiá»u chá»‰nh Ä‘á»ƒ khá»›p vá»›i MNIST (80-200 pixels)
5. **Chuáº©n hÃ³a Ä‘á»™ sÃ¡ng** - Äáº£m báº£o stroke_mean ~0.72 nhÆ° MNIST

```bash
# CÃ¡ch cÆ¡ báº£n (máº·c Ä‘á»‹nh Ä‘Ã£ tá»‘i Æ°u)
python test_model_cli.py --image my_digit.png

# Náº¿u nÃ©t Ráº¤T má»ng/nháº¡t trÃªn giáº¥y cÃ³ nhiá»…u
python test_model_cli.py --image my_digit.png --dilate 4 --contrast 2.0

# Debug Ä‘á»ƒ xem chi tiáº¿t quÃ¡ trÃ¬nh xá»­ lÃ½
python test_model_cli.py --image my_digit.png --debug

# Táº¯t cháº¿ Ä‘á»™ nÃ©t má»ng cho áº£nh Ä‘Ã£ cÃ³ nÃ©t Ä‘áº­m
python test_model_cli.py --image my_digit.png --no-thin-mode
```

**CÃ¡c tham sá»‘ quan trá»ng:**

| Tham sá»‘ | MÃ´ táº£ | Máº·c Ä‘á»‹nh | Gá»£i Ã½ cho nÃ©t má»ng |
|---------|-------|----------|-------------------|
| `--dilate` | Sá»‘ láº§n lÃ m dÃ y nÃ©t | 3 | TÄƒng lÃªn 4-5 náº¿u nÃ©t ráº¥t má»ng |
| `--contrast` | Há»‡ sá»‘ tÄƒng tÆ°Æ¡ng pháº£n | 1.5 | TÄƒng lÃªn 2.0-2.5 cho nÃ©t nháº¡t |
| `--no-thin-mode` | Táº¯t cháº¿ Ä‘á»™ nÃ©t má»ng | False | DÃ¹ng cho áº£nh nÃ©t Ä‘áº­m sáºµn |
| `--debug` | Hiá»ƒn thá»‹ thÃ´ng tin debug | False | Báº­t Ä‘á»ƒ xem Otsu threshold, pixels, v.v. |

**Hiá»‡u suáº¥t Ä‘Ã£ kiá»ƒm chá»©ng:**
- âœ… áº¢nh font nÃ©t xÃ¡m (ink=80) trÃªn ná»n tráº¯ng: **90%** (9/10 Ä‘Ãºng)
- âœ… áº¢nh ráº¥t nháº¡t (ink=150) vá»›i nhiá»…u ná»n: **70%** vá»›i `--dilate 4 --contrast 2.0`
- âœ… MNIST gá»‘c: **100%** (khÃ´ng áº£nh hÆ°á»Ÿng)

**Máº¹o Ä‘á»ƒ nháº­n diá»‡n tá»‘t hÆ¡n:**
1. ğŸ“¸ Chá»¥p áº£nh Ä‘á»§ sÃ¡ng, rÃµ nÃ©t, ná»n Ä‘á»“ng mÃ u
2. âœï¸ Chá»¯ sá»‘ nÃªn chiáº¿m pháº§n lá»›n khung hÃ¬nh (khÃ´ng quÃ¡ nhá»)
3. ğŸ“ Viáº¿t nÃ©t Ä‘áº­m hÆ¡n náº¿u cÃ³ thá»ƒ
4. ğŸ–¼ï¸ TrÃ¡nh bÃ³ng, váº¿t báº©n trÃªn ná»n giáº¥y

## ğŸ“ Cáº¥u trÃºc Project

```
/workspace
â”œâ”€â”€ README.md                      # TÃ i liá»‡u hÆ°á»›ng dáº«n
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ svm_digit_recognition.ipynb    # Jupyter Notebook (Google Colab)
â”œâ”€â”€ svm_digit_recognition.py       # Python script huáº¥n luyá»‡n (cÅ©)
â”œâ”€â”€ train_svm_model.py             # ğŸ†• Script train model cáº£i tiáº¿n (KHUYáº¾N NGHá»Š)
â”œâ”€â”€ test_app.py                    # á»¨ng dá»¥ng desktop test (Tkinter)
â”œâ”€â”€ test_model_cli.py              # CLI test model
â”œâ”€â”€ svm_digit_classifier.joblib    # MÃ´ hÃ¬nh Ä‘Ã£ train (copy á»Ÿ root)
â””â”€â”€ outputs/                       # ThÆ° má»¥c Ä‘áº§u ra (tá»± Ä‘á»™ng táº¡o)
    â””â”€â”€ svm_digit_classifier.joblib      # MÃ´ hÃ¬nh Ä‘Ã£ train (98.30% accuracy)
```

## ğŸ“Š Káº¿t quáº£

### Hiá»‡u suáº¥t mÃ´ hÃ¬nh

| Sá»‘ máº«u train | Accuracy | Train Time | Support Vectors |
|--------------|----------|------------|-----------------|
| 60,000 (full) | **98.30%** | ~6 phÃºt | ~10,700 |
| 30,000 | 97.76% | ~2.5 phÃºt | ~6,900 |
| 10,000 | ~96-97% | ~30s | ~3,000 |

### Cáº¥u hÃ¬nh tá»‘i Æ°u cho MNIST

| Tham sá»‘ | GiÃ¡ trá»‹ tá»‘i Æ°u |
|---------|----------------|
| Kernel | RBF |
| C | 10.0 |
| Gamma | 0.01 |

*LÆ°u Ã½: Káº¿t quáº£ cÃ³ thá»ƒ thay Ä‘á»•i nháº¹ tÃ¹y thuá»™c vÃ o pháº§n cá»©ng*

## ğŸ”§ API Reference

### Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u

```python
import joblib
import numpy as np

# Load mÃ´ hÃ¬nh
model = joblib.load('outputs/svm_digit_classifier.joblib')

# Dá»± Ä‘oÃ¡n nhÃ£n
image = np.random.rand(1, 784)  # áº¢nh 28x28 Ä‘Ã£ flatten
predictions = model.predict(image)
print(f"Predicted digit: {predictions[0]}")

# Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t
probabilities = model.predict_proba(image)
print(f"Probabilities: {probabilities}")
```

### HÃ m predict_digit

```python
from svm_digit_recognition import predict_digit

# Load mÃ´ hÃ¬nh
model = joblib.load('outputs/svm_digit_classifier.joblib')

# Dá»± Ä‘oÃ¡n tá»« áº£nh (28x28 hoáº·c 784)
image = np.random.rand(28, 28) * 255  # GiÃ¡ trá»‹ 0-255
result = predict_digit(model, image)

print(f"Prediction: {result['prediction']}")
print(f"Confidence: {result['confidence']:.4f}")
print(f"Probabilities: {result['probabilities']}")
```

### Tiá»n xá»­ lÃ½ áº£nh nÃ©t bÃºt má»ng (quan trá»ng!)

```python
from test_model_cli import preprocess_digit_image, load_model
from PIL import Image
import numpy as np

# Load mÃ´ hÃ¬nh
model = load_model()

# Äá»c áº£nh tá»« file
img = Image.open('my_digit.png').convert('L')
img_array = np.array(img)

# Tiá»n xá»­ lÃ½ vá»›i cÃ¡c tham sá»‘ tá»‘i Æ°u cho nÃ©t má»ng
processed = preprocess_digit_image(
    img_array,
    dilate_iterations=4,      # Sá»‘ láº§n lÃ m dÃ y nÃ©t (tÄƒng náº¿u nÃ©t má»ng)
    thin_stroke_mode=True,    # Báº­t cháº¿ Ä‘á»™ nÃ©t má»ng
    contrast_factor=1.8,      # TÄƒng Ä‘á»™ tÆ°Æ¡ng pháº£n
    debug=True                # Hiá»ƒn thá»‹ thÃ´ng tin debug
)

# Dá»± Ä‘oÃ¡n
prediction = model.predict(processed.reshape(1, -1))[0]
probabilities = model.predict_proba(processed.reshape(1, -1))[0]

print(f"Dá»± Ä‘oÃ¡n: {prediction}")
print(f"Äá»™ tin cáº­y: {probabilities[prediction]:.2%}")
```

### Load Ä‘áº§u ra cho Ensemble

```python
import pandas as pd
import numpy as np

# Load CSV
df = pd.read_csv('outputs/svm_predictions_for_ensemble.csv')
print(df.head())

# Load numpy arrays
probabilities = np.load('outputs/svm_probabilities.npy')
predictions = np.load('outputs/svm_predictions.npy')

print(f"Probabilities shape: {probabilities.shape}")  # (n_samples, 10)
print(f"Predictions shape: {predictions.shape}")      # (n_samples,)
```

## ğŸ“š Lá»™ trÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh

### 1. Chuáº©n bá»‹ dá»¯ liá»‡u vÃ  tiá»n xá»­ lÃ½

- Táº£i dá»¯ liá»‡u MNIST (60k train, 10k test, 28x28 pixels)
- Flatten áº£nh thÃ nh vector 784 chiá»u
- Chuáº©n hÃ³a pixel vá» [0, 1]

### 2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh SVM

- Sá»­ dá»¥ng SVC vá»›i RBF kernel
- **KHÃ”NG** dÃ¹ng StandardScaler Ä‘á»ƒ trÃ¡nh váº¥n Ä‘á» khÃ´ng khá»›p khi dá»± Ä‘oÃ¡n áº£nh má»›i
- Chuáº©n hÃ³a Ä‘Æ¡n giáº£n: chia 255 Ä‘á»ƒ Ä‘Æ°a vá» [0, 1]
- Tham sá»‘ tá»‘i Æ°u: C=10.0, gamma=0.01
- Há»— trá»£ probability output

### 3. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh

- Accuracy score
- Classification report (precision, recall, F1)
- Confusion matrix

### 4. Tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh

- GridSearchCV cho C, gamma, kernel
- PCA Ä‘á»ƒ giáº£m chiá»u (tÃ¹y chá»n)
- Cross-validation

### 5. Xuáº¥t Ä‘áº§u ra cho Ensemble

- XÃ¡c suáº¥t dá»± Ä‘oÃ¡n (predict_proba)
- NhÃ£n dá»± Ä‘oÃ¡n
- Format CSV vÃ  numpy

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n! Vui lÃ²ng táº¡o issue hoáº·c pull request.

## ğŸ“„ License

MIT License
