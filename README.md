# MachineLearning_NumberDetection

## ğŸ”¢ MÃ´ hÃ¬nh SVM Nháº­n dáº¡ng Chá»¯ sá»‘ Viáº¿t tay (MNIST)

Project nÃ y triá»ƒn khai Ä‘áº§y Ä‘á»§ quy trÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh SVM (Support Vector Machine) Ä‘á»ƒ nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay sá»­ dá»¥ng bá»™ dá»¯ liá»‡u MNIST.

## ğŸ“‹ Má»¥c lá»¥c

- [TÃ­nh nÄƒng](#-tÃ­nh-nÄƒng)
- [CÃ i Ä‘áº·t](#-cÃ i-Ä‘áº·t)
- [Sá»­ dá»¥ng](#-sá»­-dá»¥ng)
- [Cáº¥u trÃºc Project](#-cáº¥u-trÃºc-project)
- [Káº¿t quáº£](#-káº¿t-quáº£)
- [API Reference](#-api-reference)

## âœ¨ TÃ­nh nÄƒng

- **Tiá»n xá»­ lÃ½ dá»¯ liá»‡u**: Tá»± Ä‘á»™ng táº£i vÃ  chuáº©n hÃ³a dá»¯ liá»‡u MNIST
- **Huáº¥n luyá»‡n SVM**: Há»— trá»£ nhiá»u kernel (RBF, Linear, Polynomial, Sigmoid)
- **Tá»‘i Æ°u hÃ³a**: Grid Search Ä‘á»ƒ tÃ¬m siÃªu tham sá»‘ tá»‘t nháº¥t
- **PCA**: TÃ¹y chá»n giáº£m chiá»u vá»›i PCA
- **ÄÃ¡nh giÃ¡**: Classification report, Confusion matrix
- **Xuáº¥t cho Ensemble**: Xuáº¥t xÃ¡c suáº¥t dá»± Ä‘oÃ¡n Ä‘á»ƒ sá»­ dá»¥ng trong há»‡ ensemble
- **GPU Support**: Há»— trá»£ RAPIDS cuML cho GPU acceleration trÃªn Google Colab

## ğŸ›  CÃ i Ä‘áº·t

### YÃªu cáº§u

```bash
# CÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
pip install numpy pandas matplotlib seaborn scikit-learn joblib
```

### CÃ i Ä‘áº·t cuML cho GPU (Google Colab)

```python
# Cháº¡y trÃªn Google Colab vá»›i GPU runtime
!pip install cuml-cu11 --extra-index-url=https://pypi.nvidia.com
```

## ğŸš€ Sá»­ dá»¥ng

### CÃ¡ch 1: Cháº¡y Jupyter Notebook (Khuyáº¿n nghá»‹ cho Google Colab)

1. Upload file `svm_digit_recognition.ipynb` lÃªn Google Colab
2. Chá»n Runtime > Change runtime type > GPU
3. Cháº¡y tá»«ng cell theo thá»© tá»±

### CÃ¡ch 2: Cháº¡y Python Script

```bash
# Cháº¡y vá»›i cáº¥u hÃ¬nh máº·c Ä‘á»‹nh
python svm_digit_recognition.py

# Cháº¡y vá»›i tÃ¹y chá»‰nh
python svm_digit_recognition.py --subset-size 20000 --kernel rbf --C 10

# Sá»­ dá»¥ng toÃ n bá»™ dá»¯ liá»‡u
python svm_digit_recognition.py --use-full-data

# Bá» qua Grid Search
python svm_digit_recognition.py --skip-grid-search --kernel rbf --C 1.0

# Sá»­ dá»¥ng PCA
python svm_digit_recognition.py --use-pca --pca-components 100
```

### Tham sá»‘ dÃ²ng lá»‡nh

| Tham sá»‘ | MÃ´ táº£ | Máº·c Ä‘á»‹nh |
|---------|-------|----------|
| `--subset-size` | Sá»‘ máº«u train Ä‘á»ƒ sá»­ dá»¥ng | 60000 |
| `--use-full-data` | Sá»­ dá»¥ng toÃ n bá»™ dá»¯ liá»‡u train | True |
| `--skip-grid-search` | Bá» qua Grid Search | False |
| `--kernel` | Loáº¡i kernel (rbf, linear, poly, sigmoid) | rbf |
| `--C` | Há»‡ sá»‘ regularization | 10.0 |
| `--use-pca` | Sá»­ dá»¥ng PCA giáº£m chiá»u | False |
| `--pca-components` | Sá»‘ thÃ nh pháº§n PCA | 100 |

### Script train má»›i (khuyáº¿n nghá»‹)

```bash
# Train vá»›i full data vÃ  tham sá»‘ tá»‘i Æ°u
python train_svm_model.py --samples 60000

# Train nhanh Ä‘á»ƒ test (5000 máº«u)
python train_svm_model.py --quick

# Train vá»›i tham sá»‘ tÃ¹y chá»‰nh
python train_svm_model.py --samples 30000 --C 10.0 --gamma 0.01
```

## ğŸ§ª Test Model

### CÃ¡ch 1: á»¨ng dá»¥ng Desktop (Tkinter)

á»¨ng dá»¥ng desktop cho phÃ©p báº¡n váº½ chá»¯ sá»‘ Ä‘á»ƒ test model.

```bash
# Cháº¡y á»©ng dá»¥ng desktop
python test_app.py
```

**TÃ­nh nÄƒng:**
- âœï¸ Váº½ chá»¯ sá»‘ trá»±c tiáº¿p trÃªn canvas
- ğŸ“‚ Upload áº£nh chá»¯ sá»‘ tá»« mÃ¡y tÃ­nh (PNG, JPG, BMP, GIF, TIFF, WebP)
- ğŸ² Test vá»›i máº«u ngáº«u nhiÃªn tá»« MNIST
- ğŸ“Š Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ xÃ¡c suáº¥t dá»± Ä‘oÃ¡n
- ğŸ–¼ï¸ Xem áº£nh Ä‘Ã£ xá»­ lÃ½ (28x28)

### CÃ¡ch 2: Command Line (CLI)

```bash
# Test vá»›i máº«u MNIST ngáº«u nhiÃªn (máº·c Ä‘á»‹nh 5 máº«u)
python test_model_cli.py

# Test vá»›i nhiá»u máº«u hÆ¡n
python test_model_cli.py --samples 10

# Test vá»›i file áº£nh
python test_model_cli.py --image path/to/your/digit.png

# ÄÃ¡nh giÃ¡ model trÃªn toÃ n bá»™ test set
python test_model_cli.py --evaluate

# KhÃ´ng hiá»ƒn thá»‹ Ä‘á»“ thá»‹
python test_model_cli.py --no-plot
```

## ğŸ“ Cáº¥u trÃºc Project

```
/workspace
â”œâ”€â”€ README.md                      # TÃ i liá»‡u hÆ°á»›ng dáº«n
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ svm_digit_recognition.ipynb    # Jupyter Notebook (Google Colab)
â”œâ”€â”€ svm_digit_recognition.py       # Python script huáº¥n luyá»‡n (cÅ©)
â”œâ”€â”€ train_svm_model.py             # ğŸ†• Script train model cáº£i tiáº¿n (KHUYáº¾N NGHá»Š)
â”œâ”€â”€ test_app.py                    # á»¨ng dá»¥ng desktop test (Tkinter)
â”œâ”€â”€ test_model_cli.py              # CLI test model
â”œâ”€â”€ svm_digit_classifier.joblib    # MÃ´ hÃ¬nh Ä‘Ã£ train (copy á»Ÿ root)
â””â”€â”€ outputs/                       # ThÆ° má»¥c Ä‘áº§u ra (tá»± Ä‘á»™ng táº¡o)
    â””â”€â”€ svm_digit_classifier.joblib      # MÃ´ hÃ¬nh Ä‘Ã£ train (98.30% accuracy)
```

## ğŸ“Š Káº¿t quáº£

### Hiá»‡u suáº¥t mÃ´ hÃ¬nh

| Sá»‘ máº«u train | Accuracy | Train Time | Support Vectors |
|--------------|----------|------------|-----------------|
| 60,000 (full) | **98.30%** | ~6 phÃºt | ~10,700 |
| 30,000 | 97.76% | ~2.5 phÃºt | ~6,900 |
| 10,000 | ~96-97% | ~30s | ~3,000 |

### Cáº¥u hÃ¬nh tá»‘i Æ°u cho MNIST

| Tham sá»‘ | GiÃ¡ trá»‹ tá»‘i Æ°u |
|---------|----------------|
| Kernel | RBF |
| C | 10.0 |
| Gamma | 0.01 |

*LÆ°u Ã½: Káº¿t quáº£ cÃ³ thá»ƒ thay Ä‘á»•i nháº¹ tÃ¹y thuá»™c vÃ o pháº§n cá»©ng*

## ğŸ”§ API Reference

### Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u

```python
import joblib
import numpy as np

# Load mÃ´ hÃ¬nh
model = joblib.load('outputs/svm_digit_classifier.joblib')

# Dá»± Ä‘oÃ¡n nhÃ£n
image = np.random.rand(1, 784)  # áº¢nh 28x28 Ä‘Ã£ flatten
predictions = model.predict(image)
print(f"Predicted digit: {predictions[0]}")

# Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t
probabilities = model.predict_proba(image)
print(f"Probabilities: {probabilities}")
```

### HÃ m predict_digit

```python
from svm_digit_recognition import predict_digit

# Load mÃ´ hÃ¬nh
model = joblib.load('outputs/svm_digit_classifier.joblib')

# Dá»± Ä‘oÃ¡n tá»« áº£nh (28x28 hoáº·c 784)
image = np.random.rand(28, 28) * 255  # GiÃ¡ trá»‹ 0-255
result = predict_digit(model, image)

print(f"Prediction: {result['prediction']}")
print(f"Confidence: {result['confidence']:.4f}")
print(f"Probabilities: {result['probabilities']}")
```

### Load Ä‘áº§u ra cho Ensemble

```python
import pandas as pd
import numpy as np

# Load CSV
df = pd.read_csv('outputs/svm_predictions_for_ensemble.csv')
print(df.head())

# Load numpy arrays
probabilities = np.load('outputs/svm_probabilities.npy')
predictions = np.load('outputs/svm_predictions.npy')

print(f"Probabilities shape: {probabilities.shape}")  # (n_samples, 10)
print(f"Predictions shape: {predictions.shape}")      # (n_samples,)
```

## ğŸ“š Lá»™ trÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh

### 1. Chuáº©n bá»‹ dá»¯ liá»‡u vÃ  tiá»n xá»­ lÃ½

- Táº£i dá»¯ liá»‡u MNIST (60k train, 10k test, 28x28 pixels)
- Flatten áº£nh thÃ nh vector 784 chiá»u
- Chuáº©n hÃ³a pixel vá» [0, 1]

### 2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh SVM

- Sá»­ dá»¥ng SVC vá»›i RBF kernel
- **KHÃ”NG** dÃ¹ng StandardScaler Ä‘á»ƒ trÃ¡nh váº¥n Ä‘á» khÃ´ng khá»›p khi dá»± Ä‘oÃ¡n áº£nh má»›i
- Chuáº©n hÃ³a Ä‘Æ¡n giáº£n: chia 255 Ä‘á»ƒ Ä‘Æ°a vá» [0, 1]
- Tham sá»‘ tá»‘i Æ°u: C=10.0, gamma=0.01
- Há»— trá»£ probability output

### 3. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh

- Accuracy score
- Classification report (precision, recall, F1)
- Confusion matrix

### 4. Tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh

- GridSearchCV cho C, gamma, kernel
- PCA Ä‘á»ƒ giáº£m chiá»u (tÃ¹y chá»n)
- Cross-validation

### 5. Xuáº¥t Ä‘áº§u ra cho Ensemble

- XÃ¡c suáº¥t dá»± Ä‘oÃ¡n (predict_proba)
- NhÃ£n dá»± Ä‘oÃ¡n
- Format CSV vÃ  numpy

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n! Vui lÃ²ng táº¡o issue hoáº·c pull request.

## ğŸ“„ License

MIT License
