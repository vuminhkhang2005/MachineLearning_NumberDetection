"""
üî¢ ·ª®ng d·ª•ng Desktop Test Model Nh·∫≠n d·∫°ng Ch·ªØ s·ªë Vi·∫øt tay

·ª®ng d·ª•ng n√†y cho ph√©p b·∫°n:
1. V·∫Ω ch·ªØ s·ªë tr·ª±c ti·∫øp tr√™n canvas
2. Upload ·∫£nh ch·ªØ s·ªë t·ª´ m√°y t√≠nh
3. Xem k·∫øt qu·∫£ d·ª± ƒëo√°n v√† x√°c su·∫•t

S·ª≠ d·ª•ng:
    python test_app.py
"""

import tkinter as tk
from tkinter import ttk, messagebox, filedialog
import numpy as np
import os
import joblib
from PIL import Image, ImageDraw, ImageTk
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

# ƒê∆∞·ªùng d·∫´n model
MODEL_PATH = 'outputs/svm_digit_classifier.joblib'
FALLBACK_MODEL_PATH = 'svm_digit_classifier.joblib'


def load_model():
    """T·∫£i model ƒë√£ train."""
    if os.path.exists(MODEL_PATH):
        print(f"üì• ƒêang t·∫£i model t·ª´ {MODEL_PATH}...")
        return joblib.load(MODEL_PATH)
    elif os.path.exists(FALLBACK_MODEL_PATH):
        print(f"üì• ƒêang t·∫£i model t·ª´ {FALLBACK_MODEL_PATH}...")
        return joblib.load(FALLBACK_MODEL_PATH)
    else:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y model ƒë√£ train. ƒêang hu·∫•n luy·ªán model m·ªõi...")
        return train_new_model()


def train_new_model():
    """Hu·∫•n luy·ªán model m·ªõi n·∫øu ch∆∞a c√≥."""
    from sklearn.datasets import fetch_openml
    from sklearn.model_selection import train_test_split
    from sklearn.svm import SVC
    
    print("üì• ƒêang t·∫£i d·ªØ li·ªáu MNIST...")
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, parser='auto')
    y = y.astype(int)
    # Chu·∫©n h√≥a ƒë∆°n gi·∫£n v·ªÅ [0, 1] - KH√îNG d√πng StandardScaler
    X = X.astype(np.float64) / 255.0
    
    # S·ª≠ d·ª•ng 30000 m·∫´u ƒë·ªÉ train (c√¢n b·∫±ng gi·ªØa t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c)
    X_train, _, y_train, _ = train_test_split(X, y, train_size=30000, random_state=42, stratify=y)
    
    print("üèãÔ∏è ƒêang hu·∫•n luy·ªán model SVM...")
    print("   (Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...)")
    
    # KH√îNG d√πng Pipeline v·ªõi StandardScaler - tr√°nh v·∫•n ƒë·ªÅ kh√¥ng kh·ªõp khi d·ª± ƒëo√°n
    model = SVC(
        kernel='rbf', 
        C=10.0,  # T·ªëi ∆∞u cho MNIST
        gamma=0.01,  # T·ªëi ∆∞u cho MNIST
        probability=True, 
        cache_size=2000,
        random_state=42
    )
    model.fit(X_train, y_train)
    
    # L∆∞u model
    os.makedirs('outputs', exist_ok=True)
    joblib.dump(model, MODEL_PATH)
    print(f"‚úÖ ƒê√£ l∆∞u model t·∫°i {MODEL_PATH}")
    
    return model


class DigitRecognitionApp:
    """·ª®ng d·ª•ng Desktop nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay."""
    
    def __init__(self, root, model):
        self.root = root
        self.model = model
        self.root.title("üî¢ Nh·∫≠n d·∫°ng Ch·ªØ s·ªë Vi·∫øt tay")
        self.root.geometry("900x600")
        self.root.resizable(True, True)
        
        # Canvas size
        self.canvas_size = 280
        self.brush_size = 20
        
        # S·ªë l·∫ßn l√†m d√†y n√©t (dilation) - quan tr·ªçng cho n√©t b√∫t m·ªèng
        # M·∫∑c ƒë·ªãnh 3 ƒë·ªÉ x·ª≠ l√Ω t·ªët h∆°n n√©t m·ªèng tr√™n gi·∫•y tr·∫Øng
        self.dilate_iterations = tk.IntVar(value=3)
        
        # Image ƒë·ªÉ v·∫Ω (n·ªÅn ƒëen)
        self.image = Image.new('L', (self.canvas_size, self.canvas_size), color=0)
        self.draw = ImageDraw.Draw(self.image)
        
        # Bi·∫øn l∆∞u v·ªã tr√≠ chu·ªôt tr∆∞·ªõc ƒë√≥
        self.last_x = None
        self.last_y = None
        
        self.setup_ui()
    
    def setup_ui(self):
        """Thi·∫øt l·∫≠p giao di·ªán."""
        # Main frame
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.pack(fill=tk.BOTH, expand=True)
        
        # Title
        title_label = ttk.Label(main_frame, text="üî¢ Nh·∫≠n d·∫°ng Ch·ªØ s·ªë Vi·∫øt tay", 
                                font=('Segoe UI', 18, 'bold'))
        title_label.pack(pady=(0, 10))
        
        subtitle_label = ttk.Label(main_frame, 
                                   text="V·∫Ω m·ªôt ch·ªØ s·ªë (0-9) tr√™n canvas b√™n tr√°i, sau ƒë√≥ nh·∫•n 'Nh·∫≠n d·∫°ng'",
                                   font=('Segoe UI', 10))
        subtitle_label.pack(pady=(0, 10))
        
        # Content frame (ch·ª©a canvas v√† k·∫øt qu·∫£)
        content_frame = ttk.Frame(main_frame)
        content_frame.pack(fill=tk.BOTH, expand=True)
        
        # Left frame - Canvas v·∫Ω
        left_frame = ttk.LabelFrame(content_frame, text="‚úèÔ∏è V·∫Ω ch·ªØ s·ªë", padding="10")
        left_frame.pack(side=tk.LEFT, fill=tk.BOTH, padx=(0, 10))
        
        # Canvas ƒë·ªÉ v·∫Ω
        self.canvas = tk.Canvas(left_frame, width=self.canvas_size, height=self.canvas_size,
                                bg='black', cursor='cross', highlightthickness=2,
                                highlightbackground='#3498db')
        self.canvas.pack()
        
        # Bind mouse events
        self.canvas.bind('<Button-1>', self.start_draw)
        self.canvas.bind('<B1-Motion>', self.draw_on_canvas)
        self.canvas.bind('<ButtonRelease-1>', self.stop_draw)
        
        # Buttons frame
        btn_frame = ttk.Frame(left_frame)
        btn_frame.pack(pady=10, fill=tk.X)
        
        # Style cho buttons
        style = ttk.Style()
        style.configure('Primary.TButton', font=('Segoe UI', 11, 'bold'))
        style.configure('Secondary.TButton', font=('Segoe UI', 10))
        
        predict_btn = ttk.Button(btn_frame, text="üîç Nh·∫≠n d·∫°ng", 
                                 command=self.predict, style='Primary.TButton')
        predict_btn.pack(side=tk.LEFT, padx=5, expand=True, fill=tk.X)
        
        clear_btn = ttk.Button(btn_frame, text="üóëÔ∏è X√≥a", 
                               command=self.clear_canvas, style='Secondary.TButton')
        clear_btn.pack(side=tk.LEFT, padx=5, expand=True, fill=tk.X)
        
        # Th√™m h√†ng n√∫t th·ª© hai
        btn_frame2 = ttk.Frame(left_frame)
        btn_frame2.pack(pady=5, fill=tk.X)
        
        upload_btn = ttk.Button(btn_frame2, text="üìÇ T·∫£i ·∫£nh l√™n", 
                                command=self.upload_image, style='Secondary.TButton')
        upload_btn.pack(side=tk.LEFT, padx=5, expand=True, fill=tk.X)
        
        test_btn = ttk.Button(btn_frame2, text="üé≤ Test MNIST", 
                              command=self.test_mnist_sample, style='Secondary.TButton')
        test_btn.pack(side=tk.LEFT, padx=5, expand=True, fill=tk.X)
        
        # Slider ƒë·ªÉ ƒëi·ªÅu ch·ªânh ƒë·ªô d√†y n√©t (dilation) - quan tr·ªçng cho n√©t b√∫t m·ªèng
        dilate_frame = ttk.LabelFrame(left_frame, text="‚úèÔ∏è ƒê·ªô d√†y n√©t (cho ·∫£nh upload)", padding="5")
        dilate_frame.pack(pady=5, fill=tk.X)
        
        dilate_label = ttk.Label(dilate_frame, 
                                 text="TƒÉng l√™n 4-6 n·∫øu n√©t b√∫t M·ªéNG tr√™n gi·∫•y tr·∫Øng:")
        dilate_label.pack()
        
        dilate_slider = ttk.Scale(dilate_frame, from_=0, to=8, 
                                  variable=self.dilate_iterations, 
                                  orient=tk.HORIZONTAL)
        dilate_slider.pack(fill=tk.X, padx=5)
        
        self.dilate_value_label = ttk.Label(dilate_frame, text="M·ª©c: 3 (m·∫∑c ƒë·ªãnh)")
        self.dilate_value_label.pack()
        
        def update_dilate_label(*args):
            val = self.dilate_iterations.get()
            hint = ""
            if val <= 2:
                hint = " (n√©t ƒë·∫≠m)"
            elif val <= 4:
                hint = " (b√¨nh th∆∞·ªùng)"
            else:
                hint = " (n√©t r·∫•t m·ªèng)"
            self.dilate_value_label.config(text=f"M·ª©c: {val}{hint}")
        
        self.dilate_iterations.trace_add("write", update_dilate_label)
        
        # Right frame - K·∫øt qu·∫£
        right_frame = ttk.LabelFrame(content_frame, text="üìä K·∫øt qu·∫£", padding="10")
        right_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        # Result text
        self.result_label = ttk.Label(right_frame, text="V·∫Ω m·ªôt ch·ªØ s·ªë v√† nh·∫•n 'Nh·∫≠n d·∫°ng'",
                                      font=('Segoe UI', 12), wraplength=400)
        self.result_label.pack(pady=(0, 10))
        
        # Prediction display
        self.prediction_frame = ttk.Frame(right_frame)
        self.prediction_frame.pack(pady=10)
        
        self.prediction_label = ttk.Label(self.prediction_frame, text="?", 
                                          font=('Segoe UI', 72, 'bold'),
                                          foreground='#3498db')
        self.prediction_label.pack()
        
        self.confidence_label = ttk.Label(self.prediction_frame, text="",
                                          font=('Segoe UI', 14))
        self.confidence_label.pack()
        
        # Chart frame
        self.chart_frame = ttk.Frame(right_frame)
        self.chart_frame.pack(fill=tk.BOTH, expand=True, pady=10)
        
        # Processed image frame
        processed_frame = ttk.LabelFrame(left_frame, text="·∫¢nh sau x·ª≠ l√Ω (28x28)", padding="5")
        processed_frame.pack(pady=10)
        
        self.processed_label = ttk.Label(processed_frame)
        self.processed_label.pack()
    
    def start_draw(self, event):
        """B·∫Øt ƒë·∫ßu v·∫Ω."""
        self.last_x = event.x
        self.last_y = event.y
    
    def draw_on_canvas(self, event):
        """V·∫Ω tr√™n canvas."""
        if self.last_x and self.last_y:
            # V·∫Ω tr√™n Tkinter canvas
            self.canvas.create_line(self.last_x, self.last_y, event.x, event.y,
                                    fill='white', width=self.brush_size, 
                                    capstyle=tk.ROUND, smooth=True)
            
            # V·∫Ω tr√™n PIL Image
            self.draw.line([self.last_x, self.last_y, event.x, event.y],
                          fill=255, width=self.brush_size)
            
        self.last_x = event.x
        self.last_y = event.y
    
    def stop_draw(self, event):
        """D·ª´ng v·∫Ω."""
        self.last_x = None
        self.last_y = None
    
    def clear_canvas(self):
        """X√≥a canvas."""
        self.canvas.delete('all')
        self.image = Image.new('L', (self.canvas_size, self.canvas_size), color=0)
        self.draw = ImageDraw.Draw(self.image)
        
        # Reset k·∫øt qu·∫£
        self.prediction_label.config(text="?", foreground='#3498db')
        self.confidence_label.config(text="")
        self.result_label.config(text="V·∫Ω m·ªôt ch·ªØ s·ªë v√† nh·∫•n 'Nh·∫≠n d·∫°ng'")
        
        # Clear chart
        for widget in self.chart_frame.winfo_children():
            widget.destroy()
        
        # Clear processed image
        self.processed_label.config(image='')
    
    def preprocess_image(self, img_array):
        """Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·ªÉ kh·ªõp v·ªõi MNIST."""
        # T√¨m bounding box c·ªßa ch·ªØ s·ªë
        threshold = 20
        coords = np.where(img_array > threshold)
        
        if len(coords[0]) > 0 and len(coords[1]) > 0:
            y_min, y_max = coords[0].min(), coords[0].max()
            x_min, x_max = coords[1].min(), coords[1].max()
            
            # C·∫Øt v√πng ch·ª©a ch·ªØ s·ªë
            digit_region = img_array[y_min:y_max+1, x_min:x_max+1]
            
            # Resize v·ªÅ 20x20
            digit_img = Image.fromarray(digit_region.astype(np.uint8))
            
            # Gi·ªØ t·ª∑ l·ªá
            aspect = digit_region.shape[1] / digit_region.shape[0]
            if aspect > 1:
                new_width = 20
                new_height = max(1, int(20 / aspect))
            else:
                new_height = 20
                new_width = max(1, int(20 * aspect))
            
            digit_img = digit_img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # T·∫°o ·∫£nh 28x28 v·ªõi n·ªÅn ƒëen v√† ƒë·∫∑t ch·ªØ s·ªë v√†o gi·ªØa
            final_array = np.zeros((28, 28), dtype=np.float64)
            
            y_offset = (28 - new_height) // 2
            x_offset = (28 - new_width) // 2
            
            final_array[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = np.array(digit_img)
            
            return final_array
        else:
            # Resize ƒë∆°n gi·∫£n
            img = Image.fromarray(img_array.astype(np.uint8))
            img = img.resize((28, 28), Image.Resampling.LANCZOS)
            return np.array(img, dtype=np.float64)
    
    def predict(self):
        """D·ª± ƒëo√°n ch·ªØ s·ªë."""
        # L·∫•y ·∫£nh t·ª´ PIL Image
        img_array = np.array(self.image, dtype=np.float64)
        
        # Ki·ªÉm tra xem c√≥ v·∫Ω g√¨ kh√¥ng
        if img_array.max() < 10:
            messagebox.showwarning("C·∫£nh b√°o", "Vui l√≤ng v·∫Ω m·ªôt ch·ªØ s·ªë tr∆∞·ªõc!")
            return
        
        # Ti·ªÅn x·ª≠ l√Ω
        processed = self.preprocess_image(img_array)
        
        # Chu·∫©n h√≥a v√† flatten
        img_flat = (processed / 255.0).reshape(1, -1)
        
        # D·ª± ƒëo√°n
        prediction = self.model.predict(img_flat)[0]
        probabilities = self.model.predict_proba(img_flat)[0]
        confidence = probabilities[prediction]
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        self.prediction_label.config(text=str(prediction), foreground='#27ae60')
        self.confidence_label.config(text=f"ƒê·ªô tin c·∫≠y: {confidence:.1%}")
        
        # Top 3
        top3_idx = np.argsort(probabilities)[::-1][:3]
        result_text = "Top 3 d·ª± ƒëo√°n:\n"
        for i, idx in enumerate(top3_idx):
            emoji = "ü•á" if i == 0 else "ü•à" if i == 1 else "ü•â"
            result_text += f"{emoji} Ch·ªØ s·ªë {idx}: {probabilities[idx]:.1%}\n"
        self.result_label.config(text=result_text)
        
        # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
        self.show_probability_chart(probabilities)
        
        # Hi·ªÉn th·ªã ·∫£nh ƒë√£ x·ª≠ l√Ω
        self.show_processed_image(processed)
    
    def show_probability_chart(self, probabilities):
        """Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì x√°c su·∫•t."""
        # Clear previous chart
        for widget in self.chart_frame.winfo_children():
            widget.destroy()
        
        # T·∫°o figure
        fig, ax = plt.subplots(figsize=(5, 2.5), dpi=80)
        
        colors = ['#3498db' if p < max(probabilities) else '#e74c3c' for p in probabilities]
        bars = ax.bar(range(10), probabilities, color=colors)
        
        ax.set_xlabel('Ch·ªØ s·ªë', fontsize=9)
        ax.set_ylabel('X√°c su·∫•t', fontsize=9)
        ax.set_xticks(range(10))
        ax.set_ylim([0, 1])
        ax.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        
        # Embed v√†o Tkinter
        canvas = FigureCanvasTkAgg(fig, master=self.chart_frame)
        canvas.draw()
        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        plt.close(fig)
    
    def show_processed_image(self, processed):
        """Hi·ªÉn th·ªã ·∫£nh ƒë√£ x·ª≠ l√Ω."""
        # Scale l√™n ƒë·ªÉ d·ªÖ nh√¨n
        img = Image.fromarray(processed.astype(np.uint8))
        img = img.resize((84, 84), Image.Resampling.NEAREST)
        
        photo = ImageTk.PhotoImage(img)
        self.processed_label.config(image=photo)
        self.processed_label.image = photo  # Gi·ªØ reference
    
    def test_mnist_sample(self):
        """Test v·ªõi m·∫´u ng·∫´u nhi√™n t·ª´ MNIST."""
        from sklearn.datasets import fetch_openml
        
        self.result_label.config(text="ƒêang t·∫£i m·∫´u MNIST...")
        self.root.update()
        
        try:
            X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, parser='auto')
            
            # L·∫•y ng·∫´u nhi√™n m·ªôt m·∫´u
            idx = np.random.randint(0, len(X))
            sample = X[idx].reshape(28, 28)
            true_label = int(y[idx])
            
            # D·ª± ƒëo√°n
            img_flat = X[idx].reshape(1, -1).astype(np.float64) / 255.0
            prediction = self.model.predict(img_flat)[0]
            probabilities = self.model.predict_proba(img_flat)[0]
            confidence = probabilities[prediction]
            
            # Hi·ªÉn th·ªã tr√™n canvas
            self.clear_canvas()
            
            # Scale sample l√™n ƒë·ªÉ v·∫Ω tr√™n canvas
            sample_scaled = Image.fromarray(sample.astype(np.uint8))
            sample_scaled = sample_scaled.resize((self.canvas_size, self.canvas_size), 
                                                  Image.Resampling.NEAREST)
            photo = ImageTk.PhotoImage(sample_scaled)
            self.canvas.create_image(0, 0, anchor=tk.NW, image=photo)
            self.canvas.image = photo  # Gi·ªØ reference
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            is_correct = prediction == true_label
            color = '#27ae60' if is_correct else '#e74c3c'
            self.prediction_label.config(text=str(prediction), foreground=color)
            self.confidence_label.config(text=f"ƒê·ªô tin c·∫≠y: {confidence:.1%}")
            
            result_text = f"Nh√£n th·ª±c t·∫ø: {true_label}\n"
            result_text += f"D·ª± ƒëo√°n: {prediction}\n"
            result_text += f"K·∫øt qu·∫£: {'‚úÖ ƒê√∫ng!' if is_correct else '‚ùå Sai!'}"
            self.result_label.config(text=result_text)
            
            # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
            self.show_probability_chart(probabilities)
            
            # Hi·ªÉn th·ªã ·∫£nh ƒë√£ x·ª≠ l√Ω
            self.show_processed_image(sample)
            
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ t·∫£i MNIST: {str(e)}")
    
    def upload_image(self):
        """Upload v√† nh·∫≠n d·∫°ng ·∫£nh t·ª´ m√°y t√≠nh."""
        # M·ªü dialog ch·ªçn file
        file_types = [
            ("Image files", "*.png *.jpg *.jpeg *.bmp *.gif *.tiff *.webp"),
            ("PNG files", "*.png"),
            ("JPEG files", "*.jpg *.jpeg"),
            ("All files", "*.*")
        ]
        
        file_path = filedialog.askopenfilename(
            title="Ch·ªçn ·∫£nh ch·ªØ s·ªë",
            filetypes=file_types,
            initialdir=os.getcwd()
        )
        
        if not file_path:
            return  # Ng∆∞·ªùi d√πng h·ªßy
        
        try:
            self.result_label.config(text=f"ƒêang x·ª≠ l√Ω: {os.path.basename(file_path)}...")
            self.root.update()
            
            # ƒê·ªçc v√† ti·ªÅn x·ª≠ l√Ω ·∫£nh (s·ª≠ d·ª•ng dilate_iterations t·ª´ slider)
            processed = self.load_and_preprocess_uploaded_image(
                file_path, 
                dilate_iterations=self.dilate_iterations.get()
            )
            
            # Chu·∫©n h√≥a v√† flatten
            img_flat = (processed / 255.0).reshape(1, -1)
            
            # D·ª± ƒëo√°n
            prediction = self.model.predict(img_flat)[0]
            probabilities = self.model.predict_proba(img_flat)[0]
            confidence = probabilities[prediction]
            
            # X√≥a canvas v√† hi·ªÉn th·ªã ·∫£nh ƒë√£ upload
            self.clear_canvas()
            
            # Hi·ªÉn th·ªã ·∫£nh g·ªëc (scale ƒë·ªÉ fit canvas)
            original_img = Image.open(file_path).convert('L')
            # Scale ƒë·ªÉ fit v√†o canvas nh∆∞ng gi·ªØ t·ª∑ l·ªá
            orig_w, orig_h = original_img.size
            scale = min(self.canvas_size / orig_w, self.canvas_size / orig_h)
            new_w, new_h = int(orig_w * scale), int(orig_h * scale)
            original_scaled = original_img.resize((new_w, new_h), Image.Resampling.LANCZOS)
            
            # T·∫°o ·∫£nh n·ªÅn ƒëen v·ªõi ·∫£nh ·ªü gi·ªØa
            display_img = Image.new('L', (self.canvas_size, self.canvas_size), color=0)
            x_offset = (self.canvas_size - new_w) // 2
            y_offset = (self.canvas_size - new_h) // 2
            display_img.paste(original_scaled, (x_offset, y_offset))
            
            photo = ImageTk.PhotoImage(display_img)
            self.canvas.create_image(0, 0, anchor=tk.NW, image=photo)
            self.canvas.image = photo  # Gi·ªØ reference
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            self.prediction_label.config(text=str(prediction), foreground='#27ae60')
            self.confidence_label.config(text=f"ƒê·ªô tin c·∫≠y: {confidence:.1%}")
            
            # Top 3
            top3_idx = np.argsort(probabilities)[::-1][:3]
            result_text = f"üìÇ File: {os.path.basename(file_path)}\n\n"
            result_text += "Top 3 d·ª± ƒëo√°n:\n"
            for i, idx in enumerate(top3_idx):
                emoji = "ü•á" if i == 0 else "ü•à" if i == 1 else "ü•â"
                result_text += f"{emoji} Ch·ªØ s·ªë {idx}: {probabilities[idx]:.1%}\n"
            self.result_label.config(text=result_text)
            
            # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
            self.show_probability_chart(probabilities)
            
            # Hi·ªÉn th·ªã ·∫£nh ƒë√£ x·ª≠ l√Ω (28x28)
            self.show_processed_image(processed)
            
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh: {str(e)}")
    
    def load_and_preprocess_uploaded_image(self, image_path, dilate_iterations=3):
        """
        T·∫£i v√† ti·ªÅn x·ª≠ l√Ω ·∫£nh t·ª´ file ƒë·ªÉ ph√π h·ª£p v·ªõi MNIST.
        
        ƒê·∫∂C BI·ªÜT T·ªêI ∆ØU CHO N√âT B√öT M·ªéNG TR√äN GI·∫§Y TR·∫ÆNG!
        
        S·ª≠ d·ª•ng thu·∫≠t to√°n m·ªõi v·ªõi:
        - Otsu thresholding t·ª± ƒë·ªông
        - Binarization m·∫°nh
        - Morphological operations ƒë√∫ng th·ª© t·ª±
        
        Parameters:
        -----------
        image_path : str
            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ·∫£nh
        dilate_iterations : int
            S·ªë l·∫ßn l√†m d√†y n√©t ch·ªØ (m·∫∑c ƒë·ªãnh 3, tƒÉng l√™n 4-6 n·∫øu n√©t r·∫•t m·ªèng)
        """
        from PIL import ImageFilter, ImageOps, ImageEnhance
        
        # ƒê·ªçc ·∫£nh v√† chuy·ªÉn sang grayscale
        img = Image.open(image_path).convert('L')
        img_array = np.array(img, dtype=np.float64)
        original_shape = img_array.shape
        
        # =====================================================================
        # B∆Ø·ªöC 1: ƒê·∫¢O NG∆Ø·ª¢C M√ÄU N·∫æU N·ªÄN S√ÅNG (L√ÄM ƒê·∫¶U TI√äN!)
        # =====================================================================
        h, w = img_array.shape
        # L·∫•y m·∫´u t·ª´ vi·ªÅn
        border_samples = []
        border_samples.extend(img_array[0, :].tolist())
        border_samples.extend(img_array[-1, :].tolist())
        border_samples.extend(img_array[:, 0].tolist())
        border_samples.extend(img_array[:, -1].tolist())
        background_value = np.median(border_samples)
        
        if background_value > 127:
            img_array = 255 - img_array
        
        # =====================================================================
        # B∆Ø·ªöC 2: OTSU THRESHOLDING ƒê·ªÇ T√åM NG∆Ø·ª†NG T·ªêI ∆ØU
        # =====================================================================
        def otsu_threshold(image):
            hist, _ = np.histogram(image.flatten(), bins=256, range=(0, 256))
            total = image.size
            sum_total = np.sum(np.arange(256) * hist)
            sum_bg, weight_bg = 0, 0
            max_var, threshold = 0, 0
            
            for i in range(256):
                weight_bg += hist[i]
                if weight_bg == 0:
                    continue
                weight_fg = total - weight_bg
                if weight_fg == 0:
                    break
                sum_bg += i * hist[i]
                mean_bg = sum_bg / weight_bg
                mean_fg = (sum_total - sum_bg) / weight_fg
                var_between = weight_bg * weight_fg * (mean_bg - mean_fg) ** 2
                if var_between > max_var:
                    max_var = var_between
                    threshold = i
            return threshold
        
        otsu_thresh = otsu_threshold(img_array)
        adjusted_thresh = max(10, otsu_thresh * 0.5)
        
        # =====================================================================
        # B∆Ø·ªöC 3: TƒÇNG CONTRAST
        # =====================================================================
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        img_pil = ImageOps.autocontrast(img_pil, cutoff=0)
        enhancer = ImageEnhance.Contrast(img_pil)
        img_pil = enhancer.enhance(1.5)
        img_array = np.array(img_pil, dtype=np.float64)
        
        # =====================================================================
        # B∆Ø·ªöC 4: BINARIZATION - CHUY·ªÇN TH√ÄNH ƒêEN TR·∫ÆNG R√ï R√ÄNG
        # S·ª≠ d·ª•ng percentile ƒë·ªÉ t√¨m ng∆∞·ª°ng t·ªët h∆°n
        # =====================================================================
        non_zero = img_array[img_array > 5]
        if len(non_zero) > 100:
            p10 = np.percentile(non_zero, 10)
            p90 = np.percentile(non_zero, 90)
            binary_thresh = p10 + (p90 - p10) * 0.3
            binary_thresh = max(25, min(100, binary_thresh))
        else:
            binary_thresh = otsu_thresh * 0.5
        
        binary_mask = img_array > binary_thresh
        img_array = np.where(binary_mask, 255, 0).astype(np.float64)
        
        # =====================================================================
        # B∆Ø·ªöC 5: L√ÄM D√ÄY N√âT CH·ªÆ (DILATION)
        # =====================================================================
        if dilate_iterations > 0:
            img_pil = Image.fromarray(img_array.astype(np.uint8))
            
            scale_factor = max(original_shape) / 200.0
            adjusted_iterations = max(dilate_iterations, int(dilate_iterations * scale_factor * 0.7))
            adjusted_iterations = min(adjusted_iterations, 10)
            
            for _ in range(adjusted_iterations):
                img_pil = img_pil.filter(ImageFilter.MaxFilter(size=3))
            
            img_array = np.array(img_pil, dtype=np.float64)
        
        # =====================================================================
        # B∆Ø·ªöC 6: MORPHOLOGICAL CLOSING (Max r·ªìi Min - ƒê√öNG TH·ª® T·ª∞!)
        # =====================================================================
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        img_pil = img_pil.filter(ImageFilter.MaxFilter(size=3))
        img_pil = img_pil.filter(ImageFilter.MinFilter(size=3))
        img_array = np.array(img_pil, dtype=np.float64)
        
        # =====================================================================
        # B∆Ø·ªöC 7: T√åM BOUNDING BOX V√Ä CƒÇN GI·ªÆA
        # =====================================================================
        threshold_for_bbox = 30
        coords = np.where(img_array > threshold_for_bbox)
        
        if len(coords[0]) > 0 and len(coords[1]) > 0:
            y_min, y_max = coords[0].min(), coords[0].max()
            x_min, x_max = coords[1].min(), coords[1].max()
            
            padding = 5
            y_min = max(0, y_min - padding)
            y_max = min(img_array.shape[0] - 1, y_max + padding)
            x_min = max(0, x_min - padding)
            x_max = min(img_array.shape[1] - 1, x_max + padding)
            
            digit_region = img_array[y_min:y_max+1, x_min:x_max+1]
            digit_img = Image.fromarray(digit_region.astype(np.uint8))
            
            h, w = digit_region.shape
            aspect = w / h
            if aspect > 1:
                new_width = 20
                new_height = max(1, int(20 / aspect))
            else:
                new_height = 20
                new_width = max(1, int(20 * aspect))
            
            digit_img = digit_img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            final_array = np.zeros((28, 28), dtype=np.float64)
            y_offset = (28 - new_height) // 2
            x_offset = (28 - new_width) // 2
            
            resized_digit = np.array(digit_img, dtype=np.float64)
            final_array[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = resized_digit
            
            img_array = final_array
        else:
            img = Image.fromarray(img_array.astype(np.uint8))
            img = img.resize((28, 28), Image.Resampling.LANCZOS)
            img_array = np.array(img, dtype=np.float64)
        
        # =====================================================================
        # B∆Ø·ªöC 8: ƒêI·ªÄU CH·ªàNH ƒê·ªò D√ÄY N√âT PH√ô H·ª¢P V·ªöI MNIST
        # MNIST c√≥ kho·∫£ng 100-180 pixels stroke
        # =====================================================================
        current_pixels = np.count_nonzero(img_array > 25)
        target_min_pixels = 80
        target_max_pixels = 200
        
        img_pil = Image.fromarray(img_array.astype(np.uint8))
        
        if current_pixels < target_min_pixels:
            # N√©t qu√° m·ªèng, dilate th√™m
            while current_pixels < target_min_pixels:
                img_pil = img_pil.filter(ImageFilter.MaxFilter(size=3))
                temp_array = np.array(img_pil, dtype=np.float64)
                current_pixels = np.count_nonzero(temp_array > 25)
                if current_pixels >= target_max_pixels:
                    break
                    
        elif current_pixels > target_max_pixels:
            # N√©t qu√° d√†y, erosion ƒë·ªÉ l√†m m·ªèng
            erosion_count = 0
            while current_pixels > target_max_pixels and erosion_count < 3:
                img_pil = img_pil.filter(ImageFilter.MinFilter(size=3))
                temp_array = np.array(img_pil, dtype=np.float64)
                current_pixels = np.count_nonzero(temp_array > 25)
                erosion_count += 1
                if current_pixels < target_min_pixels:
                    img_pil = img_pil.filter(ImageFilter.MaxFilter(size=3))
                    break
        
        img_array = np.array(img_pil, dtype=np.float64)
        
        # =====================================================================
        # B∆Ø·ªöC 9: ƒê·∫¢M B·∫¢O ƒê·ªò S√ÅNG PH√ô H·ª¢P V·ªöI MNIST
        # =====================================================================
        if img_array.max() > 0:
            stroke_mask = img_array > 25
            if np.any(stroke_mask):
                current_mean = img_array[stroke_mask].mean()
                target_mean = 185  # MNIST stroke mean * 255 ‚âà 0.72 * 255
                if abs(current_mean - target_mean) > 25:
                    scale_factor = target_mean / max(current_mean, 1)
                    scale_factor = np.clip(scale_factor, 0.7, 1.5)
                    img_array = np.where(stroke_mask, img_array * scale_factor, img_array)
                    img_array = np.clip(img_array, 0, 255)
        
        return img_array


# ============================================================================
# CH·∫†Y ·ª®NG D·ª§NG
# ============================================================================

if __name__ == "__main__":
    print("="*60)
    print("üî¢ ·ª®NG D·ª§NG DESKTOP NH·∫¨N D·∫†NG CH·ªÆ S·ªê VI·∫æT TAY")
    print("="*60)
    
    # T·∫£i model
    model = load_model()
    print("‚úÖ Model ƒë√£ s·∫µn s√†ng!")
    
    # T·∫°o v√† ch·∫°y ·ª©ng d·ª•ng
    print("\nüöÄ Kh·ªüi ƒë·ªông ·ª©ng d·ª•ng desktop...")
    root = tk.Tk()
    app = DigitRecognitionApp(root, model)
    root.mainloop()
