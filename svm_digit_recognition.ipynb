{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mục tiêu của notebook này (để trình bày với giảng viên)\n",
        "\n",
        "Notebook này xây dựng **bộ phân loại chữ số viết tay (0–9)** trên bộ dữ liệu **MNIST** bằng **SVM (Support Vector Machine)**.\n",
        "\n",
        "### Bạn sẽ làm được gì sau khi chạy notebook\n",
        "- **Hiểu dữ liệu MNIST**: ảnh xám 28×28, mỗi ảnh được “trải phẳng” thành vector 784 chiều.\n",
        "- **Thực hiện tiền xử lý**: chuẩn hoá giá trị pixel về [0, 1], chia train/test, (tuỳ chọn) lấy tập con để chạy nhanh.\n",
        "- **Huấn luyện SVM** với các cấu hình:\n",
        "  - **RBF kernel** (phi tuyến)\n",
        "  - **Linear kernel** (tuyến tính)\n",
        "  - **RBF + PCA** (giảm chiều trước khi SVM)\n",
        "- **Đánh giá mô hình**: accuracy, classification report (precision/recall/F1), confusion matrix, xem các mẫu đoán sai.\n",
        "- **Tối ưu tham số** bằng **GridSearchCV** và so sánh.\n",
        "- **Xuất xác suất dự đoán** (predict_proba) để dùng cho **ensemble** và **lưu model** bằng joblib.\n",
        "\n",
        "### “Kịch bản nói” gợi ý (1–2 phút)\n",
        "1) *Bài toán*: Nhận dạng chữ số từ ảnh (classification 10 lớp).\n",
        "2) *Dữ liệu*: MNIST 70k ảnh, 28×28 → vector 784, label 0–9.\n",
        "3) *Tiền xử lý*: đưa pixel về [0,1], sau đó chuẩn hoá theo mean/variance (StandardScaler) vì SVM nhạy với scale.\n",
        "4) *Mô hình*: SVM tìm siêu phẳng tối ưu; dùng kernel để xử lý phi tuyến (RBF).\n",
        "5) *Tối ưu*: thử nhiều C/gamma/kernel bằng GridSearchCV, chọn cấu hình tốt nhất.\n",
        "6) *Kết quả*: báo cáo accuracy + ma trận nhầm lẫn; lưu model và xuất xác suất để ghép ensemble.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kiến thức nền cần nắm (giải thích theo kiểu “thuyết trình”)\n",
        "\n",
        "### 1) MNIST là gì?\n",
        "- **MNIST** gồm khoảng **70,000** ảnh chữ số viết tay (0–9):\n",
        "  - 60,000 train + 10,000 test (OpenML có thể trả về 70k rồi ta tự chia).\n",
        "- Mỗi ảnh là **ảnh xám 28×28**.\n",
        "- Khi dùng scikit-learn, ảnh thường được biểu diễn dưới dạng vector **784 chiều** (28×28) bằng cách “trải phẳng”.\n",
        "\n",
        "### 2) SVM (Support Vector Machine) giải bài toán classification như thế nào?\n",
        "- SVM cố gắng tìm **siêu phẳng phân tách** sao cho **biên (margin) lớn nhất**.\n",
        "- Với dữ liệu *không tách tuyến tính*, SVM dùng **kernel trick** để “ngầm” ánh xạ dữ liệu sang không gian cao hơn, nơi có thể tách được.\n",
        "\n",
        "### 3) Những tham số quan trọng nhất khi dùng SVM\n",
        "- **kernel**:\n",
        "  - `linear`: đường/siêu phẳng tuyến tính. Nhanh, hợp khi dữ liệu gần tuyến tính hoặc số chiều rất lớn.\n",
        "  - `rbf`: phi tuyến, phổ biến cho bài toán ảnh nhưng tốn tài nguyên hơn.\n",
        "- **C** (regularization strength):\n",
        "  - C lớn → phạt lỗi mạnh → cố gắng fit đúng train → nguy cơ overfit.\n",
        "  - C nhỏ → cho phép một số lỗi → margin rộng hơn → tổng quát tốt hơn.\n",
        "- **gamma** (độ “cục bộ” của RBF):\n",
        "  - gamma lớn → ảnh hưởng rất cục bộ → dễ overfit.\n",
        "  - gamma nhỏ → ảnh hưởng rộng → mô hình “mượt” hơn.\n",
        "  - `gamma='scale'` là lựa chọn an toàn mặc định của sklearn.\n",
        "\n",
        "### 4) Vì sao cần chuẩn hoá (scaling)?\n",
        "- SVM dựa trên **khoảng cách** giữa các điểm → nếu feature có thang đo khác nhau sẽ làm sai lệch khoảng cách.\n",
        "- Vì vậy pipeline thường là: **StandardScaler → (PCA) → SVM**.\n",
        "\n",
        "### 5) Vì sao cần PCA?\n",
        "- MNIST có 784 chiều; PCA giúp:\n",
        "  - giảm chiều → giảm thời gian train/predict\n",
        "  - lọc nhiễu và giữ phần “quan trọng” (variance lớn)\n",
        "- Nhưng PCA có thể làm mất thông tin, nên cần so sánh accuracy và thời gian.\n",
        "\n",
        "### 6) Đánh giá mô hình\n",
        "- **Accuracy**: tỉ lệ dự đoán đúng.\n",
        "- **Precision/Recall/F1**: quan trọng khi các lớp mất cân bằng (MNIST thường khá cân bằng).\n",
        "- **Confusion matrix**: xem mô hình hay nhầm chữ số nào với chữ số nào.\n",
        "\n",
        "### 7) Vì sao có `probability=True`?\n",
        "- SVM “gốc” không trả xác suất; `probability=True` bật bước hiệu chỉnh (thường là **Platt scaling**) để có `predict_proba`.\n",
        "- Đổi lại: training có thể chậm hơn, nhưng hữu ích cho **ensemble**.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import subprocess\n",
        "try:\n",
        "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "    print(result.stdout)\n",
        "    GPU_AVAILABLE = True\n",
        "except:\n",
        "    print('Không tìm thấy GPU')\n",
        "    GPU_AVAILABLE = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Ghi chú môi trường chạy (CPU/GPU)\n",
        "\n",
        "- Notebook có đoạn kiểm tra `nvidia-smi` để biết máy có GPU NVIDIA hay không.\n",
        "- Nếu có thể import **cuML** (thư viện RAPIDS), notebook có thể dùng các phiên bản GPU của:\n",
        "  - `StandardScaler`, `PCA`, `SVC`\n",
        "- Nếu không có cuML thì sẽ tự động dùng **scikit-learn (CPU)**.\n",
        "\n",
        "### Khi trình bày\n",
        "- Bạn có thể nói: *“Mình viết code theo hướng linh hoạt: nếu môi trường có GPU + cuML thì tăng tốc, còn không thì vẫn chạy được trên CPU.”*\n",
        "- Lưu ý: SVM RBF trên tập dữ liệu lớn có thể rất chậm; vì vậy notebook có cơ chế dùng **subset** để thử nghiệm nhanh.\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from time import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "try:\n",
        "    from cuml.svm import SVC as cuSVC\n",
        "    from cuml.preprocessing import StandardScaler as cuStandardScaler\n",
        "    from cuml.decomposition import PCA as cuPCA\n",
        "    CUML_AVAILABLE = True\n",
        "    print(' cuML đã được import thành công - Sử dụng GPU acceleration!')\n",
        "except ImportError:\n",
        "    CUML_AVAILABLE = False\n",
        "    print(' cuML không khả dụng - Sử dụng sklearn (CPU)')\n",
        "import joblib\n",
        "print(f'\\n Cấu hình:')\n",
        "print(f'   - GPU Available: {GPU_AVAILABLE}')\n",
        "print(f'   - cuML Available: {CUML_AVAILABLE}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Chuẩn bị dữ liệu và Tiền xử lý\n",
        "\n",
        "### Vì sao cần bước này?\n",
        "- **Load dữ liệu** từ OpenML: lấy `X` (ma trận đặc trưng) và `y` (nhãn 0–9).\n",
        "- **Quan sát ảnh mẫu**: kiểm tra reshape đúng 28×28 và nhãn đi kèm hợp lý.\n",
        "- **Chuẩn hoá pixel**: từ [0,255] → [0,1] để mô hình học ổn định hơn.\n",
        "- **Chia train/test có stratify**: đảm bảo phân bố các lớp 0–9 ở train/test tương đồng.\n",
        "\n",
        "### Các khái niệm bạn cần nói rõ\n",
        "- `fetch_openml('mnist_784')`:\n",
        "  - `mnist_784` nghĩa là mỗi ảnh được biểu diễn bởi **784 feature** (28×28).\n",
        "  - Mỗi hàng của `X` là 1 ảnh → `X[i].reshape(28,28)` sẽ ra lại ảnh.\n",
        "- `y = y.astype(int)`:\n",
        "  - OpenML thường trả nhãn dạng chuỗi; ép kiểu sang int để tiện metric và xử lý.\n",
        "- Chuẩn hoá `X / 255.0`:\n",
        "  - Đây là **min-max đơn giản** theo pixel.\n",
        "  - Ở bước train SVM, ta vẫn dùng `StandardScaler` để chuẩn hoá theo mean/variance vì SVM rất nhạy với scale.\n",
        "\n",
        "### “Câu nói mẫu”\n",
        "- *“Em tải MNIST từ OpenML, kiểm tra nhanh một vài ảnh để chắc chắn dữ liệu đúng. Sau đó em đưa pixel về [0,1] và chia train/test theo stratify để giữ tỉ lệ mỗi chữ số.”*\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(' Đang tải dữ liệu MNIST...')\n",
        "start_time = time()\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, parser='auto')\n",
        "print(f' Tải xong trong {time() - start_time:.2f} giây')\n",
        "print(f'\\n Thông tin dữ liệu:')\n",
        "print(f'   - Shape của X: {X.shape}')\n",
        "print(f'   - Shape của y: {y.shape}')\n",
        "print(f'   - Số lượng lớp: {len(np.unique(y))}')\n",
        "print(f'   - Các lớp: {np.unique(y)}')\n",
        "print(f'   - Dtype của X: {X.dtype}')\n",
        "print(f'   - Range của pixel: [{X.min()}, {X.max()}]')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
        "fig.suptitle('Một số ảnh mẫu từ MNIST', fontsize=14)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(X[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(f'Label: {y[i]}')\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y = y.astype(int)\n",
        "print(' Chuẩn hóa dữ liệu...')\n",
        "X = X.astype(np.float32) / 255.0\n",
        "print(f'   - Dtype sau chuẩn hóa: {X.dtype}')\n",
        "print(f'   - Range sau chuẩn hóa: [{X.min():.2f}, {X.max():.2f}]')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10000, random_state=42, stratify=y)\n",
        "print(f' Chia dữ liệu:')\n",
        "print(f'   - Train: {X_train.shape[0]} mẫu')\n",
        "print(f'   - Test: {X_test.shape[0]} mẫu')\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(f'\\n Phân bố lớp trong tập train:')\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f'   Chữ số {label}: {count} mẫu ({count / len(y_train) * 100:.1f}%)')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "USE_SUBSET = True\n",
        "SUBSET_SIZE = 10000\n",
        "if USE_SUBSET:\n",
        "    print(f' Sử dụng tập con {SUBSET_SIZE} mẫu để thử nghiệm nhanh...')\n",
        "    from sklearn.model_selection import StratifiedShuffleSplit\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, train_size=SUBSET_SIZE, random_state=42)\n",
        "    for train_idx, _ in sss.split(X_train, y_train):\n",
        "        X_train_subset = X_train[train_idx]\n",
        "        y_train_subset = y_train[train_idx]\n",
        "    print(f'   - Tập train subset: {X_train_subset.shape[0]} mẫu')\n",
        "else:\n",
        "    X_train_subset = X_train\n",
        "    y_train_subset = y_train\n",
        "    print(f' Sử dụng toàn bộ {X_train.shape[0]} mẫu train')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Huấn luyện mô hình SVM\n",
        "\n",
        "### Tại sao chọn SVM cho MNIST?\n",
        "- MNIST là bài toán phân loại ảnh “cổ điển”, SVM (đặc biệt với **RBF**) có thể cho kết quả tốt khi feature tương đối đơn giản.\n",
        "- Điểm yếu: SVM (nhất là RBF) **tốn thời gian/memory** khi số mẫu lớn → notebook có tuỳ chọn **subset** để thử nhanh.\n",
        "\n",
        "### Pipeline huấn luyện trong notebook\n",
        "Ta dùng `Pipeline` để đảm bảo các bước tiền xử lý và mô hình được “gói” chung:\n",
        "1) `StandardScaler`: chuẩn hoá feature\n",
        "2) (tuỳ chọn) `PCA`: giảm chiều\n",
        "3) `SVC`: mô hình SVM\n",
        "\n",
        "**Lợi ích khi dùng Pipeline**\n",
        "- Tránh “data leakage”: scaler/PCA chỉ fit trên train rồi apply sang test.\n",
        "- Dễ GridSearch: đặt tham số dạng `svc__C`, `svc__gamma`, ...\n",
        "\n",
        "### Ý nghĩa các cấu hình được thử\n",
        "- **SVM RBF**: mô hình phi tuyến (thường mạnh hơn nhưng chậm hơn).\n",
        "- **SVM Linear**: nhanh hơn; đôi khi đủ tốt nếu dữ liệu gần tuyến tính.\n",
        "- **RBF + PCA**: giảm chiều để tăng tốc, đánh đổi một phần độ chính xác.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def train_svm(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    kernel='rbf',\n",
        "    C=1.0,\n",
        "    gamma='scale',\n",
        "    use_pca=False,\n",
        "    n_components=100,\n",
        "    use_gpu=False,\n",
        "):\n",
        "    \"\"\"Huấn luyện SVM theo dạng Pipeline.\n",
        "\n",
        "    Pipeline (chuẩn):\n",
        "      1) StandardScaler: chuẩn hoá mean=0, std=1 (SVM rất nhạy với scale)\n",
        "      2) (tuỳ chọn) PCA: giảm chiều để tăng tốc / giảm nhiễu\n",
        "      3) SVC: mô hình phân loại\n",
        "\n",
        "    Tham số quan trọng để giải thích khi thuyết trình:\n",
        "    - kernel: 'linear' hoặc 'rbf'\n",
        "    - C: mức phạt sai số (C lớn -> fit mạnh -> dễ overfit)\n",
        "    - gamma (với RBF): độ \"cục bộ\" của biên quyết định (gamma lớn -> dễ overfit)\n",
        "    - probability=True: bật khả năng trả xác suất (predict_proba) để dùng ensemble\n",
        "    \"\"\"\n",
        "\n",
        "    steps = []\n",
        "\n",
        "    # 1) Chuẩn hoá dữ liệu\n",
        "    # - Nếu có GPU + cuML: dùng cuStandardScaler để tăng tốc\n",
        "    # - Nếu không: dùng StandardScaler của sklearn\n",
        "    if use_gpu and CUML_AVAILABLE:\n",
        "        steps.append(('scaler', cuStandardScaler()))\n",
        "    else:\n",
        "        steps.append(('scaler', StandardScaler()))\n",
        "\n",
        "    # 2) (Tuỳ chọn) PCA để giảm chiều\n",
        "    if use_pca:\n",
        "        if use_gpu and CUML_AVAILABLE:\n",
        "            steps.append(('pca', cuPCA(n_components=n_components)))\n",
        "        else:\n",
        "            steps.append(('pca', PCA(n_components=n_components)))\n",
        "\n",
        "    # 3) Mô hình SVM\n",
        "    # - RBF thường mạnh hơn nhưng chậm hơn\n",
        "    # - Linear thường nhanh hơn, phù hợp khi dữ liệu gần tuyến tính\n",
        "    if use_gpu and CUML_AVAILABLE:\n",
        "        svm = cuSVC(kernel=kernel, C=C, gamma=gamma, probability=True)\n",
        "    else:\n",
        "        # cache_size tăng bộ nhớ cache cho kernel (giúp nhanh hơn trong một số trường hợp)\n",
        "        svm = SVC(kernel=kernel, C=C, gamma=gamma, probability=True, cache_size=1000)\n",
        "\n",
        "    steps.append(('svc', svm))\n",
        "    pipeline = Pipeline(steps)\n",
        "\n",
        "    print(' Bắt đầu huấn luyện SVM...')\n",
        "    print(f'   - Kernel: {kernel}')\n",
        "    print(f'   - C: {C}')\n",
        "    print(f'   - Gamma: {gamma}')\n",
        "    print(\n",
        "        f'   - PCA: {use_pca} ({n_components} components)'\n",
        "        if use_pca\n",
        "        else f'   - PCA: {use_pca}'\n",
        "    )\n",
        "    print(f'   - GPU: {use_gpu and CUML_AVAILABLE}')\n",
        "\n",
        "    start_time = time()\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    train_time = time() - start_time\n",
        "\n",
        "    print(f'\\n Huấn luyện hoàn tất trong {train_time:.2f} giây')\n",
        "    return pipeline, train_time\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('=' * 60)\n",
        "print(' Huấn luyện SVM với RBF Kernel')\n",
        "print('=' * 60)\n",
        "model_rbf, time_rbf = train_svm(X_train_subset, y_train_subset, kernel='rbf', C=1.0, gamma='scale', use_pca=False, use_gpu=CUML_AVAILABLE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('\\n' + '=' * 60)\n",
        "print(' Huấn luyện SVM với Linear Kernel')\n",
        "print('=' * 60)\n",
        "model_linear, time_linear = train_svm(X_train_subset, y_train_subset, kernel='linear', C=1.0, use_pca=False, use_gpu=CUML_AVAILABLE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('\\n' + '=' * 60)\n",
        "print(' Huấn luyện SVM với RBF Kernel + PCA')\n",
        "print('=' * 60)\n",
        "model_pca, time_pca = train_svm(X_train_subset, y_train_subset, kernel='rbf', C=1.0, gamma='scale', use_pca=True, n_components=100, use_gpu=CUML_AVAILABLE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Đánh giá mô hình\n",
        "\n",
        "### Bạn cần báo cáo những gì?\n",
        "- **Accuracy**: tổng tỉ lệ đúng.\n",
        "- **Classification report**:\n",
        "  - `precision`: trong các mẫu dự đoán là lớp k, đúng được bao nhiêu\n",
        "  - `recall`: trong các mẫu thật sự là lớp k, bắt được bao nhiêu\n",
        "  - `f1-score`: trung bình điều hoà của precision và recall\n",
        "- **Confusion matrix**: xem mô hình hay nhầm chữ số nào (ví dụ 4 vs 9, 3 vs 5...).\n",
        "\n",
        "### Lưu ý khi thuyết trình\n",
        "- MNIST tương đối cân bằng nên accuracy thường phản ánh khá tốt.\n",
        "- Tuy nhiên confusion matrix giúp bạn *kể câu chuyện*: mô hình nhầm vì nét viết tay giống nhau.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def evaluate_model(model, X_test, y_test, model_name='Model'):\n",
        "    \"\"\"Đánh giá mô hình trên tập test.\n",
        "\n",
        "    Trả về:\n",
        "    - accuracy: tỉ lệ đúng\n",
        "    - predict_time: thời gian dự đoán\n",
        "    - y_pred: nhãn dự đoán\n",
        "    - confusion_matrix: ma trận nhầm lẫn\n",
        "\n",
        "    Gợi ý trình bày:\n",
        "    - Accuracy cho biết tổng quan.\n",
        "    - Classification report giúp nhìn chi tiết theo từng chữ số.\n",
        "    - Confusion matrix để phân tích các cặp hay nhầm.\n",
        "    \"\"\"\n",
        "\n",
        "    print('\\n' + '=' * 60)\n",
        "    print(f' Đánh giá: {model_name}')\n",
        "    print('=' * 60)\n",
        "\n",
        "    start_time = time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    predict_time = time() - start_time\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'\\n Accuracy: {accuracy:.4f} ({accuracy * 100:.2f}%)')\n",
        "    print(f' Thời gian dự đoán: {predict_time:.4f} giây')\n",
        "\n",
        "    print('\\n Classification Report:')\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'predict_time': predict_time,\n",
        "        'y_pred': y_pred,\n",
        "        'confusion_matrix': cm,\n",
        "    }\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results_rbf = evaluate_model(model_rbf, X_test, y_test, 'SVM RBF Kernel')\n",
        "results_linear = evaluate_model(model_linear, X_test, y_test, 'SVM Linear Kernel')\n",
        "results_pca = evaluate_model(model_pca, X_test, y_test, 'SVM RBF + PCA')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_confusion_matrix(cm, title='Confusion Matrix'):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd', xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel('Dự đoán', fontsize=12)\n",
        "    plt.ylabel('Thực tế', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plot_confusion_matrix(results_rbf['confusion_matrix'], 'Ma trận Nhầm lẫn - SVM RBF Kernel')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "comparison_df = pd.DataFrame({'Model': ['SVM RBF', 'SVM Linear', 'SVM RBF + PCA'], 'Accuracy': [results_rbf['accuracy'], results_linear['accuracy'], results_pca['accuracy']], 'Train Time (s)': [time_rbf, time_linear, time_pca], 'Predict Time (s)': [results_rbf['predict_time'], results_linear['predict_time'], results_pca['predict_time']]})\n",
        "print('\\n So sánh các mô hình:')\n",
        "print(comparison_df.to_string(index=False))\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "axes[0].bar(comparison_df['Model'], comparison_df['Accuracy'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title('So sánh Accuracy')\n",
        "axes[0].set_ylim([0.9, 1.0])\n",
        "for i, v in enumerate(comparison_df['Accuracy']):\n",
        "    axes[0].text(i, v + 0.002, f'{v:.4f}', ha='center')\n",
        "axes[1].bar(comparison_df['Model'], comparison_df['Train Time (s)'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
        "axes[1].set_ylabel('Thời gian (s)')\n",
        "axes[1].set_title('So sánh Thời gian Huấn luyện')\n",
        "axes[2].bar(comparison_df['Model'], comparison_df['Predict Time (s)'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
        "axes[2].set_ylabel('Thời gian (s)')\n",
        "axes[2].set_title('So sánh Thời gian Dự đoán')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def show_misclassified(X_test, y_test, y_pred, n_samples=10):\n",
        "    misclassified_idx = np.where(y_test != y_pred)[0]\n",
        "    if len(misclassified_idx) == 0:\n",
        "        print('Không có mẫu nào bị phân loại sai!')\n",
        "        return\n",
        "    n_show = min(n_samples, len(misclassified_idx))\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    fig.suptitle(f'Các mẫu bị phân loại sai ({len(misclassified_idx)} mẫu)', fontsize=14)\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < n_show:\n",
        "            idx = misclassified_idx[i]\n",
        "            ax.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
        "            ax.set_title(f'Thực: {y_test[idx]}\\nDự đoán: {y_pred[idx]}', color='red', fontsize=10)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "show_misclassified(X_test, y_test, results_rbf['y_pred'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Tối ưu hoá mô hình (GridSearchCV) + phân tích PCA\n",
        "\n",
        "### GridSearchCV làm gì?\n",
        "- Ta thử một lưới tham số (grid) gồm nhiều tổ hợp `C`, `gamma`, `kernel`.\n",
        "- Với mỗi tổ hợp, ta chạy **cross-validation (CV)** để ước lượng độ tổng quát.\n",
        "- Chọn cấu hình có `mean_test_score` tốt nhất.\n",
        "\n",
        "### Vì sao cần CV?\n",
        "- Nếu chỉ chọn theo accuracy trên một lần split, có thể “ăn may”.\n",
        "- CV chia train thành nhiều fold, train/val luân phiên → đánh giá ổn định hơn.\n",
        "\n",
        "### Lưu ý về chi phí tính toán\n",
        "- SVM RBF + GridSearch trên MNIST rất nặng, nên notebook giới hạn số mẫu (`n_grid_samples`) để chạy trong thời gian hợp lý.\n",
        "\n",
        "### Phần PCA\n",
        "- Sau khi có best_params, notebook thử nhiều `n_components` để tìm trade-off:\n",
        "  - `n_components` nhỏ → nhanh hơn nhưng dễ giảm accuracy\n",
        "  - `n_components` lớn → giữ thông tin nhiều hơn nhưng chậm hơn\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(' Bắt đầu Grid Search...')\n",
        "print(' Quá trình này có thể mất vài phút...\\n')\n",
        "\n",
        "# Dùng Pipeline để đảm bảo scaler luôn được fit đúng trên train fold\n",
        "pipeline_grid = Pipeline(\n",
        "    [\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svc', SVC(probability=True, cache_size=1000)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Lưới tham số: thử nhiều tổ hợp C/gamma/kernel\n",
        "param_grid = {\n",
        "    'svc__C': [0.1, 1, 10],\n",
        "    'svc__gamma': ['scale', 0.01, 0.1],\n",
        "    'svc__kernel': ['rbf', 'linear'],\n",
        "}\n",
        "\n",
        "# Giới hạn số mẫu để GridSearch không quá nặng\n",
        "n_grid_samples = min(5000, len(X_train_subset))\n",
        "X_grid = X_train_subset[:n_grid_samples]\n",
        "y_grid = y_train_subset[:n_grid_samples]\n",
        "\n",
        "print(f' Sử dụng {n_grid_samples} mẫu cho GridSearch')\n",
        "num_combinations = (\n",
        "    len(param_grid['svc__C'])\n",
        "    * len(param_grid['svc__gamma'])\n",
        "    * len(param_grid['svc__kernel'])\n",
        ")\n",
        "print(f' Số lượng kết hợp tham số: {num_combinations}')\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline_grid,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    scoring='accuracy',\n",
        "    return_train_score=True,\n",
        ")\n",
        "\n",
        "start_time = time()\n",
        "grid_search.fit(X_grid, y_grid)\n",
        "grid_time = time() - start_time\n",
        "print(f'\\n GridSearch hoàn tất trong {grid_time:.2f} giây')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('\\n Kết quả GridSearch:')\n",
        "print(f'   - Best Score (CV): {grid_search.best_score_:.4f}')\n",
        "print(f'   - Best Parameters: {grid_search.best_params_}')\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "results_df = results_df.sort_values('rank_test_score')[['params', 'mean_test_score', 'std_test_score', 'mean_train_score', 'rank_test_score']].head(10)\n",
        "print('\\n Top 10 kết hợp tham số:')\n",
        "print(results_df.to_string(index=False))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('\\n Huấn luyện mô hình tối ưu với tham số tốt nhất...')\n",
        "best_params = grid_search.best_params_\n",
        "model_best, time_best = train_svm(X_train_subset, y_train_subset, kernel=best_params['svc__kernel'], C=best_params['svc__C'], gamma=best_params['svc__gamma'] if 'svc__gamma' in best_params else 'scale', use_pca=False, use_gpu=CUML_AVAILABLE)\n",
        "results_best = evaluate_model(model_best, X_test, y_test, 'SVM Tối ưu (Best Params)')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('\\n Thử nghiệm với PCA:')\n",
        "pca_components = [50, 100, 150, 200]\n",
        "pca_results = []\n",
        "for n_comp in pca_components:\n",
        "    print(f'\\n Huấn luyện với PCA n_components={n_comp}')\n",
        "    model_pca_test, train_time = train_svm(X_train_subset, y_train_subset, kernel='rbf', C=best_params.get('svc__C', 1.0), gamma='scale', use_pca=True, n_components=n_comp, use_gpu=CUML_AVAILABLE)\n",
        "    y_pred = model_pca_test.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    pca_results.append({'n_components': n_comp, 'accuracy': accuracy, 'train_time': train_time})\n",
        "    print(f'   Accuracy: {accuracy:.4f}')\n",
        "pca_df = pd.DataFrame(pca_results)\n",
        "print('\\n So sánh các cấu hình PCA:')\n",
        "print(pca_df.to_string(index=False))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].plot(pca_df['n_components'], pca_df['accuracy'], 'bo-', markersize=8)\n",
        "axes[0].set_xlabel('Số thành phần PCA')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title('Accuracy vs Số thành phần PCA')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[1].plot(pca_df['n_components'], pca_df['train_time'], 'ro-', markersize=8)\n",
        "axes[1].set_xlabel('Số thành phần PCA')\n",
        "axes[1].set_ylabel('Thời gian huấn luyện (s)')\n",
        "axes[1].set_title('Thời gian huấn luyện vs Số thành phần PCA')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Mô hình cuối cùng + xuất đầu ra cho Ensemble\n",
        "\n",
        "### Mục tiêu của phần này\n",
        "- Chốt một mô hình SVM “tốt nhất” (dựa trên kết quả GridSearch) để:\n",
        "  - đánh giá lại trên tập test\n",
        "  - **lưu model** phục vụ triển khai\n",
        "  - **xuất xác suất** `predict_proba` để dùng trong hệ **ensemble** (kết hợp nhiều mô hình)\n",
        "\n",
        "### Ensemble output là gì?\n",
        "- Với mỗi ảnh test, thay vì chỉ xuất nhãn (0–9), ta xuất thêm **vector xác suất 10 chiều**:\n",
        "  - \n",
        "  \\[\n",
        "  p = [P(y=0), P(y=1), ..., P(y=9)]\n",
        "  \\]\n",
        "- Hệ ensemble (ví dụ stacking/blending) có thể lấy các vector xác suất từ nhiều mô hình khác nhau (SVM, CNN, RF, …) rồi học một mô hình “meta” để ra quyết định cuối.\n",
        "\n",
        "### Lưu ý\n",
        "- `probability=True` là điều kiện để có `predict_proba`.\n",
        "- File `.joblib` lưu cả pipeline (scaler + svm) → khi load lên dự đoán ảnh mới sẽ đúng quy trình tiền xử lý.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('=' * 60)\n",
        "print(' Huấn luyện Mô hình Cuối cùng')\n",
        "print('=' * 60)\n",
        "\n",
        "# Mô hình cuối cùng dùng tham số tốt nhất từ GridSearch\n",
        "final_model = Pipeline(\n",
        "    [\n",
        "        ('scaler', StandardScaler()),\n",
        "        (\n",
        "            'svc',\n",
        "            SVC(\n",
        "                kernel=best_params['svc__kernel'],\n",
        "                C=best_params['svc__C'],\n",
        "                gamma=best_params.get('svc__gamma', 'scale'),\n",
        "                probability=True,\n",
        "                cache_size=1000,\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print('\\n Cấu hình mô hình cuối cùng:')\n",
        "print(f\"   - Kernel: {best_params['svc__kernel']}\")\n",
        "print(f\"   - C: {best_params['svc__C']}\")\n",
        "print(f\"   - Gamma: {best_params.get('svc__gamma', 'scale')}\")\n",
        "\n",
        "start_time = time()\n",
        "final_model.fit(X_train_subset, y_train_subset)\n",
        "final_train_time = time() - start_time\n",
        "\n",
        "print(f'\\n Huấn luyện hoàn tất trong {final_train_time:.2f} giây')\n",
        "final_results = evaluate_model(final_model, X_test, y_test, 'Mô hình Cuối cùng')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('\\n Xuất đầu ra cho Ensemble:')\n",
        "proba = final_model.predict_proba(X_test)\n",
        "pred = final_model.predict(X_test)\n",
        "print(f'\\n Shape của xác suất: {proba.shape}')\n",
        "print(f'   - Mỗi hàng là một mẫu')\n",
        "print(f'   - Mỗi cột là xác suất cho chữ số 0-9')\n",
        "print(f'\\n Ví dụ 5 mẫu đầu tiên:')\n",
        "sample_output = pd.DataFrame(proba[:5], columns=[f'P(digit={i})' for i in range(10)])\n",
        "sample_output['Predicted'] = pred[:5]\n",
        "sample_output['Actual'] = y_test[:5]\n",
        "print(sample_output.to_string(index=False))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('\\n Lưu đầu ra...')\n",
        "ensemble_output = pd.DataFrame(proba, columns=[f'prob_digit_{i}' for i in range(10)])\n",
        "ensemble_output['predicted_label'] = pred\n",
        "ensemble_output['true_label'] = y_test\n",
        "ensemble_output.to_csv('svm_predictions_for_ensemble.csv', index=False)\n",
        "print(' Đã lưu: svm_predictions_for_ensemble.csv')\n",
        "np.save('svm_probabilities.npy', proba)\n",
        "print(' Đã lưu: svm_probabilities.npy')\n",
        "np.save('svm_predictions.npy', pred)\n",
        "print(' Đã lưu: svm_predictions.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('\\n Lưu mô hình...')\n",
        "joblib.dump(final_model, 'svm_digit_classifier.joblib')\n",
        "print(' Đã lưu mô hình: svm_digit_classifier.joblib')\n",
        "print('\\n Hướng dẫn sử dụng mô hình đã lưu:')\n",
        "print(\"\\n# Load mô hình\\nimport joblib\\nmodel = joblib.load('svm_digit_classifier.joblib')\\n\\n# Dự đoán nhãn\\npredictions = model.predict(X_new)\\n\\n# Dự đoán xác suất\\nprobabilities = model.predict_proba(X_new)\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ghi chú về các file đầu ra (để bạn giải thích rõ)\n",
        "\n",
        "Sau khi chạy xong, notebook tạo ra các file chính:\n",
        "\n",
        "### 1) `svm_digit_classifier.joblib`\n",
        "- Là **pipeline đã huấn luyện** (gồm `StandardScaler` + `SVC`).\n",
        "- Khi load lại, bạn chỉ cần đưa ảnh về đúng format (vector 784 hoặc ảnh 28×28) và gọi `predict`/`predict_proba`.\n",
        "\n",
        "### 2) `svm_predictions_for_ensemble.csv`\n",
        "- Mỗi dòng tương ứng **1 mẫu test**.\n",
        "- Có các cột:\n",
        "  - `prob_digit_0 ... prob_digit_9`: xác suất cho từng chữ số\n",
        "  - `predicted_label`: nhãn dự đoán\n",
        "  - `true_label`: nhãn thật (để đánh giá/huấn luyện meta-model nếu cần)\n",
        "\n",
        "### 3) `svm_probabilities.npy`, `svm_predictions.npy`\n",
        "- Lưu dạng numpy array cho nhanh, tiện dùng trong pipeline ML khác.\n",
        "\n",
        "### 4) `confusion_matrix.png`\n",
        "- Ảnh ma trận nhầm lẫn chuẩn hoá theo hàng (mỗi hàng tổng = 100%).\n",
        "- Dễ đưa vào báo cáo.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('=' * 60)\n",
        "print(' TỔNG KẾT KẾT QUẢ')\n",
        "print('=' * 60)\n",
        "\n",
        "print('\\n Mô hình cuối cùng:')\n",
        "print(\n",
        "    f\"   - Accuracy: {final_results['accuracy']:.4f} ({final_results['accuracy'] * 100:.2f}%)\"\n",
        ")\n",
        "print(f\"   - Kernel: {best_params['svc__kernel']}\")\n",
        "print(f\"   - C: {best_params['svc__C']}\")\n",
        "print(f\"   - Gamma: {best_params.get('svc__gamma', 'scale')}\")\n",
        "\n",
        "print('\\n Các file đã lưu:')\n",
        "print('   - svm_digit_classifier.joblib (mô hình)')\n",
        "print('   - svm_predictions_for_ensemble.csv (đầu ra cho ensemble)')\n",
        "print('   - svm_probabilities.npy (xác suất dự đoán)')\n",
        "print('   - svm_predictions.npy (nhãn dự đoán)')\n",
        "print('   - confusion_matrix.png (ma trận nhầm lẫn chuẩn hoá)')\n",
        "\n",
        "print('\\n Hoàn tất!')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "cm = final_results['confusion_matrix']\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', xticklabels=range(10), yticklabels=range(10), cbar_kws={'label': 'Tỷ lệ'})\n",
        "plt.title('Ma trận Nhầm lẫn (Normalized) - Mô hình SVM Cuối cùng', fontsize=14)\n",
        "plt.xlabel('Dự đoán', fontsize=12)\n",
        "plt.ylabel('Thực tế', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "print(' Đã lưu: confusion_matrix.png')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Câu hỏi giảng viên hay hỏi + câu trả lời gợi ý\n",
        "\n",
        "### 1) “Vì sao em chọn SVM mà không phải CNN?”\n",
        "- *Gợi ý trả lời*: CNN thường mạnh nhất cho ảnh, nhưng mục tiêu bài này là minh hoạ một mô hình cổ điển, dễ giải thích toán học và quy trình ML (tiền xử lý, GridSearch, confusion matrix). Với MNIST, SVM vẫn đạt kết quả tốt khi cấu hình phù hợp.\n",
        "\n",
        "### 2) “Kernel RBF khác Linear thế nào?”\n",
        "- Linear: biên quyết định tuyến tính trong không gian gốc.\n",
        "- RBF: cho phép biên quyết định phi tuyến; kernel trick giúp mô hình hoá quan hệ phức tạp.\n",
        "\n",
        "### 3) “C và gamma ảnh hưởng gì?”\n",
        "- C: trade-off giữa margin rộng và lỗi trên train.\n",
        "- gamma: mức ảnh hưởng của từng điểm dữ liệu trong RBF (cục bộ vs toàn cục).\n",
        "\n",
        "### 4) “Vì sao phải StandardScaler khi đã chia 255?”\n",
        "- Chia 255 chỉ đưa pixel về [0,1].\n",
        "- StandardScaler đưa từng feature về phân phối chuẩn hoá (mean=0, std=1) → SVM (dựa trên khoảng cách) học ổn định hơn.\n",
        "\n",
        "### 5) “PCA có làm giảm accuracy không?”\n",
        "- Có thể giảm nếu n_components quá thấp vì mất thông tin.\n",
        "- Nhưng đổi lại tăng tốc và giảm nhiễu; cần thực nghiệm để chọn trade-off phù hợp.\n",
        "\n",
        "### 6) “predict_proba của SVM có phải xác suất thật không?”\n",
        "- Đây là xác suất sau hiệu chỉnh (calibration) khi bật `probability=True`.\n",
        "- Hữu ích để so sánh mức tin cậy và làm đầu vào cho ensemble.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def predict_digit(model, image):\n",
        "    \"\"\"Dự đoán 1 ảnh chữ số và trả về cả nhãn + xác suất.\n",
        "\n",
        "    Input chấp nhận:\n",
        "    - Ảnh 28x28 (ndim=2)\n",
        "    - Vector 784 (ndim=1)\n",
        "\n",
        "    Lưu ý:\n",
        "    - Nếu ảnh đang ở thang [0,255] thì chuẩn hoá về [0,1].\n",
        "    - Vì model là Pipeline (scaler + SVC), bạn không cần tự StandardScaler ở đây.\n",
        "    \"\"\"\n",
        "\n",
        "    # Đưa về dạng (1, 784)\n",
        "    if image.ndim == 2:\n",
        "        image = image.reshape(1, -1)\n",
        "    elif image.ndim == 1:\n",
        "        image = image.reshape(1, -1)\n",
        "\n",
        "    # Nếu pixel đang là 0..255 thì chuẩn hoá về 0..1\n",
        "    if image.max() > 1:\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "\n",
        "    pred = model.predict(image)[0]\n",
        "    proba = model.predict_proba(image)[0]\n",
        "\n",
        "    return {\n",
        "        'prediction': pred,\n",
        "        'confidence': float(proba[pred]),\n",
        "        'probabilities': proba,\n",
        "    }\n",
        "\n",
        "# Demo dự đoán 1 ảnh trong tập test\n",
        "test_image = X_test[0]\n",
        "result = predict_digit(final_model, test_image)\n",
        "\n",
        "print(f\" Dự đoán: {result['prediction']}\")\n",
        "print(f\" Độ tin cậy: {result['confidence']:.4f}\")\n",
        "print(f\" Nhãn thực tế: {y_test[0]}\")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(test_image.reshape(28, 28), cmap='gray')\n",
        "plt.title(f\"Dự đoán: {result['prediction']} (Thực tế: {y_test[0]})\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(range(10), result['probabilities'])\n",
        "plt.xlabel('Chữ số')\n",
        "plt.ylabel('Xác suất')\n",
        "plt.title('Phân bố xác suất')\n",
        "plt.xticks(range(10))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}