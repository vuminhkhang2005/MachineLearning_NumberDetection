{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî¢ M√¥ h√¨nh SVM Nh·∫≠n d·∫°ng Ch·ªØ s·ªë Vi·∫øt tay (MNIST)\n",
        "\n",
        "Notebook n√†y tri·ªÉn khai ƒë·∫ßy ƒë·ªß quy tr√¨nh x√¢y d·ª±ng m√¥ h√¨nh SVM ƒë·ªÉ nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay s·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu MNIST.\n",
        "\n",
        "**C√°c b∆∞·ªõc ch√≠nh:**\n",
        "1. Chu·∫©n b·ªã d·ªØ li·ªáu v√† ti·ªÅn x·ª≠ l√Ω\n",
        "2. Hu·∫•n luy·ªán m√¥ h√¨nh SVM\n",
        "3. ƒê√°nh gi√° m√¥ h√¨nh\n",
        "4. T·ªëi ∆∞u h√≥a m√¥ h√¨nh (GridSearch, PCA)\n",
        "5. Xu·∫•t ƒë·∫ßu ra cho h·ªá ensemble\n",
        "\n",
        "**L∆∞u √Ω:** ƒê·ªÉ s·ª≠ d·ª•ng GPU tr√™n Google Colab, notebook n√†y s·ª≠ d·ª•ng th∆∞ vi·ªán RAPIDS cuML khi c√≥ s·∫µn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ C√†i ƒë·∫∑t v√† Import th∆∞ vi·ªán"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ki·ªÉm tra GPU tr√™n Google Colab\n",
        "import subprocess\n",
        "try:\n",
        "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "    print(result.stdout)\n",
        "    GPU_AVAILABLE = True\n",
        "except:\n",
        "    print(\"Kh√¥ng t√¨m th·∫•y GPU\")\n",
        "    GPU_AVAILABLE = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# C√†i ƒë·∫∑t RAPIDS cuML n·∫øu c√≥ GPU (cho Google Colab)\n",
        "# Uncomment d√≤ng d∆∞·ªõi n·∫øu ch·∫°y tr√™n Google Colab v·ªõi GPU\n",
        "# !pip install cuml-cu11 --extra-index-url=https://pypi.nvidia.com"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from time import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Sklearn imports\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import (\n",
        "    classification_report, \n",
        "    confusion_matrix, \n",
        "    accuracy_score,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# C·ªë g·∫Øng import cuML cho GPU acceleration\n",
        "try:\n",
        "    from cuml.svm import SVC as cuSVC\n",
        "    from cuml.preprocessing import StandardScaler as cuStandardScaler\n",
        "    from cuml.decomposition import PCA as cuPCA\n",
        "    CUML_AVAILABLE = True\n",
        "    print(\"‚úÖ cuML ƒë√£ ƒë∆∞·ª£c import th√†nh c√¥ng - S·ª≠ d·ª•ng GPU acceleration!\")\n",
        "except ImportError:\n",
        "    CUML_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è cuML kh√¥ng kh·∫£ d·ª•ng - S·ª≠ d·ª•ng sklearn (CPU)\")\n",
        "\n",
        "# Joblib ƒë·ªÉ l∆∞u model\n",
        "import joblib\n",
        "\n",
        "print(f\"\\nüìä C·∫•u h√¨nh:\")\n",
        "print(f\"   - GPU Available: {GPU_AVAILABLE}\")\n",
        "print(f\"   - cuML Available: {CUML_AVAILABLE}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ 1. Chu·∫©n b·ªã d·ªØ li·ªáu v√† Ti·ªÅn x·ª≠ l√Ω"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# T·∫£i d·ªØ li·ªáu MNIST\n",
        "print(\"üì• ƒêang t·∫£i d·ªØ li·ªáu MNIST...\")\n",
        "start_time = time()\n",
        "\n",
        "# C√°ch 1: S·ª≠ d·ª•ng fetch_openml (d·ªØ li·ªáu ƒë√£ flatten s·∫µn th√†nh 784 features)\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, parser='auto')\n",
        "\n",
        "print(f\"‚úÖ T·∫£i xong trong {time() - start_time:.2f} gi√¢y\")\n",
        "print(f\"\\nüìä Th√¥ng tin d·ªØ li·ªáu:\")\n",
        "print(f\"   - Shape c·ªßa X: {X.shape}\")\n",
        "print(f\"   - Shape c·ªßa y: {y.shape}\")\n",
        "print(f\"   - S·ªë l∆∞·ª£ng l·ªõp: {len(np.unique(y))}\")\n",
        "print(f\"   - C√°c l·ªõp: {np.unique(y)}\")\n",
        "print(f\"   - Dtype c·ªßa X: {X.dtype}\")\n",
        "print(f\"   - Range c·ªßa pixel: [{X.min()}, {X.max()}]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hi·ªÉn th·ªã m·ªôt s·ªë ·∫£nh m·∫´u\n",
        "fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
        "fig.suptitle('M·ªôt s·ªë ·∫£nh m·∫´u t·ª´ MNIST', fontsize=14)\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(X[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(f'Label: {y[i]}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Chuy·ªÉn ƒë·ªïi nh√£n sang s·ªë nguy√™n\n",
        "y = y.astype(int)\n",
        "\n",
        "# Chu·∫©n h√≥a d·ªØ li·ªáu: chia cho 255 ƒë·ªÉ ƒë∆∞a v·ªÅ [0, 1]\n",
        "print(\"üîÑ Chu·∫©n h√≥a d·ªØ li·ªáu...\")\n",
        "X = X.astype(np.float32) / 255.0\n",
        "\n",
        "print(f\"   - Dtype sau chu·∫©n h√≥a: {X.dtype}\")\n",
        "print(f\"   - Range sau chu·∫©n h√≥a: [{X.min():.2f}, {X.max():.2f}]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Chia t·∫≠p train/test theo chu·∫©n MNIST (60k train, 10k test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=10000, \n",
        "    random_state=42,\n",
        "    stratify=y  # ƒê·∫£m b·∫£o ph√¢n b·ªë ƒë·ªÅu c√°c l·ªõp\n",
        ")\n",
        "\n",
        "print(f\"üìä Chia d·ªØ li·ªáu:\")\n",
        "print(f\"   - Train: {X_train.shape[0]} m·∫´u\")\n",
        "print(f\"   - Test: {X_test.shape[0]} m·∫´u\")\n",
        "\n",
        "# Ph√¢n b·ªë c√°c l·ªõp trong t·∫≠p train\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(f\"\\nüìà Ph√¢n b·ªë l·ªõp trong t·∫≠p train:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"   Ch·ªØ s·ªë {label}: {count} m·∫´u ({count/len(y_train)*100:.1f}%)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# T√πy ch·ªçn: S·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu nh·ªè h∆°n ƒë·ªÉ th·ª≠ nghi·ªám nhanh\n",
        "USE_SUBSET = True  # ƒê·∫∑t False ƒë·ªÉ d√πng to√†n b·ªô d·ªØ li·ªáu\n",
        "SUBSET_SIZE = 10000  # S·ªë m·∫´u train ƒë·ªÉ th·ª≠ nghi·ªám\n",
        "\n",
        "if USE_SUBSET:\n",
        "    print(f\"‚ö° S·ª≠ d·ª•ng t·∫≠p con {SUBSET_SIZE} m·∫´u ƒë·ªÉ th·ª≠ nghi·ªám nhanh...\")\n",
        "    # L·∫•y m·∫´u ng·∫´u nhi√™n c√≥ ph√¢n t·∫ßng\n",
        "    from sklearn.model_selection import StratifiedShuffleSplit\n",
        "    \n",
        "    sss = StratifiedShuffleSplit(n_splits=1, train_size=SUBSET_SIZE, random_state=42)\n",
        "    for train_idx, _ in sss.split(X_train, y_train):\n",
        "        X_train_subset = X_train[train_idx]\n",
        "        y_train_subset = y_train[train_idx]\n",
        "    \n",
        "    print(f\"   - T·∫≠p train subset: {X_train_subset.shape[0]} m·∫´u\")\n",
        "else:\n",
        "    X_train_subset = X_train\n",
        "    y_train_subset = y_train\n",
        "    print(f\"üìä S·ª≠ d·ª•ng to√†n b·ªô {X_train.shape[0]} m·∫´u train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† 2. Hu·∫•n luy·ªán M√¥ h√¨nh SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ƒê·ªãnh nghƒ©a h√†m hu·∫•n luy·ªán SVM\n",
        "def train_svm(X_train, y_train, kernel='rbf', C=1.0, gamma='scale', \n",
        "              use_pca=False, n_components=100, use_gpu=False):\n",
        "    \"\"\"\n",
        "    Hu·∫•n luy·ªán m√¥ h√¨nh SVM v·ªõi c√°c t√πy ch·ªçn.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    X_train : array-like\n",
        "        D·ªØ li·ªáu hu·∫•n luy·ªán\n",
        "    y_train : array-like\n",
        "        Nh√£n hu·∫•n luy·ªán\n",
        "    kernel : str\n",
        "        Lo·∫°i kernel ('rbf', 'linear', 'poly', 'sigmoid')\n",
        "    C : float\n",
        "        H·ªá s·ªë regularization\n",
        "    gamma : str or float\n",
        "        H·ªá s·ªë gamma cho kernel RBF\n",
        "    use_pca : bool\n",
        "        C√≥ s·ª≠ d·ª•ng PCA gi·∫£m chi·ªÅu hay kh√¥ng\n",
        "    n_components : int\n",
        "        S·ªë th√†nh ph·∫ßn PCA\n",
        "    use_gpu : bool\n",
        "        S·ª≠ d·ª•ng GPU (cuML) n·∫øu c√≥\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    pipeline : sklearn Pipeline\n",
        "        Model ƒë√£ hu·∫•n luy·ªán\n",
        "    \"\"\"\n",
        "    steps = []\n",
        "    \n",
        "    # B∆∞·ªõc 1: Chu·∫©n h√≥a (StandardScaler)\n",
        "    if use_gpu and CUML_AVAILABLE:\n",
        "        steps.append(('scaler', cuStandardScaler()))\n",
        "    else:\n",
        "        steps.append(('scaler', StandardScaler()))\n",
        "    \n",
        "    # B∆∞·ªõc 2: PCA (t√πy ch·ªçn)\n",
        "    if use_pca:\n",
        "        if use_gpu and CUML_AVAILABLE:\n",
        "            steps.append(('pca', cuPCA(n_components=n_components)))\n",
        "        else:\n",
        "            steps.append(('pca', PCA(n_components=n_components)))\n",
        "    \n",
        "    # B∆∞·ªõc 3: SVM\n",
        "    if use_gpu and CUML_AVAILABLE:\n",
        "        # cuML SVC\n",
        "        svm = cuSVC(kernel=kernel, C=C, gamma=gamma, probability=True)\n",
        "    else:\n",
        "        # sklearn SVC\n",
        "        svm = SVC(kernel=kernel, C=C, gamma=gamma, probability=True, cache_size=1000)\n",
        "    \n",
        "    steps.append(('svc', svm))\n",
        "    \n",
        "    # T·∫°o pipeline\n",
        "    pipeline = Pipeline(steps)\n",
        "    \n",
        "    # Hu·∫•n luy·ªán\n",
        "    print(f\"üèãÔ∏è B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán SVM...\")\n",
        "    print(f\"   - Kernel: {kernel}\")\n",
        "    print(f\"   - C: {C}\")\n",
        "    print(f\"   - Gamma: {gamma}\")\n",
        "    print(f\"   - PCA: {use_pca} ({n_components} components)\" if use_pca else f\"   - PCA: {use_pca}\")\n",
        "    print(f\"   - GPU: {use_gpu and CUML_AVAILABLE}\")\n",
        "    \n",
        "    start_time = time()\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    train_time = time() - start_time\n",
        "    \n",
        "    print(f\"\\n‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t trong {train_time:.2f} gi√¢y\")\n",
        "    \n",
        "    return pipeline, train_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hu·∫•n luy·ªán m√¥ h√¨nh SVM c∆° b·∫£n v·ªõi RBF kernel\n",
        "print(\"=\"*60)\n",
        "print(\"üéØ Hu·∫•n luy·ªán SVM v·ªõi RBF Kernel\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model_rbf, time_rbf = train_svm(\n",
        "    X_train_subset, y_train_subset,\n",
        "    kernel='rbf',\n",
        "    C=1.0,\n",
        "    gamma='scale',\n",
        "    use_pca=False,\n",
        "    use_gpu=CUML_AVAILABLE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hu·∫•n luy·ªán m√¥ h√¨nh SVM v·ªõi Linear kernel ƒë·ªÉ so s√°nh\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ Hu·∫•n luy·ªán SVM v·ªõi Linear Kernel\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model_linear, time_linear = train_svm(\n",
        "    X_train_subset, y_train_subset,\n",
        "    kernel='linear',\n",
        "    C=1.0,\n",
        "    use_pca=False,\n",
        "    use_gpu=CUML_AVAILABLE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hu·∫•n luy·ªán m√¥ h√¨nh SVM v·ªõi PCA\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ Hu·∫•n luy·ªán SVM v·ªõi RBF Kernel + PCA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model_pca, time_pca = train_svm(\n",
        "    X_train_subset, y_train_subset,\n",
        "    kernel='rbf',\n",
        "    C=1.0,\n",
        "    gamma='scale',\n",
        "    use_pca=True,\n",
        "    n_components=100,\n",
        "    use_gpu=CUML_AVAILABLE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä 3. ƒê√°nh gi√° M√¥ h√¨nh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° m√¥ h√¨nh v√† in ra c√°c ch·ªâ s·ªë.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : sklearn Pipeline\n",
        "        M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n",
        "    X_test : array-like\n",
        "        D·ªØ li·ªáu test\n",
        "    y_test : array-like\n",
        "        Nh√£n test\n",
        "    model_name : str\n",
        "        T√™n m√¥ h√¨nh ƒë·ªÉ hi·ªÉn th·ªã\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : C√°c ch·ªâ s·ªë ƒë√°nh gi√°\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä ƒê√°nh gi√°: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # D·ª± ƒëo√°n\n",
        "    start_time = time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    predict_time = time() - start_time\n",
        "    \n",
        "    # T√≠nh accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    print(f\"\\nüéØ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"‚è±Ô∏è Th·ªùi gian d·ª± ƒëo√°n: {predict_time:.4f} gi√¢y\")\n",
        "    \n",
        "    # Classification report\n",
        "    print(f\"\\nüìã Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'predict_time': predict_time,\n",
        "        'y_pred': y_pred,\n",
        "        'confusion_matrix': cm\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ƒê√°nh gi√° c√°c m√¥ h√¨nh\n",
        "results_rbf = evaluate_model(model_rbf, X_test, y_test, \"SVM RBF Kernel\")\n",
        "results_linear = evaluate_model(model_linear, X_test, y_test, \"SVM Linear Kernel\")\n",
        "results_pca = evaluate_model(model_pca, X_test, y_test, \"SVM RBF + PCA\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# V·∫Ω Confusion Matrix\n",
        "def plot_confusion_matrix(cm, title=\"Confusion Matrix\"):\n",
        "    \"\"\"\n",
        "    V·∫Ω ma tr·∫≠n nh·∫ßm l·∫´n.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n",
        "                xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel('D·ª± ƒëo√°n', fontsize=12)\n",
        "    plt.ylabel('Th·ª±c t·∫ø', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# V·∫Ω confusion matrix cho m√¥ h√¨nh t·ªët nh·∫•t (RBF)\n",
        "plot_confusion_matrix(results_rbf['confusion_matrix'], \"Ma tr·∫≠n Nh·∫ßm l·∫´n - SVM RBF Kernel\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# So s√°nh c√°c m√¥ h√¨nh\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['SVM RBF', 'SVM Linear', 'SVM RBF + PCA'],\n",
        "    'Accuracy': [results_rbf['accuracy'], results_linear['accuracy'], results_pca['accuracy']],\n",
        "    'Train Time (s)': [time_rbf, time_linear, time_pca],\n",
        "    'Predict Time (s)': [results_rbf['predict_time'], results_linear['predict_time'], results_pca['predict_time']]\n",
        "})\n",
        "\n",
        "print(\"\\nüìä So s√°nh c√°c m√¥ h√¨nh:\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# V·∫Ω bi·ªÉu ƒë·ªì so s√°nh\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Accuracy\n",
        "axes[0].bar(comparison_df['Model'], comparison_df['Accuracy'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title('So s√°nh Accuracy')\n",
        "axes[0].set_ylim([0.9, 1.0])\n",
        "for i, v in enumerate(comparison_df['Accuracy']):\n",
        "    axes[0].text(i, v + 0.002, f'{v:.4f}', ha='center')\n",
        "\n",
        "# Train time\n",
        "axes[1].bar(comparison_df['Model'], comparison_df['Train Time (s)'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
        "axes[1].set_ylabel('Th·ªùi gian (s)')\n",
        "axes[1].set_title('So s√°nh Th·ªùi gian Hu·∫•n luy·ªán')\n",
        "\n",
        "# Predict time\n",
        "axes[2].bar(comparison_df['Model'], comparison_df['Predict Time (s)'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
        "axes[2].set_ylabel('Th·ªùi gian (s)')\n",
        "axes[2].set_title('So s√°nh Th·ªùi gian D·ª± ƒëo√°n')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hi·ªÉn th·ªã m·ªôt s·ªë ·∫£nh b·ªã ph√¢n lo·∫°i sai\n",
        "def show_misclassified(X_test, y_test, y_pred, n_samples=10):\n",
        "    \"\"\"\n",
        "    Hi·ªÉn th·ªã c√°c ·∫£nh b·ªã ph√¢n lo·∫°i sai.\n",
        "    \"\"\"\n",
        "    misclassified_idx = np.where(y_test != y_pred)[0]\n",
        "    \n",
        "    if len(misclassified_idx) == 0:\n",
        "        print(\"Kh√¥ng c√≥ m·∫´u n√†o b·ªã ph√¢n lo·∫°i sai!\")\n",
        "        return\n",
        "    \n",
        "    n_show = min(n_samples, len(misclassified_idx))\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    fig.suptitle(f'C√°c m·∫´u b·ªã ph√¢n lo·∫°i sai ({len(misclassified_idx)} m·∫´u)', fontsize=14)\n",
        "    \n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < n_show:\n",
        "            idx = misclassified_idx[i]\n",
        "            ax.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
        "            ax.set_title(f'Th·ª±c: {y_test[idx]}\\nD·ª± ƒëo√°n: {y_pred[idx]}', \n",
        "                        color='red', fontsize=10)\n",
        "        ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_misclassified(X_test, y_test, results_rbf['y_pred'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è 4. T·ªëi ∆∞u h√≥a M√¥ h√¨nh (GridSearch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# GridSearch ƒë·ªÉ t√¨m si√™u tham s·ªë t·ªët nh·∫•t\n",
        "# L∆∞u √Ω: GridSearch t·ªën th·ªùi gian, n√™n s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu nh·ªè\n",
        "\n",
        "print(\"üîç B·∫Øt ƒë·∫ßu Grid Search...\")\n",
        "print(\"‚ö†Ô∏è Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...\\n\")\n",
        "\n",
        "# T·∫°o pipeline cho GridSearch\n",
        "pipeline_grid = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svc', SVC(probability=True, cache_size=1000))\n",
        "])\n",
        "\n",
        "# ƒê·ªãnh nghƒ©a l∆∞·ªõi tham s·ªë\n",
        "param_grid = {\n",
        "    'svc__C': [0.1, 1, 10],\n",
        "    'svc__gamma': ['scale', 0.01, 0.1],\n",
        "    'svc__kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "# S·ª≠ d·ª•ng t·∫≠p con nh·ªè h∆°n cho GridSearch\n",
        "n_grid_samples = min(5000, len(X_train_subset))\n",
        "X_grid = X_train_subset[:n_grid_samples]\n",
        "y_grid = y_train_subset[:n_grid_samples]\n",
        "\n",
        "print(f\"üìä S·ª≠ d·ª•ng {n_grid_samples} m·∫´u cho GridSearch\")\n",
        "print(f\"üìä S·ªë l∆∞·ª£ng k·∫øt h·ª£p tham s·ªë: {len(param_grid['svc__C']) * len(param_grid['svc__gamma']) * len(param_grid['svc__kernel'])}\")\n",
        "\n",
        "# Th·ª±c hi·ªán GridSearch\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline_grid,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    scoring='accuracy',\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "start_time = time()\n",
        "grid_search.fit(X_grid, y_grid)\n",
        "grid_time = time() - start_time\n",
        "\n",
        "print(f\"\\n‚úÖ GridSearch ho√†n t·∫•t trong {grid_time:.2f} gi√¢y\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# K·∫øt qu·∫£ GridSearch\n",
        "print(\"\\nüìä K·∫øt qu·∫£ GridSearch:\")\n",
        "print(f\"   - Best Score (CV): {grid_search.best_score_:.4f}\")\n",
        "print(f\"   - Best Parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Hi·ªÉn th·ªã top 5 k·∫øt h·ª£p tham s·ªë\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "results_df = results_df.sort_values('rank_test_score')[[\n",
        "    'params', 'mean_test_score', 'std_test_score', 'mean_train_score', 'rank_test_score'\n",
        "]].head(10)\n",
        "\n",
        "print(\"\\nüèÜ Top 10 k·∫øt h·ª£p tham s·ªë:\")\n",
        "print(results_df.to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi tham s·ªë t·ªët nh·∫•t tr√™n to√†n b·ªô d·ªØ li·ªáu\n",
        "print(\"\\nüèãÔ∏è Hu·∫•n luy·ªán m√¥ h√¨nh t·ªëi ∆∞u v·ªõi tham s·ªë t·ªët nh·∫•t...\")\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "model_best, time_best = train_svm(\n",
        "    X_train_subset, y_train_subset,\n",
        "    kernel=best_params['svc__kernel'],\n",
        "    C=best_params['svc__C'],\n",
        "    gamma=best_params['svc__gamma'] if 'svc__gamma' in best_params else 'scale',\n",
        "    use_pca=False,\n",
        "    use_gpu=CUML_AVAILABLE\n",
        ")\n",
        "\n",
        "# ƒê√°nh gi√° m√¥ h√¨nh t·ªëi ∆∞u\n",
        "results_best = evaluate_model(model_best, X_test, y_test, \"SVM T·ªëi ∆∞u (Best Params)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Th·ª≠ nghi·ªám v·ªõi PCA v√† c√°c s·ªë th√†nh ph·∫ßn kh√°c nhau\n",
        "print(\"\\nüìä Th·ª≠ nghi·ªám v·ªõi PCA:\")\n",
        "\n",
        "pca_components = [50, 100, 150, 200]\n",
        "pca_results = []\n",
        "\n",
        "for n_comp in pca_components:\n",
        "    print(f\"\\nüîÑ Hu·∫•n luy·ªán v·ªõi PCA n_components={n_comp}\")\n",
        "    \n",
        "    model_pca_test, train_time = train_svm(\n",
        "        X_train_subset, y_train_subset,\n",
        "        kernel='rbf',\n",
        "        C=best_params.get('svc__C', 1.0),\n",
        "        gamma='scale',\n",
        "        use_pca=True,\n",
        "        n_components=n_comp,\n",
        "        use_gpu=CUML_AVAILABLE\n",
        "    )\n",
        "    \n",
        "    # ƒê√°nh gi√°\n",
        "    y_pred = model_pca_test.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    pca_results.append({\n",
        "        'n_components': n_comp,\n",
        "        'accuracy': accuracy,\n",
        "        'train_time': train_time\n",
        "    })\n",
        "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Hi·ªÉn th·ªã k·∫øt qu·∫£ PCA\n",
        "pca_df = pd.DataFrame(pca_results)\n",
        "print(\"\\nüìä So s√°nh c√°c c·∫•u h√¨nh PCA:\")\n",
        "print(pca_df.to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# V·∫Ω bi·ªÉu ƒë·ªì ·∫£nh h∆∞·ªüng c·ªßa PCA\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Accuracy vs PCA components\n",
        "axes[0].plot(pca_df['n_components'], pca_df['accuracy'], 'bo-', markersize=8)\n",
        "axes[0].set_xlabel('S·ªë th√†nh ph·∫ßn PCA')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title('Accuracy vs S·ªë th√†nh ph·∫ßn PCA')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Train time vs PCA components\n",
        "axes[1].plot(pca_df['n_components'], pca_df['train_time'], 'ro-', markersize=8)\n",
        "axes[1].set_xlabel('S·ªë th√†nh ph·∫ßn PCA')\n",
        "axes[1].set_ylabel('Th·ªùi gian hu·∫•n luy·ªán (s)')\n",
        "axes[1].set_title('Th·ªùi gian hu·∫•n luy·ªán vs S·ªë th√†nh ph·∫ßn PCA')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ 5. M√¥ h√¨nh Cu·ªëi c√πng v√† Xu·∫•t ƒê·∫ßu ra cho Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hu·∫•n luy·ªán m√¥ h√¨nh cu·ªëi c√πng v·ªõi to√†n b·ªô d·ªØ li·ªáu (n·∫øu mu·ªën)\n",
        "print(\"=\"*60)\n",
        "print(\"üèÜ Hu·∫•n luy·ªán M√¥ h√¨nh Cu·ªëi c√πng\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# S·ª≠ d·ª•ng tham s·ªë t·ªët nh·∫•t t·ª´ GridSearch\n",
        "final_model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svc', SVC(\n",
        "        kernel=best_params['svc__kernel'],\n",
        "        C=best_params['svc__C'],\n",
        "        gamma=best_params.get('svc__gamma', 'scale'),\n",
        "        probability=True,\n",
        "        cache_size=1000\n",
        "    ))\n",
        "])\n",
        "\n",
        "print(f\"\\nüìä C·∫•u h√¨nh m√¥ h√¨nh cu·ªëi c√πng:\")\n",
        "print(f\"   - Kernel: {best_params['svc__kernel']}\")\n",
        "print(f\"   - C: {best_params['svc__C']}\")\n",
        "print(f\"   - Gamma: {best_params.get('svc__gamma', 'scale')}\")\n",
        "\n",
        "# Hu·∫•n luy·ªán tr√™n t·∫≠p train ƒë·∫ßy ƒë·ªß (subset)\n",
        "start_time = time()\n",
        "final_model.fit(X_train_subset, y_train_subset)\n",
        "final_train_time = time() - start_time\n",
        "\n",
        "print(f\"\\n‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t trong {final_train_time:.2f} gi√¢y\")\n",
        "\n",
        "# ƒê√°nh gi√° cu·ªëi c√πng\n",
        "final_results = evaluate_model(final_model, X_test, y_test, \"M√¥ h√¨nh Cu·ªëi c√πng\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Xu·∫•t x√°c su·∫•t d·ª± ƒëo√°n cho Ensemble\n",
        "print(\"\\nüì§ Xu·∫•t ƒë·∫ßu ra cho Ensemble:\")\n",
        "\n",
        "# L·∫•y x√°c su·∫•t d·ª± ƒëo√°n\n",
        "proba = final_model.predict_proba(X_test)\n",
        "pred = final_model.predict(X_test)\n",
        "\n",
        "print(f\"\\nüìä Shape c·ªßa x√°c su·∫•t: {proba.shape}\")\n",
        "print(f\"   - M·ªói h√†ng l√† m·ªôt m·∫´u\")\n",
        "print(f\"   - M·ªói c·ªôt l√† x√°c su·∫•t cho ch·ªØ s·ªë 0-9\")\n",
        "\n",
        "# Hi·ªÉn th·ªã m·∫´u ƒë·∫ßu ra\n",
        "print(f\"\\nüìã V√≠ d·ª• 5 m·∫´u ƒë·∫ßu ti√™n:\")\n",
        "sample_output = pd.DataFrame(\n",
        "    proba[:5],\n",
        "    columns=[f'P(digit={i})' for i in range(10)]\n",
        ")\n",
        "sample_output['Predicted'] = pred[:5]\n",
        "sample_output['Actual'] = y_test[:5]\n",
        "print(sample_output.to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# L∆∞u ƒë·∫ßu ra cho ensemble\n",
        "print(\"\\nüíæ L∆∞u ƒë·∫ßu ra...\")\n",
        "\n",
        "# T·∫°o DataFrame cho ensemble\n",
        "ensemble_output = pd.DataFrame(proba, columns=[f'prob_digit_{i}' for i in range(10)])\n",
        "ensemble_output['predicted_label'] = pred\n",
        "ensemble_output['true_label'] = y_test\n",
        "\n",
        "# L∆∞u ra file CSV\n",
        "ensemble_output.to_csv('svm_predictions_for_ensemble.csv', index=False)\n",
        "print(\"‚úÖ ƒê√£ l∆∞u: svm_predictions_for_ensemble.csv\")\n",
        "\n",
        "# L∆∞u x√°c su·∫•t d·∫°ng numpy array\n",
        "np.save('svm_probabilities.npy', proba)\n",
        "print(\"‚úÖ ƒê√£ l∆∞u: svm_probabilities.npy\")\n",
        "\n",
        "# L∆∞u nh√£n d·ª± ƒëo√°n\n",
        "np.save('svm_predictions.npy', pred)\n",
        "print(\"‚úÖ ƒê√£ l∆∞u: svm_predictions.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ Save v√† Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================\n",
        "# SAVE MODEL V·ªÄ M√ÅY\n",
        "# ============================\n",
        "\n",
        "import joblib\n",
        "from google.colab import files  # Ch·ªâ d√πng tr√™n Google Colab\n",
        "\n",
        "# 1. L∆∞u model v√†o file\n",
        "model_filename = 'svm_digit_classifier.joblib'\n",
        "joblib.dump(final_model, model_filename)\n",
        "print(f\"‚úÖ ƒê√£ l∆∞u model: {model_filename}\")\n",
        "\n",
        "# 2. L∆∞u predictions v√† probabilities\n",
        "np.save('svm_probabilities.npy', proba)\n",
        "np.save('svm_predictions.npy', pred)\n",
        "ensemble_output.to_csv('svm_predictions_for_ensemble.csv', index=False)\n",
        "print(\"‚úÖ ƒê√£ l∆∞u predictions\")\n",
        "\n",
        "# 3. Download v·ªÅ m√°y (Google Colab)\n",
        "print(\"\\nüì• ƒêang t·∫£i files v·ªÅ m√°y...\")\n",
        "try:\n",
        "    files.download(model_filename)\n",
        "    files.download('svm_probabilities.npy')\n",
        "    files.download('svm_predictions.npy')\n",
        "    files.download('svm_predictions_for_ensemble.csv')\n",
        "    files.download('confusion_matrix.png')\n",
        "    print(\"‚úÖ T·∫£i th√†nh c√¥ng!\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Kh√¥ng th·ªÉ t·ª± ƒë·ªông download. Vui l√≤ng download th·ªß c√¥ng t·ª´ Files panel b√™n tr√°i.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================\n",
        "# LOAD MODEL V√Ä S·ª¨ D·ª§NG L·∫†I\n",
        "# ============================\n",
        "\n",
        "# Load model ƒë√£ l∆∞u\n",
        "loaded_model = joblib.load('svm_digit_classifier.joblib')\n",
        "print(\"‚úÖ ƒê√£ load model th√†nh c√¥ng!\")\n",
        "\n",
        "# Test v·ªõi m·ªôt ·∫£nh\n",
        "test_idx = 0\n",
        "test_image = X_test[test_idx:test_idx+1]\n",
        "\n",
        "# D·ª± ƒëo√°n\n",
        "prediction = loaded_model.predict(test_image)[0]\n",
        "probability = loaded_model.predict_proba(test_image)[0]\n",
        "\n",
        "print(f\"\\nüîÆ D·ª± ƒëo√°n: {prediction}\")\n",
        "print(f\"üéØ Nh√£n th·ª±c t·∫ø: {y_test[test_idx]}\")\n",
        "print(f\"üìä ƒê·ªô tin c·∫≠y: {probability[prediction]:.4f}\")\n",
        "print(f\"üìà X√°c su·∫•t c√°c l·ªõp: {dict(zip(range(10), probability.round(4)))}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìñ Code s·ª≠ d·ª•ng model trong session m·ªõi\n",
        "\n",
        "Copy code d∆∞·ªõi ƒë√¢y ƒë·ªÉ s·ª≠ d·ª•ng model ƒë√£ l∆∞u trong m·ªôt notebook/script m·ªõi:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================\n",
        "# CODE S·ª¨ D·ª§NG TRONG SESSION M·ªöI\n",
        "# ============================\n",
        "# Copy ƒëo·∫°n code n√†y ƒë·ªÉ s·ª≠ d·ª•ng model ƒë√£ l∆∞u\n",
        "\n",
        "\"\"\"\n",
        "import joblib\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# Upload model file (n·∫øu c·∫ßn)\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Load model\n",
        "model = joblib.load('svm_digit_classifier.joblib')\n",
        "\n",
        "# Chu·∫©n b·ªã ·∫£nh ƒë·∫ßu v√†o (28x28 pixels, gi√° tr·ªã 0-255)\n",
        "# image = your_image.reshape(1, 784)  # Flatten v·ªÅ 1D\n",
        "# image = image.astype(np.float32) / 255.0  # Chu·∫©n h√≥a\n",
        "\n",
        "# D·ª± ƒëo√°n\n",
        "# prediction = model.predict(image)[0]\n",
        "# probabilities = model.predict_proba(image)[0]\n",
        "\n",
        "# print(f\"Predicted digit: {prediction}\")\n",
        "# print(f\"Confidence: {probabilities[prediction]:.4f}\")\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìã Code m·∫´u ƒë√£ ƒë∆∞·ª£c in ·ªü tr√™n. Uncomment ƒë·ªÉ s·ª≠ d·ª•ng.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# L∆∞u m√¥ h√¨nh\n",
        "print(\"\\nüíæ L∆∞u m√¥ h√¨nh...\")\n",
        "\n",
        "joblib.dump(final_model, 'svm_digit_classifier.joblib')\n",
        "print(\"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh: svm_digit_classifier.joblib\")\n",
        "\n",
        "# H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ l∆∞u\n",
        "print(\"\\nüìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ l∆∞u:\")\n",
        "print(\"\"\"\n",
        "# Load m√¥ h√¨nh\n",
        "import joblib\n",
        "model = joblib.load('svm_digit_classifier.joblib')\n",
        "\n",
        "# D·ª± ƒëo√°n nh√£n\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# D·ª± ƒëo√°n x√°c su·∫•t\n",
        "probabilities = model.predict_proba(X_new)\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä T·ªïng k·∫øt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# T·ªïng k·∫øt k·∫øt qu·∫£\n",
        "print(\"=\"*60)\n",
        "print(\"üìä T·ªîNG K·∫æT K·∫æT QU·∫¢\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nüéØ M√¥ h√¨nh cu·ªëi c√πng:\")\n",
        "print(f\"   - Accuracy: {final_results['accuracy']:.4f} ({final_results['accuracy']*100:.2f}%)\")\n",
        "print(f\"   - Kernel: {best_params['svc__kernel']}\")\n",
        "print(f\"   - C: {best_params['svc__C']}\")\n",
        "print(f\"   - Gamma: {best_params.get('svc__gamma', 'scale')}\")\n",
        "\n",
        "print(f\"\\nüìÅ C√°c file ƒë√£ l∆∞u:\")\n",
        "print(\"   - svm_digit_classifier.joblib (m√¥ h√¨nh)\")\n",
        "print(\"   - svm_predictions_for_ensemble.csv (ƒë·∫ßu ra cho ensemble)\")\n",
        "print(\"   - svm_probabilities.npy (x√°c su·∫•t d·ª± ƒëo√°n)\")\n",
        "print(\"   - svm_predictions.npy (nh√£n d·ª± ƒëo√°n)\")\n",
        "\n",
        "print(f\"\\n‚úÖ Ho√†n t·∫•t!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# V·∫Ω confusion matrix cu·ªëi c√πng v·ªõi ƒë·ªãnh d·∫°ng ƒë·∫πp\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Normalize confusion matrix\n",
        "cm = final_results['confusion_matrix']\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# V·∫Ω heatmap\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
        "            xticklabels=range(10), yticklabels=range(10),\n",
        "            cbar_kws={'label': 'T·ª∑ l·ªá'})\n",
        "\n",
        "plt.title('Ma tr·∫≠n Nh·∫ßm l·∫´n (Normalized) - M√¥ h√¨nh SVM Cu·ªëi c√πng', fontsize=14)\n",
        "plt.xlabel('D·ª± ƒëo√°n', fontsize=12)\n",
        "plt.ylabel('Th·ª±c t·∫ø', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "print(\"‚úÖ ƒê√£ l∆∞u: confusion_matrix.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Bonus: H√†m ti·ªán √≠ch ƒë·ªÉ d·ª± ƒëo√°n ·∫£nh m·ªõi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def predict_digit(model, image):\n",
        "    \"\"\"\n",
        "    D·ª± ƒëo√°n ch·ªØ s·ªë t·ª´ ·∫£nh.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : sklearn Pipeline\n",
        "        M√¥ h√¨nh SVM ƒë√£ hu·∫•n luy·ªán\n",
        "    image : array-like\n",
        "        ·∫¢nh ƒë·∫ßu v√†o (28x28 ho·∫∑c 784,)\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : K·∫øt qu·∫£ d·ª± ƒëo√°n\n",
        "    \"\"\"\n",
        "    # Flatten n·∫øu c·∫ßn\n",
        "    if image.ndim == 2:\n",
        "        image = image.reshape(1, -1)\n",
        "    elif image.ndim == 1:\n",
        "        image = image.reshape(1, -1)\n",
        "    \n",
        "    # Chu·∫©n h√≥a n·∫øu c·∫ßn (gi·∫£ s·ª≠ ·∫£nh c√≥ gi√° tr·ªã 0-255)\n",
        "    if image.max() > 1:\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "    \n",
        "    # D·ª± ƒëo√°n\n",
        "    pred = model.predict(image)[0]\n",
        "    proba = model.predict_proba(image)[0]\n",
        "    \n",
        "    return {\n",
        "        'prediction': pred,\n",
        "        'confidence': proba[pred],\n",
        "        'probabilities': proba\n",
        "    }\n",
        "\n",
        "# Test v·ªõi m·ªôt ·∫£nh t·ª´ t·∫≠p test\n",
        "test_image = X_test[0]\n",
        "result = predict_digit(final_model, test_image)\n",
        "\n",
        "print(f\"üîÆ D·ª± ƒëo√°n: {result['prediction']}\")\n",
        "print(f\"üìä ƒê·ªô tin c·∫≠y: {result['confidence']:.4f}\")\n",
        "print(f\"üéØ Nh√£n th·ª±c t·∫ø: {y_test[0]}\")\n",
        "\n",
        "# Hi·ªÉn th·ªã ·∫£nh\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(test_image.reshape(28, 28), cmap='gray')\n",
        "plt.title(f'D·ª± ƒëo√°n: {result[\"prediction\"]} (Th·ª±c t·∫ø: {y_test[0]})')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(range(10), result['probabilities'])\n",
        "plt.xlabel('Ch·ªØ s·ªë')\n",
        "plt.ylabel('X√°c su·∫•t')\n",
        "plt.title('Ph√¢n b·ªë x√°c su·∫•t')\n",
        "plt.xticks(range(10))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}